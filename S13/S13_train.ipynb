{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n",
      "loaded 341094 tokens\n",
      "1 epoch = 20 batches\n",
      "step0 | loss: 10.947792053222656 | dt: 8432.83ms | tok/sec:  1942.88\n",
      "step1 | loss: 9.57986831665039 | dt: 316.14ms | tok/sec:  51825.58\n",
      "step2 | loss: 9.27359390258789 | dt: 315.59ms | tok/sec:  51915.04\n",
      "step3 | loss: 9.166304588317871 | dt: 315.96ms | tok/sec:  51854.40\n",
      "step4 | loss: 8.875709533691406 | dt: 314.95ms | tok/sec:  52021.27\n",
      "step5 | loss: 8.707947731018066 | dt: 316.47ms | tok/sec:  51770.73\n",
      "step6 | loss: 8.66827392578125 | dt: 314.92ms | tok/sec:  52025.37\n",
      "step7 | loss: 8.412836074829102 | dt: 315.74ms | tok/sec:  51890.27\n",
      "step8 | loss: 8.15450382232666 | dt: 314.91ms | tok/sec:  52027.89\n",
      "step9 | loss: 7.983860015869141 | dt: 315.74ms | tok/sec:  51890.31\n",
      "step10 | loss: 7.764669895172119 | dt: 315.56ms | tok/sec:  51920.42\n",
      "step11 | loss: 7.631190299987793 | dt: 315.23ms | tok/sec:  51975.24\n",
      "step12 | loss: 7.48146390914917 | dt: 314.91ms | tok/sec:  52027.85\n",
      "step13 | loss: 7.435215950012207 | dt: 315.54ms | tok/sec:  51924.22\n",
      "step14 | loss: 7.384522438049316 | dt: 315.40ms | tok/sec:  51946.32\n",
      "step15 | loss: 7.17930793762207 | dt: 316.19ms | tok/sec:  51816.63\n",
      "step16 | loss: 7.057337760925293 | dt: 315.32ms | tok/sec:  51960.30\n",
      "step17 | loss: 6.992191791534424 | dt: 316.34ms | tok/sec:  51791.91\n",
      "step18 | loss: 6.92584228515625 | dt: 315.53ms | tok/sec:  51924.58\n",
      "step19 | loss: 6.710968971252441 | dt: 316.18ms | tok/sec:  51818.39\n",
      "step20 | loss: 6.653669357299805 | dt: 314.86ms | tok/sec:  52035.41\n",
      "step21 | loss: 6.407564640045166 | dt: 315.01ms | tok/sec:  52010.45\n",
      "step22 | loss: 6.465216159820557 | dt: 315.32ms | tok/sec:  51960.23\n",
      "step23 | loss: 6.356006622314453 | dt: 315.53ms | tok/sec:  51925.56\n",
      "step24 | loss: 6.274307727813721 | dt: 314.99ms | tok/sec:  52013.63\n",
      "step25 | loss: 6.399373531341553 | dt: 316.30ms | tok/sec:  51799.45\n",
      "step26 | loss: 6.484272003173828 | dt: 314.97ms | tok/sec:  52018.16\n",
      "step27 | loss: 6.405840873718262 | dt: 315.34ms | tok/sec:  51956.34\n",
      "step28 | loss: 6.263428211212158 | dt: 315.39ms | tok/sec:  51948.72\n",
      "step29 | loss: 6.228601455688477 | dt: 315.89ms | tok/sec:  51865.95\n",
      "step30 | loss: 6.138632297515869 | dt: 315.36ms | tok/sec:  51953.55\n",
      "step31 | loss: 6.170716762542725 | dt: 315.18ms | tok/sec:  51983.57\n",
      "step32 | loss: 6.15438985824585 | dt: 316.23ms | tok/sec:  51810.30\n",
      "step33 | loss: 6.23642635345459 | dt: 315.32ms | tok/sec:  51959.28\n",
      "step34 | loss: 6.3222246170043945 | dt: 315.02ms | tok/sec:  52009.62\n",
      "step35 | loss: 6.199630260467529 | dt: 315.03ms | tok/sec:  52008.44\n",
      "step36 | loss: 6.149497985839844 | dt: 315.87ms | tok/sec:  51868.73\n",
      "step37 | loss: 6.153378486633301 | dt: 316.66ms | tok/sec:  51740.67\n",
      "step38 | loss: 6.175041198730469 | dt: 316.33ms | tok/sec:  51793.90\n",
      "step39 | loss: 6.021989822387695 | dt: 316.28ms | tok/sec:  51801.91\n",
      "step40 | loss: 6.181881427764893 | dt: 314.84ms | tok/sec:  52038.65\n",
      "step41 | loss: 5.956357955932617 | dt: 315.68ms | tok/sec:  51900.50\n",
      "step42 | loss: 6.072529315948486 | dt: 315.20ms | tok/sec:  51980.03\n",
      "step43 | loss: 5.947836399078369 | dt: 315.12ms | tok/sec:  51992.78\n",
      "step44 | loss: 5.9123125076293945 | dt: 314.95ms | tok/sec:  52021.23\n",
      "step45 | loss: 6.070395469665527 | dt: 315.20ms | tok/sec:  51979.72\n",
      "step46 | loss: 6.2073140144348145 | dt: 315.03ms | tok/sec:  52007.53\n",
      "step47 | loss: 6.129936218261719 | dt: 315.39ms | tok/sec:  51948.40\n",
      "step48 | loss: 6.033378601074219 | dt: 314.96ms | tok/sec:  52018.71\n",
      "step49 | loss: 6.003600120544434 | dt: 316.62ms | tok/sec:  51746.75\n",
      "step50 | loss: 5.92996883392334 | dt: 315.64ms | tok/sec:  51906.85\n",
      "step51 | loss: 5.972348213195801 | dt: 317.54ms | tok/sec:  51597.20\n",
      "step52 | loss: 5.940213680267334 | dt: 315.30ms | tok/sec:  51963.45\n",
      "step53 | loss: 6.03945255279541 | dt: 317.58ms | tok/sec:  51589.69\n",
      "step54 | loss: 6.15225887298584 | dt: 316.55ms | tok/sec:  51758.29\n",
      "step55 | loss: 6.028790473937988 | dt: 317.27ms | tok/sec:  51640.05\n",
      "step56 | loss: 5.958652496337891 | dt: 316.98ms | tok/sec:  51687.78\n",
      "step57 | loss: 5.937507629394531 | dt: 316.69ms | tok/sec:  51734.79\n",
      "step58 | loss: 5.9758076667785645 | dt: 316.50ms | tok/sec:  51766.83\n",
      "step59 | loss: 5.8180460929870605 | dt: 316.82ms | tok/sec:  51713.34\n",
      "step60 | loss: 6.037160396575928 | dt: 316.62ms | tok/sec:  51746.24\n",
      "step61 | loss: 5.790504455566406 | dt: 316.44ms | tok/sec:  51775.83\n",
      "step62 | loss: 5.924043655395508 | dt: 316.43ms | tok/sec:  51777.51\n",
      "step63 | loss: 5.813302993774414 | dt: 317.58ms | tok/sec:  51590.39\n",
      "step64 | loss: 5.77497673034668 | dt: 316.50ms | tok/sec:  51765.77\n",
      "step65 | loss: 5.919419765472412 | dt: 317.80ms | tok/sec:  51553.93\n",
      "step66 | loss: 6.082854747772217 | dt: 316.38ms | tok/sec:  51785.67\n",
      "step67 | loss: 6.009209632873535 | dt: 316.40ms | tok/sec:  51783.33\n",
      "step68 | loss: 5.89581298828125 | dt: 317.18ms | tok/sec:  51654.99\n",
      "step69 | loss: 5.849365234375 | dt: 316.73ms | tok/sec:  51729.38\n",
      "step70 | loss: 5.791043281555176 | dt: 316.70ms | tok/sec:  51734.13\n",
      "step71 | loss: 5.846635818481445 | dt: 316.81ms | tok/sec:  51716.06\n",
      "step72 | loss: 5.796531677246094 | dt: 316.30ms | tok/sec:  51799.60\n",
      "step73 | loss: 5.899295330047607 | dt: 316.68ms | tok/sec:  51737.13\n",
      "step74 | loss: 6.034929275512695 | dt: 317.45ms | tok/sec:  51611.27\n",
      "step75 | loss: 5.892142295837402 | dt: 317.47ms | tok/sec:  51608.79\n",
      "step76 | loss: 5.802130699157715 | dt: 316.74ms | tok/sec:  51726.42\n",
      "step77 | loss: 5.777308464050293 | dt: 317.47ms | tok/sec:  51607.55\n",
      "step78 | loss: 5.815530300140381 | dt: 317.08ms | tok/sec:  51671.97\n",
      "step79 | loss: 5.642458438873291 | dt: 317.17ms | tok/sec:  51656.47\n",
      "step80 | loss: 5.882730484008789 | dt: 316.35ms | tok/sec:  51791.17\n",
      "step81 | loss: 5.632319450378418 | dt: 317.64ms | tok/sec:  51580.05\n",
      "step82 | loss: 5.779943466186523 | dt: 318.08ms | tok/sec:  51508.83\n",
      "step83 | loss: 5.678743362426758 | dt: 317.91ms | tok/sec:  51536.45\n",
      "step84 | loss: 5.66831111907959 | dt: 316.75ms | tok/sec:  51725.29\n",
      "step85 | loss: 5.796831130981445 | dt: 317.98ms | tok/sec:  51525.01\n",
      "step86 | loss: 5.972435474395752 | dt: 317.24ms | tok/sec:  51645.48\n",
      "step87 | loss: 5.888358116149902 | dt: 317.78ms | tok/sec:  51557.37\n",
      "step88 | loss: 5.777889251708984 | dt: 316.30ms | tok/sec:  51799.02\n",
      "step89 | loss: 5.732553005218506 | dt: 317.49ms | tok/sec:  51604.53\n",
      "step90 | loss: 5.663937568664551 | dt: 317.39ms | tok/sec:  51620.61\n",
      "step91 | loss: 5.737165451049805 | dt: 318.04ms | tok/sec:  51515.51\n",
      "step92 | loss: 5.6830549240112305 | dt: 317.24ms | tok/sec:  51646.10\n",
      "step93 | loss: 5.77519416809082 | dt: 317.13ms | tok/sec:  51662.95\n",
      "step94 | loss: 5.925685405731201 | dt: 317.66ms | tok/sec:  51577.92\n",
      "step95 | loss: 5.756545543670654 | dt: 317.71ms | tok/sec:  51568.36\n",
      "step96 | loss: 5.657118320465088 | dt: 317.91ms | tok/sec:  51536.10\n",
      "step97 | loss: 5.64070987701416 | dt: 318.08ms | tok/sec:  51508.64\n",
      "step98 | loss: 5.693837642669678 | dt: 317.46ms | tok/sec:  51609.64\n",
      "step99 | loss: 5.517798900604248 | dt: 318.12ms | tok/sec:  51502.92\n",
      "step100 | loss: 5.800572872161865 | dt: 316.95ms | tok/sec:  51692.84\n",
      "step101 | loss: 5.513270378112793 | dt: 317.11ms | tok/sec:  51667.26\n",
      "step102 | loss: 5.674553394317627 | dt: 317.77ms | tok/sec:  51559.11\n",
      "step103 | loss: 5.5948805809021 | dt: 317.03ms | tok/sec:  51679.50\n",
      "step104 | loss: 5.532259941101074 | dt: 318.05ms | tok/sec:  51514.47\n",
      "step105 | loss: 5.686662197113037 | dt: 317.31ms | tok/sec:  51634.62\n",
      "step106 | loss: 5.871673107147217 | dt: 316.92ms | tok/sec:  51698.05\n",
      "step107 | loss: 5.78400993347168 | dt: 318.36ms | tok/sec:  51464.12\n",
      "step108 | loss: 5.63985538482666 | dt: 317.64ms | tok/sec:  51580.78\n",
      "step109 | loss: 5.602919578552246 | dt: 318.08ms | tok/sec:  51508.95\n",
      "step110 | loss: 5.557062149047852 | dt: 317.28ms | tok/sec:  51639.19\n",
      "step111 | loss: 5.604378700256348 | dt: 318.40ms | tok/sec:  51457.19\n",
      "step112 | loss: 5.55348014831543 | dt: 317.80ms | tok/sec:  51553.89\n",
      "step113 | loss: 5.648366451263428 | dt: 446.31ms | tok/sec:  36709.69\n",
      "step114 | loss: 5.799012184143066 | dt: 317.62ms | tok/sec:  51584.03\n",
      "step115 | loss: 5.6458420753479 | dt: 318.35ms | tok/sec:  51465.16\n",
      "step116 | loss: 5.534024238586426 | dt: 317.44ms | tok/sec:  51612.59\n",
      "step117 | loss: 5.4892377853393555 | dt: 317.25ms | tok/sec:  51643.93\n",
      "step118 | loss: 5.572911739349365 | dt: 317.80ms | tok/sec:  51554.47\n",
      "step119 | loss: 5.415262222290039 | dt: 318.14ms | tok/sec:  51499.26\n",
      "step120 | loss: 5.624882698059082 | dt: 317.94ms | tok/sec:  51531.85\n",
      "step121 | loss: 5.345019817352295 | dt: 317.42ms | tok/sec:  51615.46\n",
      "step122 | loss: 5.498775959014893 | dt: 318.28ms | tok/sec:  51476.34\n",
      "step123 | loss: 5.446020126342773 | dt: 318.74ms | tok/sec:  51402.38\n",
      "step124 | loss: 5.376105785369873 | dt: 318.44ms | tok/sec:  51450.98\n",
      "step125 | loss: 5.518994331359863 | dt: 318.52ms | tok/sec:  51438.00\n",
      "step126 | loss: 5.715825080871582 | dt: 318.45ms | tok/sec:  51448.79\n",
      "step127 | loss: 5.607705593109131 | dt: 318.80ms | tok/sec:  51392.42\n",
      "step128 | loss: 5.499417304992676 | dt: 318.23ms | tok/sec:  51484.36\n",
      "step129 | loss: 5.458685874938965 | dt: 318.52ms | tok/sec:  51438.43\n",
      "step130 | loss: 5.406837463378906 | dt: 317.12ms | tok/sec:  51665.79\n",
      "step131 | loss: 5.439040184020996 | dt: 317.54ms | tok/sec:  51596.85\n",
      "step132 | loss: 5.376880645751953 | dt: 318.41ms | tok/sec:  51455.41\n",
      "step133 | loss: 5.498472213745117 | dt: 317.80ms | tok/sec:  51555.20\n",
      "step134 | loss: 5.6520538330078125 | dt: 318.44ms | tok/sec:  51450.52\n",
      "step135 | loss: 5.479037284851074 | dt: 318.36ms | tok/sec:  51463.66\n",
      "step136 | loss: 5.3676958084106445 | dt: 318.47ms | tok/sec:  51445.51\n",
      "step137 | loss: 5.338772773742676 | dt: 318.58ms | tok/sec:  51427.84\n",
      "step138 | loss: 5.428502082824707 | dt: 318.51ms | tok/sec:  51439.70\n",
      "step139 | loss: 5.2297515869140625 | dt: 318.67ms | tok/sec:  51414.41\n",
      "step140 | loss: 5.473635196685791 | dt: 317.68ms | tok/sec:  51573.93\n",
      "step141 | loss: 5.174899101257324 | dt: 318.58ms | tok/sec:  51428.84\n",
      "step142 | loss: 5.328699588775635 | dt: 317.53ms | tok/sec:  51597.82\n",
      "step143 | loss: 5.273567199707031 | dt: 317.50ms | tok/sec:  51603.63\n",
      "step144 | loss: 5.198273658752441 | dt: 317.60ms | tok/sec:  51587.71\n",
      "step145 | loss: 5.33328104019165 | dt: 317.51ms | tok/sec:  51602.01\n",
      "step146 | loss: 5.523095607757568 | dt: 317.69ms | tok/sec:  51572.73\n",
      "step147 | loss: 5.447673797607422 | dt: 318.66ms | tok/sec:  51415.14\n",
      "step148 | loss: 5.346713066101074 | dt: 317.64ms | tok/sec:  51580.63\n",
      "step149 | loss: 5.30948543548584 | dt: 318.02ms | tok/sec:  51518.33\n",
      "step150 | loss: 5.231387138366699 | dt: 318.07ms | tok/sec:  51510.61\n",
      "step151 | loss: 5.2688703536987305 | dt: 318.77ms | tok/sec:  51397.34\n",
      "step152 | loss: 5.20304012298584 | dt: 317.65ms | tok/sec:  51579.50\n",
      "step153 | loss: 5.333573818206787 | dt: 318.31ms | tok/sec:  51472.64\n",
      "step154 | loss: 5.502878665924072 | dt: 318.11ms | tok/sec:  51504.47\n",
      "step155 | loss: 5.335020065307617 | dt: 318.45ms | tok/sec:  51449.13\n",
      "step156 | loss: 5.197319984436035 | dt: 317.41ms | tok/sec:  51617.36\n",
      "step157 | loss: 5.145983695983887 | dt: 318.64ms | tok/sec:  51418.80\n",
      "step158 | loss: 5.240964889526367 | dt: 318.08ms | tok/sec:  51508.87\n",
      "step159 | loss: 5.048583030700684 | dt: 318.35ms | tok/sec:  51465.63\n",
      "step160 | loss: 5.310612201690674 | dt: 317.47ms | tok/sec:  51607.78\n",
      "step161 | loss: 5.029911994934082 | dt: 319.03ms | tok/sec:  51355.89\n",
      "step162 | loss: 5.192503929138184 | dt: 318.06ms | tok/sec:  51511.73\n",
      "step163 | loss: 5.124131202697754 | dt: 318.24ms | tok/sec:  51483.01\n",
      "step164 | loss: 5.041393756866455 | dt: 317.93ms | tok/sec:  51534.13\n",
      "step165 | loss: 5.161077976226807 | dt: 318.83ms | tok/sec:  51388.61\n",
      "step166 | loss: 5.392002105712891 | dt: 317.75ms | tok/sec:  51561.93\n",
      "step167 | loss: 5.259151458740234 | dt: 319.00ms | tok/sec:  51360.81\n",
      "step168 | loss: 5.225896835327148 | dt: 317.93ms | tok/sec:  51532.62\n",
      "step169 | loss: 5.187356948852539 | dt: 317.91ms | tok/sec:  51536.72\n",
      "step170 | loss: 5.121884346008301 | dt: 318.08ms | tok/sec:  51508.33\n",
      "step171 | loss: 5.134254455566406 | dt: 318.57ms | tok/sec:  51430.61\n",
      "step172 | loss: 5.077415466308594 | dt: 319.07ms | tok/sec:  51349.83\n",
      "step173 | loss: 5.238107681274414 | dt: 318.57ms | tok/sec:  51429.27\n",
      "step174 | loss: 5.387846946716309 | dt: 318.83ms | tok/sec:  51387.65\n",
      "step175 | loss: 5.217818260192871 | dt: 319.99ms | tok/sec:  51201.69\n",
      "step176 | loss: 5.084592819213867 | dt: 319.00ms | tok/sec:  51360.35\n",
      "step177 | loss: 5.031870365142822 | dt: 319.02ms | tok/sec:  51357.24\n",
      "step178 | loss: 5.123651027679443 | dt: 318.92ms | tok/sec:  51373.59\n",
      "step179 | loss: 4.944004058837891 | dt: 319.28ms | tok/sec:  51315.51\n",
      "step180 | loss: 5.216139793395996 | dt: 319.05ms | tok/sec:  51352.33\n",
      "step181 | loss: 4.9076948165893555 | dt: 319.18ms | tok/sec:  51331.38\n",
      "step182 | loss: 5.074070930480957 | dt: 319.53ms | tok/sec:  51274.96\n",
      "step183 | loss: 4.977914810180664 | dt: 320.36ms | tok/sec:  51142.97\n",
      "step184 | loss: 4.923034191131592 | dt: 319.26ms | tok/sec:  51318.43\n",
      "step185 | loss: 5.046722412109375 | dt: 318.97ms | tok/sec:  51365.68\n",
      "step186 | loss: 5.294093132019043 | dt: 319.14ms | tok/sec:  51338.32\n",
      "step187 | loss: 5.124746322631836 | dt: 320.12ms | tok/sec:  51180.98\n",
      "step188 | loss: 5.129446029663086 | dt: 318.70ms | tok/sec:  51408.45\n",
      "step189 | loss: 5.084692001342773 | dt: 319.98ms | tok/sec:  51203.14\n",
      "step190 | loss: 5.035611152648926 | dt: 318.74ms | tok/sec:  51402.03\n",
      "step191 | loss: 5.04939603805542 | dt: 319.57ms | tok/sec:  51268.58\n",
      "step192 | loss: 4.9401469230651855 | dt: 319.63ms | tok/sec:  51259.63\n",
      "step193 | loss: 5.1557111740112305 | dt: 319.02ms | tok/sec:  51356.78\n",
      "step194 | loss: 5.2987470626831055 | dt: 319.01ms | tok/sec:  51359.16\n",
      "step195 | loss: 5.152591705322266 | dt: 320.27ms | tok/sec:  51156.98\n",
      "step196 | loss: 4.981314659118652 | dt: 319.37ms | tok/sec:  51301.45\n",
      "step197 | loss: 4.904049396514893 | dt: 318.79ms | tok/sec:  51393.73\n",
      "step198 | loss: 5.034578323364258 | dt: 319.81ms | tok/sec:  51230.81\n",
      "step199 | loss: 4.839526176452637 | dt: 319.06ms | tok/sec:  51351.02\n",
      "step200 | loss: 5.153886795043945 | dt: 319.23ms | tok/sec:  51323.68\n",
      "step201 | loss: 4.838475704193115 | dt: 320.36ms | tok/sec:  51142.17\n",
      "step202 | loss: 4.978523254394531 | dt: 318.85ms | tok/sec:  51385.39\n",
      "step203 | loss: 4.87954044342041 | dt: 319.89ms | tok/sec:  51217.49\n",
      "step204 | loss: 4.8408613204956055 | dt: 320.24ms | tok/sec:  51161.74\n",
      "step205 | loss: 4.930048942565918 | dt: 319.90ms | tok/sec:  51215.69\n",
      "step206 | loss: 5.162858486175537 | dt: 319.53ms | tok/sec:  51274.54\n",
      "step207 | loss: 5.043913841247559 | dt: 320.44ms | tok/sec:  51130.22\n",
      "step208 | loss: 5.050972938537598 | dt: 319.03ms | tok/sec:  51355.28\n",
      "step209 | loss: 5.013604164123535 | dt: 319.55ms | tok/sec:  51272.02\n",
      "step210 | loss: 4.9314093589782715 | dt: 319.18ms | tok/sec:  51332.34\n",
      "step211 | loss: 4.940997123718262 | dt: 320.01ms | tok/sec:  51198.94\n",
      "step212 | loss: 4.885701656341553 | dt: 319.05ms | tok/sec:  51352.71\n",
      "step213 | loss: 5.0669755935668945 | dt: 320.63ms | tok/sec:  51099.16\n",
      "step214 | loss: 5.239953994750977 | dt: 319.17ms | tok/sec:  51333.91\n",
      "step215 | loss: 5.068647384643555 | dt: 319.34ms | tok/sec:  51306.47\n",
      "step216 | loss: 4.905516624450684 | dt: 320.62ms | tok/sec:  51101.32\n",
      "step217 | loss: 4.794954299926758 | dt: 320.02ms | tok/sec:  51197.53\n",
      "step218 | loss: 4.977658271789551 | dt: 319.10ms | tok/sec:  51344.00\n",
      "step219 | loss: 4.766141891479492 | dt: 320.63ms | tok/sec:  51099.08\n",
      "step220 | loss: 5.071146488189697 | dt: 319.03ms | tok/sec:  51355.70\n",
      "step221 | loss: 4.748632431030273 | dt: 319.39ms | tok/sec:  51297.78\n",
      "step222 | loss: 4.933743476867676 | dt: 319.71ms | tok/sec:  51246.78\n",
      "step223 | loss: 4.821136474609375 | dt: 320.15ms | tok/sec:  51175.80\n",
      "step224 | loss: 4.769083023071289 | dt: 319.16ms | tok/sec:  51335.14\n",
      "step225 | loss: 4.843467712402344 | dt: 319.28ms | tok/sec:  51315.63\n",
      "step226 | loss: 5.098479747772217 | dt: 320.53ms | tok/sec:  51116.03\n",
      "step227 | loss: 4.933220863342285 | dt: 320.35ms | tok/sec:  51144.76\n",
      "step228 | loss: 5.04022741317749 | dt: 319.35ms | tok/sec:  51303.79\n",
      "step229 | loss: 4.941211223602295 | dt: 320.46ms | tok/sec:  51126.76\n",
      "step230 | loss: 4.873640060424805 | dt: 319.33ms | tok/sec:  51308.00\n",
      "step231 | loss: 4.924638748168945 | dt: 320.11ms | tok/sec:  51182.01\n",
      "step232 | loss: 4.837747573852539 | dt: 320.03ms | tok/sec:  51195.89\n",
      "step233 | loss: 5.01227331161499 | dt: 320.62ms | tok/sec:  51101.06\n",
      "step234 | loss: 5.167198657989502 | dt: 319.15ms | tok/sec:  51336.56\n",
      "step235 | loss: 4.998368263244629 | dt: 320.55ms | tok/sec:  51112.76\n",
      "step236 | loss: 4.8119306564331055 | dt: 319.38ms | tok/sec:  51300.00\n",
      "step237 | loss: 4.717806816101074 | dt: 319.40ms | tok/sec:  51296.86\n",
      "step238 | loss: 4.871889114379883 | dt: 319.70ms | tok/sec:  51247.74\n",
      "step239 | loss: 4.710724830627441 | dt: 320.76ms | tok/sec:  51079.41\n",
      "step240 | loss: 5.012284278869629 | dt: 319.77ms | tok/sec:  51236.47\n",
      "step241 | loss: 4.689193248748779 | dt: 319.67ms | tok/sec:  51253.43\n",
      "step242 | loss: 4.84143590927124 | dt: 319.69ms | tok/sec:  51249.19\n",
      "step243 | loss: 4.765905380249023 | dt: 320.65ms | tok/sec:  51096.08\n",
      "step244 | loss: 4.7180867195129395 | dt: 319.00ms | tok/sec:  51361.00\n",
      "step245 | loss: 4.730320930480957 | dt: 320.49ms | tok/sec:  51121.32\n",
      "step246 | loss: 5.059233665466309 | dt: 320.53ms | tok/sec:  51114.59\n",
      "step247 | loss: 4.944089889526367 | dt: 319.35ms | tok/sec:  51304.86\n",
      "step248 | loss: 4.93656063079834 | dt: 320.51ms | tok/sec:  51119.15\n",
      "step249 | loss: 4.895112037658691 | dt: 320.56ms | tok/sec:  51110.07\n",
      "step250 | loss: 4.836836814880371 | dt: 319.16ms | tok/sec:  51334.26\n",
      "step251 | loss: 4.835473537445068 | dt: 320.43ms | tok/sec:  51130.60\n",
      "step252 | loss: 4.7891035079956055 | dt: 319.32ms | tok/sec:  51309.04\n",
      "step253 | loss: 4.948111534118652 | dt: 320.42ms | tok/sec:  51133.23\n",
      "step254 | loss: 5.12017822265625 | dt: 319.63ms | tok/sec:  51260.01\n",
      "step255 | loss: 4.978427886962891 | dt: 320.54ms | tok/sec:  51113.34\n",
      "step256 | loss: 4.816043376922607 | dt: 320.41ms | tok/sec:  51134.52\n",
      "step257 | loss: 4.67710018157959 | dt: 320.57ms | tok/sec:  51108.85\n",
      "step258 | loss: 4.903940677642822 | dt: 319.24ms | tok/sec:  51321.49\n",
      "step259 | loss: 4.638767719268799 | dt: 320.46ms | tok/sec:  51126.38\n",
      "step260 | loss: 5.010835647583008 | dt: 319.86ms | tok/sec:  51222.49\n",
      "step261 | loss: 4.649806976318359 | dt: 320.66ms | tok/sec:  51093.95\n",
      "step262 | loss: 4.814743995666504 | dt: 320.19ms | tok/sec:  51169.17\n",
      "step263 | loss: 4.715546607971191 | dt: 319.71ms | tok/sec:  51246.82\n",
      "step264 | loss: 4.64696741104126 | dt: 319.96ms | tok/sec:  51207.07\n",
      "step265 | loss: 4.708004951477051 | dt: 320.36ms | tok/sec:  51142.05\n",
      "step266 | loss: 4.998505592346191 | dt: 319.53ms | tok/sec:  51276.04\n",
      "step267 | loss: 4.836651802062988 | dt: 320.59ms | tok/sec:  51106.23\n",
      "step268 | loss: 4.892258644104004 | dt: 319.63ms | tok/sec:  51259.02\n",
      "step269 | loss: 4.8540802001953125 | dt: 320.36ms | tok/sec:  51141.67\n",
      "step270 | loss: 4.8607025146484375 | dt: 319.90ms | tok/sec:  51216.30\n",
      "step271 | loss: 4.804898738861084 | dt: 319.34ms | tok/sec:  51306.32\n",
      "step272 | loss: 4.795624732971191 | dt: 320.28ms | tok/sec:  51154.47\n",
      "step273 | loss: 4.998499870300293 | dt: 320.31ms | tok/sec:  51150.43\n",
      "step274 | loss: 5.1200432777404785 | dt: 320.31ms | tok/sec:  51150.35\n",
      "step275 | loss: 4.9179792404174805 | dt: 320.20ms | tok/sec:  51168.18\n",
      "step276 | loss: 4.7465901374816895 | dt: 319.92ms | tok/sec:  51212.87\n",
      "step277 | loss: 4.641100883483887 | dt: 320.50ms | tok/sec:  51120.52\n",
      "step278 | loss: 4.82366943359375 | dt: 320.31ms | tok/sec:  51149.93\n",
      "step279 | loss: 4.630477428436279 | dt: 320.47ms | tok/sec:  51125.09\n",
      "step280 | loss: 5.009579658508301 | dt: 320.32ms | tok/sec:  51148.41\n",
      "step281 | loss: 4.637963771820068 | dt: 319.67ms | tok/sec:  51252.36\n",
      "step282 | loss: 4.772361755371094 | dt: 319.28ms | tok/sec:  51315.63\n",
      "step283 | loss: 4.675957202911377 | dt: 319.74ms | tok/sec:  51241.28\n",
      "step284 | loss: 4.601571083068848 | dt: 319.44ms | tok/sec:  51289.43\n",
      "step285 | loss: 4.64188814163208 | dt: 319.49ms | tok/sec:  51281.39\n",
      "step286 | loss: 4.921022891998291 | dt: 320.54ms | tok/sec:  51113.56\n",
      "step287 | loss: 4.783396244049072 | dt: 319.09ms | tok/sec:  51346.30\n",
      "step288 | loss: 4.827518463134766 | dt: 320.52ms | tok/sec:  51117.21\n",
      "step289 | loss: 4.752490520477295 | dt: 320.09ms | tok/sec:  51185.33\n",
      "step290 | loss: 4.691906929016113 | dt: 319.37ms | tok/sec:  51300.57\n",
      "step291 | loss: 4.727074146270752 | dt: 320.56ms | tok/sec:  51110.48\n",
      "step292 | loss: 4.655154228210449 | dt: 319.86ms | tok/sec:  51223.18\n",
      "step293 | loss: 4.859676361083984 | dt: 318.86ms | tok/sec:  51383.77\n",
      "step294 | loss: 5.046869277954102 | dt: 320.43ms | tok/sec:  51131.13\n",
      "step295 | loss: 4.873991012573242 | dt: 320.55ms | tok/sec:  51112.54\n",
      "step296 | loss: 4.645326614379883 | dt: 319.55ms | tok/sec:  51272.13\n",
      "step297 | loss: 4.512204170227051 | dt: 320.14ms | tok/sec:  51177.09\n",
      "step298 | loss: 4.7136054039001465 | dt: 320.63ms | tok/sec:  51099.88\n",
      "step299 | loss: 4.508171081542969 | dt: 320.49ms | tok/sec:  51121.32\n",
      "step300 | loss: 4.842348098754883 | dt: 318.91ms | tok/sec:  51374.36\n",
      "step301 | loss: 4.511519432067871 | dt: 319.87ms | tok/sec:  51221.23\n",
      "step302 | loss: 4.677712440490723 | dt: 319.41ms | tok/sec:  51293.99\n",
      "step303 | loss: 4.579127788543701 | dt: 319.91ms | tok/sec:  51214.59\n",
      "step304 | loss: 4.517482280731201 | dt: 320.60ms | tok/sec:  51103.91\n",
      "step305 | loss: 4.578020095825195 | dt: 320.64ms | tok/sec:  51097.45\n",
      "step306 | loss: 4.855836868286133 | dt: 319.50ms | tok/sec:  51280.59\n",
      "step307 | loss: 4.687087535858154 | dt: 320.74ms | tok/sec:  51081.08\n",
      "step308 | loss: 4.734899520874023 | dt: 320.15ms | tok/sec:  51175.23\n",
      "step309 | loss: 4.669538497924805 | dt: 318.91ms | tok/sec:  51375.40\n",
      "step310 | loss: 4.624204635620117 | dt: 320.23ms | tok/sec:  51162.81\n",
      "step311 | loss: 4.633654594421387 | dt: 320.76ms | tok/sec:  51078.99\n",
      "step312 | loss: 4.567581653594971 | dt: 319.01ms | tok/sec:  51359.46\n",
      "step313 | loss: 4.764101982116699 | dt: 320.39ms | tok/sec:  51137.60\n",
      "step314 | loss: 4.959218978881836 | dt: 319.17ms | tok/sec:  51333.68\n",
      "step315 | loss: 4.781915664672852 | dt: 319.51ms | tok/sec:  51278.52\n",
      "step316 | loss: 4.559237480163574 | dt: 319.81ms | tok/sec:  51230.62\n",
      "step317 | loss: 4.45660400390625 | dt: 319.14ms | tok/sec:  51338.71\n",
      "step318 | loss: 4.637454032897949 | dt: 320.28ms | tok/sec:  51155.76\n",
      "step319 | loss: 4.414292335510254 | dt: 320.46ms | tok/sec:  51126.19\n",
      "step320 | loss: 4.767433166503906 | dt: 319.68ms | tok/sec:  51250.72\n",
      "step321 | loss: 4.4462761878967285 | dt: 320.03ms | tok/sec:  51195.28\n",
      "step322 | loss: 4.618174076080322 | dt: 320.39ms | tok/sec:  51137.98\n",
      "step323 | loss: 4.500027179718018 | dt: 319.28ms | tok/sec:  51315.40\n",
      "step324 | loss: 4.448539733886719 | dt: 319.20ms | tok/sec:  51329.12\n",
      "step325 | loss: 4.49920654296875 | dt: 320.65ms | tok/sec:  51095.51\n",
      "step326 | loss: 4.791126728057861 | dt: 319.53ms | tok/sec:  51275.19\n",
      "step327 | loss: 4.613860607147217 | dt: 320.60ms | tok/sec:  51103.57\n",
      "step328 | loss: 4.676556587219238 | dt: 319.65ms | tok/sec:  51256.80\n",
      "step329 | loss: 4.596299648284912 | dt: 319.71ms | tok/sec:  51246.48\n",
      "step330 | loss: 4.547680854797363 | dt: 319.42ms | tok/sec:  51292.19\n",
      "step331 | loss: 4.584568977355957 | dt: 320.68ms | tok/sec:  51092.21\n",
      "step332 | loss: 4.530196189880371 | dt: 319.54ms | tok/sec:  51273.78\n",
      "step333 | loss: 4.725377082824707 | dt: 320.50ms | tok/sec:  51120.83\n",
      "step334 | loss: 4.906525611877441 | dt: 320.34ms | tok/sec:  51146.17\n",
      "step335 | loss: 4.7205095291137695 | dt: 319.91ms | tok/sec:  51214.93\n",
      "step336 | loss: 4.483189582824707 | dt: 319.75ms | tok/sec:  51240.78\n",
      "step337 | loss: 4.365826606750488 | dt: 320.56ms | tok/sec:  51110.60\n",
      "step338 | loss: 4.547172546386719 | dt: 319.08ms | tok/sec:  51347.11\n",
      "step339 | loss: 4.3365068435668945 | dt: 319.61ms | tok/sec:  51262.88\n",
      "step340 | loss: 4.728512763977051 | dt: 319.44ms | tok/sec:  51289.89\n",
      "step341 | loss: 4.387704849243164 | dt: 320.46ms | tok/sec:  51126.11\n",
      "step342 | loss: 4.533127784729004 | dt: 319.10ms | tok/sec:  51344.58\n",
      "step343 | loss: 4.418802261352539 | dt: 320.32ms | tok/sec:  51148.91\n",
      "step344 | loss: 4.377713203430176 | dt: 320.04ms | tok/sec:  51194.17\n",
      "step345 | loss: 4.450244903564453 | dt: 320.31ms | tok/sec:  51151.15\n",
      "step346 | loss: 4.702749252319336 | dt: 320.33ms | tok/sec:  51147.95\n",
      "step347 | loss: 4.5517191886901855 | dt: 319.24ms | tok/sec:  51321.91\n",
      "step348 | loss: 4.638169288635254 | dt: 319.91ms | tok/sec:  51214.43\n",
      "step349 | loss: 4.542414665222168 | dt: 320.64ms | tok/sec:  51098.32\n",
      "step350 | loss: 4.525459289550781 | dt: 320.17ms | tok/sec:  51172.86\n",
      "step351 | loss: 4.5429792404174805 | dt: 319.56ms | tok/sec:  51270.53\n",
      "step352 | loss: 4.441580772399902 | dt: 319.37ms | tok/sec:  51300.34\n",
      "step353 | loss: 4.675213813781738 | dt: 320.47ms | tok/sec:  51124.25\n",
      "step354 | loss: 4.854019641876221 | dt: 319.77ms | tok/sec:  51236.93\n",
      "step355 | loss: 4.670114994049072 | dt: 320.64ms | tok/sec:  51097.45\n",
      "step356 | loss: 4.4490227699279785 | dt: 320.45ms | tok/sec:  51128.47\n",
      "step357 | loss: 4.351680278778076 | dt: 319.47ms | tok/sec:  51285.22\n",
      "step358 | loss: 4.520113945007324 | dt: 320.14ms | tok/sec:  51178.20\n",
      "step359 | loss: 4.292202949523926 | dt: 320.81ms | tok/sec:  51070.11\n",
      "step360 | loss: 4.638816833496094 | dt: 319.13ms | tok/sec:  51339.17\n",
      "step361 | loss: 4.3460612297058105 | dt: 320.87ms | tok/sec:  51060.73\n",
      "step362 | loss: 4.513497352600098 | dt: 320.79ms | tok/sec:  51073.30\n",
      "step363 | loss: 4.363224983215332 | dt: 319.54ms | tok/sec:  51273.51\n",
      "step364 | loss: 4.314284324645996 | dt: 319.29ms | tok/sec:  51314.48\n",
      "step365 | loss: 4.3987274169921875 | dt: 320.75ms | tok/sec:  51080.77\n",
      "step366 | loss: 4.6823272705078125 | dt: 319.20ms | tok/sec:  51328.35\n",
      "step367 | loss: 4.5139946937561035 | dt: 320.62ms | tok/sec:  51100.26\n",
      "step368 | loss: 4.57003116607666 | dt: 320.46ms | tok/sec:  51126.80\n",
      "step369 | loss: 4.5228729248046875 | dt: 319.55ms | tok/sec:  51271.41\n",
      "step370 | loss: 4.448470592498779 | dt: 320.38ms | tok/sec:  51138.59\n",
      "step371 | loss: 4.489046573638916 | dt: 320.96ms | tok/sec:  51046.70\n",
      "step372 | loss: 4.42972469329834 | dt: 320.44ms | tok/sec:  51130.18\n",
      "step373 | loss: 4.6594390869140625 | dt: 321.22ms | tok/sec:  51005.33\n",
      "step374 | loss: 4.832216262817383 | dt: 320.65ms | tok/sec:  51096.84\n",
      "step375 | loss: 4.65017032623291 | dt: 320.57ms | tok/sec:  51108.74\n",
      "step376 | loss: 4.453824043273926 | dt: 320.62ms | tok/sec:  51101.10\n",
      "step377 | loss: 4.3036603927612305 | dt: 320.80ms | tok/sec:  51071.59\n",
      "step378 | loss: 4.436779975891113 | dt: 319.60ms | tok/sec:  51263.80\n",
      "step379 | loss: 4.252751350402832 | dt: 320.41ms | tok/sec:  51134.22\n",
      "step380 | loss: 4.675268650054932 | dt: 319.98ms | tok/sec:  51202.60\n",
      "step381 | loss: 4.360403537750244 | dt: 320.70ms | tok/sec:  51088.83\n",
      "step382 | loss: 4.468945503234863 | dt: 320.34ms | tok/sec:  51145.90\n",
      "step383 | loss: 4.291691303253174 | dt: 320.49ms | tok/sec:  51121.24\n",
      "step384 | loss: 4.293454170227051 | dt: 319.48ms | tok/sec:  51284.03\n",
      "step385 | loss: 4.357016563415527 | dt: 320.86ms | tok/sec:  51062.94\n",
      "step386 | loss: 4.61478328704834 | dt: 319.55ms | tok/sec:  51271.64\n",
      "step387 | loss: 4.460741996765137 | dt: 320.47ms | tok/sec:  51124.74\n",
      "step388 | loss: 4.538917541503906 | dt: 320.30ms | tok/sec:  51152.33\n",
      "step389 | loss: 4.454036712646484 | dt: 320.80ms | tok/sec:  51071.55\n",
      "step390 | loss: 4.407451629638672 | dt: 319.58ms | tok/sec:  51267.73\n",
      "step391 | loss: 4.469771862030029 | dt: 320.61ms | tok/sec:  51102.88\n",
      "step392 | loss: 4.3828229904174805 | dt: 319.43ms | tok/sec:  51290.92\n",
      "step393 | loss: 4.565873146057129 | dt: 320.51ms | tok/sec:  51117.90\n",
      "step394 | loss: 4.769664287567139 | dt: 320.59ms | tok/sec:  51106.45\n",
      "step395 | loss: 4.597418785095215 | dt: 320.64ms | tok/sec:  51098.02\n",
      "step396 | loss: 4.352112770080566 | dt: 319.26ms | tok/sec:  51319.27\n",
      "step397 | loss: 4.228462219238281 | dt: 320.64ms | tok/sec:  51097.90\n",
      "step398 | loss: 4.428813457489014 | dt: 319.88ms | tok/sec:  51218.63\n",
      "step399 | loss: 4.201086521148682 | dt: 320.51ms | tok/sec:  51117.94\n",
      "step400 | loss: 4.545790195465088 | dt: 319.87ms | tok/sec:  51220.62\n",
      "step401 | loss: 4.26700496673584 | dt: 320.65ms | tok/sec:  51095.97\n",
      "step402 | loss: 4.417738914489746 | dt: 319.47ms | tok/sec:  51285.26\n",
      "step403 | loss: 4.271795272827148 | dt: 319.55ms | tok/sec:  51272.32\n",
      "step404 | loss: 4.2449212074279785 | dt: 320.08ms | tok/sec:  51187.16\n",
      "step405 | loss: 4.293720245361328 | dt: 320.70ms | tok/sec:  51087.80\n",
      "step406 | loss: 4.529223442077637 | dt: 319.08ms | tok/sec:  51347.68\n",
      "step407 | loss: 4.406710624694824 | dt: 320.63ms | tok/sec:  51098.63\n",
      "step408 | loss: 4.460548400878906 | dt: 319.91ms | tok/sec:  51213.75\n",
      "step409 | loss: 4.373940944671631 | dt: 320.55ms | tok/sec:  51111.81\n",
      "step410 | loss: 4.352280139923096 | dt: 319.37ms | tok/sec:  51300.92\n",
      "step411 | loss: 4.4164814949035645 | dt: 320.49ms | tok/sec:  51121.59\n",
      "step412 | loss: 4.327236175537109 | dt: 320.41ms | tok/sec:  51134.52\n",
      "step413 | loss: 4.5363450050354 | dt: 319.50ms | tok/sec:  51279.67\n",
      "step414 | loss: 4.713070869445801 | dt: 320.78ms | tok/sec:  51074.78\n",
      "step415 | loss: 4.543909549713135 | dt: 319.64ms | tok/sec:  51257.10\n",
      "step416 | loss: 4.309870719909668 | dt: 319.93ms | tok/sec:  51211.00\n",
      "step417 | loss: 4.184735298156738 | dt: 320.68ms | tok/sec:  51090.91\n",
      "step418 | loss: 4.353452682495117 | dt: 319.49ms | tok/sec:  51281.55\n",
      "step419 | loss: 4.129888534545898 | dt: 319.46ms | tok/sec:  51286.60\n",
      "step420 | loss: 4.549689769744873 | dt: 320.72ms | tok/sec:  51084.34\n",
      "step421 | loss: 4.224822521209717 | dt: 319.67ms | tok/sec:  51252.06\n",
      "step422 | loss: 4.356521129608154 | dt: 319.37ms | tok/sec:  51300.57\n",
      "step423 | loss: 4.252588272094727 | dt: 320.76ms | tok/sec:  51079.22\n",
      "step424 | loss: 4.224433898925781 | dt: 320.03ms | tok/sec:  51194.71\n",
      "step425 | loss: 4.286977767944336 | dt: 320.56ms | tok/sec:  51110.71\n",
      "step426 | loss: 4.514196395874023 | dt: 320.51ms | tok/sec:  51118.58\n",
      "step427 | loss: 4.374638080596924 | dt: 319.98ms | tok/sec:  51203.14\n",
      "step428 | loss: 4.468655586242676 | dt: 319.68ms | tok/sec:  51251.60\n",
      "step429 | loss: 4.359347343444824 | dt: 320.83ms | tok/sec:  51066.81\n",
      "step430 | loss: 4.309832572937012 | dt: 320.38ms | tok/sec:  51139.58\n",
      "step431 | loss: 4.3507232666015625 | dt: 320.68ms | tok/sec:  51091.33\n",
      "step432 | loss: 4.286041259765625 | dt: 319.61ms | tok/sec:  51262.42\n",
      "step433 | loss: 4.498156547546387 | dt: 320.41ms | tok/sec:  51134.33\n",
      "step434 | loss: 4.693060874938965 | dt: 320.52ms | tok/sec:  51117.21\n",
      "step435 | loss: 4.551843643188477 | dt: 320.81ms | tok/sec:  51070.30\n",
      "step436 | loss: 4.293333530426025 | dt: 320.37ms | tok/sec:  51141.60\n",
      "step437 | loss: 4.180176734924316 | dt: 320.33ms | tok/sec:  51147.23\n",
      "step438 | loss: 4.339761734008789 | dt: 320.81ms | tok/sec:  51070.07\n",
      "step439 | loss: 4.141157150268555 | dt: 320.34ms | tok/sec:  51145.67\n",
      "step440 | loss: 4.473172187805176 | dt: 320.81ms | tok/sec:  51070.22\n",
      "step441 | loss: 4.197616100311279 | dt: 320.79ms | tok/sec:  51074.51\n",
      "step442 | loss: 4.376539707183838 | dt: 319.40ms | tok/sec:  51296.44\n",
      "step443 | loss: 4.212498664855957 | dt: 320.35ms | tok/sec:  51144.34\n",
      "step444 | loss: 4.149158477783203 | dt: 320.21ms | tok/sec:  51166.39\n",
      "step445 | loss: 4.236252784729004 | dt: 320.51ms | tok/sec:  51117.90\n",
      "step446 | loss: 4.468229293823242 | dt: 319.54ms | tok/sec:  51274.47\n",
      "step447 | loss: 4.345470428466797 | dt: 320.41ms | tok/sec:  51135.17\n",
      "step448 | loss: 4.421822547912598 | dt: 320.33ms | tok/sec:  51147.76\n",
      "step449 | loss: 4.312379837036133 | dt: 320.41ms | tok/sec:  51134.79\n",
      "step450 | loss: 4.2945404052734375 | dt: 320.07ms | tok/sec:  51189.48\n",
      "step451 | loss: 4.318779468536377 | dt: 320.64ms | tok/sec:  51097.94\n",
      "step452 | loss: 4.250386714935303 | dt: 319.39ms | tok/sec:  51297.24\n",
      "step453 | loss: 4.47227668762207 | dt: 320.61ms | tok/sec:  51102.54\n",
      "step454 | loss: 4.65705680847168 | dt: 320.13ms | tok/sec:  51179.53\n",
      "step455 | loss: 4.469582557678223 | dt: 320.39ms | tok/sec:  51137.41\n",
      "step456 | loss: 4.260549545288086 | dt: 320.09ms | tok/sec:  51186.36\n",
      "step457 | loss: 4.15544319152832 | dt: 320.45ms | tok/sec:  51127.41\n",
      "step458 | loss: 4.260267734527588 | dt: 319.67ms | tok/sec:  51252.48\n",
      "step459 | loss: 4.057817459106445 | dt: 320.78ms | tok/sec:  51076.14\n",
      "step460 | loss: 4.493071556091309 | dt: 320.59ms | tok/sec:  51105.50\n",
      "step461 | loss: 4.16449499130249 | dt: 320.71ms | tok/sec:  51087.08\n",
      "step462 | loss: 4.29451847076416 | dt: 320.92ms | tok/sec:  51053.64\n",
      "step463 | loss: 4.172811508178711 | dt: 321.02ms | tok/sec:  51038.02\n",
      "step464 | loss: 4.141995429992676 | dt: 319.24ms | tok/sec:  51321.87\n",
      "step465 | loss: 4.203166484832764 | dt: 320.98ms | tok/sec:  51043.10\n",
      "step466 | loss: 4.464882850646973 | dt: 320.02ms | tok/sec:  51197.49\n",
      "step467 | loss: 4.289030075073242 | dt: 320.20ms | tok/sec:  51168.14\n",
      "step468 | loss: 4.3931989669799805 | dt: 320.04ms | tok/sec:  51193.68\n",
      "step469 | loss: 4.306602478027344 | dt: 320.93ms | tok/sec:  51051.40\n",
      "step470 | loss: 4.276608943939209 | dt: 319.21ms | tok/sec:  51326.51\n",
      "step471 | loss: 4.315485954284668 | dt: 320.27ms | tok/sec:  51156.64\n",
      "step472 | loss: 4.238193988800049 | dt: 319.71ms | tok/sec:  51246.75\n",
      "step473 | loss: 4.468898773193359 | dt: 320.71ms | tok/sec:  51087.08\n",
      "step474 | loss: 4.638187408447266 | dt: 319.77ms | tok/sec:  51236.89\n",
      "step475 | loss: 4.443356513977051 | dt: 319.72ms | tok/sec:  51244.80\n",
      "step476 | loss: 4.199769973754883 | dt: 320.62ms | tok/sec:  51101.17\n",
      "step477 | loss: 4.102545738220215 | dt: 320.41ms | tok/sec:  51134.71\n",
      "step478 | loss: 4.27313756942749 | dt: 319.93ms | tok/sec:  51211.23\n",
      "step479 | loss: 4.041408538818359 | dt: 320.73ms | tok/sec:  51083.51\n",
      "step480 | loss: 4.429612159729004 | dt: 320.81ms | tok/sec:  51070.03\n",
      "step481 | loss: 4.142025470733643 | dt: 320.70ms | tok/sec:  51088.83\n",
      "step482 | loss: 4.264873504638672 | dt: 319.88ms | tok/sec:  51218.86\n",
      "step483 | loss: 4.124558448791504 | dt: 320.69ms | tok/sec:  51089.13\n",
      "step484 | loss: 4.129319667816162 | dt: 320.66ms | tok/sec:  51094.26\n",
      "step485 | loss: 4.165827751159668 | dt: 319.93ms | tok/sec:  51210.88\n",
      "step486 | loss: 4.402381420135498 | dt: 320.00ms | tok/sec:  51199.63\n",
      "step487 | loss: 4.261214256286621 | dt: 320.44ms | tok/sec:  51129.46\n",
      "step488 | loss: 4.362567901611328 | dt: 320.59ms | tok/sec:  51105.43\n",
      "step489 | loss: 4.265127182006836 | dt: 320.14ms | tok/sec:  51176.90\n",
      "step490 | loss: 4.225703716278076 | dt: 320.41ms | tok/sec:  51134.41\n",
      "step491 | loss: 4.279979228973389 | dt: 320.83ms | tok/sec:  51066.88\n",
      "step492 | loss: 4.186509132385254 | dt: 320.56ms | tok/sec:  51111.09\n",
      "step493 | loss: 4.384979724884033 | dt: 320.57ms | tok/sec:  51109.61\n",
      "step494 | loss: 4.560851097106934 | dt: 320.17ms | tok/sec:  51172.33\n",
      "step495 | loss: 4.4052228927612305 | dt: 319.97ms | tok/sec:  51205.24\n",
      "step496 | loss: 4.161385536193848 | dt: 320.74ms | tok/sec:  51081.12\n",
      "step497 | loss: 4.054536819458008 | dt: 320.50ms | tok/sec:  51120.22\n",
      "step498 | loss: 4.197414875030518 | dt: 319.64ms | tok/sec:  51258.06\n",
      "step499 | loss: 3.9563398361206055 | dt: 320.91ms | tok/sec:  51054.44\n",
      "Prediction at step 500: \n",
      " : This is a fixed text used for prediction.sh doe and my lord.\n",
      "\n",
      "How \n",
      "\n",
      "step500 | loss: 4.372805595397949 | dt: 318.02ms | tok/sec:  51518.45\n",
      "step501 | loss: 4.084029197692871 | dt: 319.35ms | tok/sec:  51304.86\n",
      "step502 | loss: 4.2310285568237305 | dt: 320.28ms | tok/sec:  51155.80\n",
      "step503 | loss: 4.113715648651123 | dt: 320.91ms | tok/sec:  51055.42\n",
      "step504 | loss: 4.024665355682373 | dt: 319.90ms | tok/sec:  51216.57\n",
      "step505 | loss: 4.1046295166015625 | dt: 319.67ms | tok/sec:  51252.90\n",
      "step506 | loss: 4.331409931182861 | dt: 320.73ms | tok/sec:  51083.51\n",
      "step507 | loss: 4.197813510894775 | dt: 320.13ms | tok/sec:  51179.04\n",
      "step508 | loss: 4.296344757080078 | dt: 319.27ms | tok/sec:  51317.62\n",
      "step509 | loss: 4.204806804656982 | dt: 320.80ms | tok/sec:  51072.65\n",
      "step510 | loss: 4.142740249633789 | dt: 319.60ms | tok/sec:  51263.30\n",
      "step511 | loss: 4.218912124633789 | dt: 320.78ms | tok/sec:  51075.88\n",
      "step512 | loss: 4.175359725952148 | dt: 319.97ms | tok/sec:  51204.78\n",
      "step513 | loss: 4.359755039215088 | dt: 320.86ms | tok/sec:  51063.16\n",
      "step514 | loss: 4.523202419281006 | dt: 320.76ms | tok/sec:  51078.19\n",
      "step515 | loss: 4.35233736038208 | dt: 319.78ms | tok/sec:  51236.01\n",
      "step516 | loss: 4.131495475769043 | dt: 319.85ms | tok/sec:  51224.36\n",
      "step517 | loss: 4.015769958496094 | dt: 320.62ms | tok/sec:  51100.98\n",
      "step518 | loss: 4.149252891540527 | dt: 319.50ms | tok/sec:  51279.63\n",
      "step519 | loss: 3.9120447635650635 | dt: 320.84ms | tok/sec:  51066.12\n",
      "step520 | loss: 4.316704273223877 | dt: 320.22ms | tok/sec:  51165.59\n",
      "step521 | loss: 4.063579559326172 | dt: 319.86ms | tok/sec:  51222.41\n",
      "step522 | loss: 4.19435453414917 | dt: 319.60ms | tok/sec:  51264.29\n",
      "step523 | loss: 4.048972129821777 | dt: 321.07ms | tok/sec:  51029.34\n",
      "step524 | loss: 4.035193920135498 | dt: 320.76ms | tok/sec:  51078.19\n",
      "step525 | loss: 4.084217071533203 | dt: 320.70ms | tok/sec:  51088.37\n",
      "step526 | loss: 4.2837018966674805 | dt: 319.95ms | tok/sec:  51207.79\n",
      "step527 | loss: 4.1368513107299805 | dt: 321.01ms | tok/sec:  51039.00\n",
      "step528 | loss: 4.299574851989746 | dt: 319.50ms | tok/sec:  51280.17\n",
      "step529 | loss: 4.261713027954102 | dt: 320.34ms | tok/sec:  51145.06\n",
      "step530 | loss: 4.130331039428711 | dt: 320.92ms | tok/sec:  51053.00\n",
      "step531 | loss: 4.169083595275879 | dt: 319.47ms | tok/sec:  51284.15\n",
      "step532 | loss: 4.095170974731445 | dt: 319.45ms | tok/sec:  51288.36\n",
      "step533 | loss: 4.335136413574219 | dt: 320.62ms | tok/sec:  51101.48\n",
      "step534 | loss: 4.515159606933594 | dt: 319.28ms | tok/sec:  51315.05\n",
      "step535 | loss: 4.312489032745361 | dt: 319.82ms | tok/sec:  51228.68\n",
      "step536 | loss: 4.064028263092041 | dt: 321.26ms | tok/sec:  50998.82\n",
      "step537 | loss: 3.969640016555786 | dt: 320.62ms | tok/sec:  51100.30\n",
      "step538 | loss: 4.116704940795898 | dt: 319.58ms | tok/sec:  51266.70\n",
      "step539 | loss: 3.8873367309570312 | dt: 321.85ms | tok/sec:  50905.99\n",
      "step540 | loss: 4.273210525512695 | dt: 319.66ms | tok/sec:  51254.66\n",
      "step541 | loss: 3.987725257873535 | dt: 321.45ms | tok/sec:  50969.20\n",
      "step542 | loss: 4.134502410888672 | dt: 319.82ms | tok/sec:  51228.83\n",
      "step543 | loss: 4.031973838806152 | dt: 320.58ms | tok/sec:  51106.76\n",
      "step544 | loss: 3.9922409057617188 | dt: 320.19ms | tok/sec:  51169.13\n",
      "step545 | loss: 4.040820121765137 | dt: 319.92ms | tok/sec:  51212.87\n",
      "step546 | loss: 4.24906063079834 | dt: 319.77ms | tok/sec:  51236.89\n",
      "step547 | loss: 4.14011287689209 | dt: 319.91ms | tok/sec:  51215.05\n",
      "step548 | loss: 4.248354911804199 | dt: 320.20ms | tok/sec:  51168.22\n",
      "step549 | loss: 4.145689964294434 | dt: 320.77ms | tok/sec:  51076.56\n",
      "step550 | loss: 4.128388404846191 | dt: 320.61ms | tok/sec:  51103.03\n",
      "step551 | loss: 4.15522575378418 | dt: 320.38ms | tok/sec:  51138.71\n",
      "step552 | loss: 4.048275947570801 | dt: 319.69ms | tok/sec:  51250.34\n",
      "step553 | loss: 4.266696929931641 | dt: 321.20ms | tok/sec:  51009.30\n",
      "step554 | loss: 4.44196081161499 | dt: 319.64ms | tok/sec:  51257.52\n",
      "step555 | loss: 4.296384334564209 | dt: 320.29ms | tok/sec:  51153.32\n",
      "step556 | loss: 4.058027744293213 | dt: 319.70ms | tok/sec:  51248.77\n",
      "step557 | loss: 3.9356091022491455 | dt: 320.72ms | tok/sec:  51084.61\n",
      "step558 | loss: 4.112496376037598 | dt: 319.98ms | tok/sec:  51203.18\n",
      "step559 | loss: 3.865083694458008 | dt: 319.95ms | tok/sec:  51208.52\n",
      "step560 | loss: 4.2362895011901855 | dt: 319.91ms | tok/sec:  51214.32\n",
      "step561 | loss: 3.966620922088623 | dt: 320.76ms | tok/sec:  51077.93\n",
      "step562 | loss: 4.068809509277344 | dt: 320.42ms | tok/sec:  51132.66\n",
      "step563 | loss: 3.9627931118011475 | dt: 320.93ms | tok/sec:  51052.16\n",
      "step564 | loss: 3.944672107696533 | dt: 320.48ms | tok/sec:  51123.83\n",
      "step565 | loss: 3.9720661640167236 | dt: 320.73ms | tok/sec:  51082.67\n",
      "step566 | loss: 4.2237162590026855 | dt: 319.91ms | tok/sec:  51214.24\n",
      "step567 | loss: 4.06870174407959 | dt: 320.95ms | tok/sec:  51049.20\n",
      "step568 | loss: 4.199192047119141 | dt: 319.57ms | tok/sec:  51268.77\n",
      "step569 | loss: 4.075479507446289 | dt: 319.80ms | tok/sec:  51232.27\n",
      "step570 | loss: 4.024775505065918 | dt: 320.24ms | tok/sec:  51160.98\n",
      "step571 | loss: 4.07900333404541 | dt: 319.90ms | tok/sec:  51216.11\n",
      "step572 | loss: 3.9865238666534424 | dt: 320.10ms | tok/sec:  51183.88\n",
      "step573 | loss: 4.203534126281738 | dt: 320.05ms | tok/sec:  51191.70\n",
      "step574 | loss: 4.362414360046387 | dt: 320.60ms | tok/sec:  51104.48\n",
      "step575 | loss: 4.238645553588867 | dt: 320.78ms | tok/sec:  51075.42\n",
      "step576 | loss: 3.9661519527435303 | dt: 319.87ms | tok/sec:  51220.43\n",
      "step577 | loss: 3.8864941596984863 | dt: 320.03ms | tok/sec:  51194.52\n",
      "step578 | loss: 4.036025524139404 | dt: 320.21ms | tok/sec:  51167.07\n",
      "step579 | loss: 3.822680950164795 | dt: 319.54ms | tok/sec:  51274.01\n",
      "step580 | loss: 4.231253147125244 | dt: 319.55ms | tok/sec:  51272.25\n",
      "step581 | loss: 3.8957109451293945 | dt: 320.32ms | tok/sec:  51148.98\n",
      "step582 | loss: 4.030100345611572 | dt: 319.35ms | tok/sec:  51304.86\n",
      "step583 | loss: 3.9962990283966064 | dt: 320.66ms | tok/sec:  51095.24\n",
      "step584 | loss: 3.947312355041504 | dt: 320.26ms | tok/sec:  51158.01\n",
      "step585 | loss: 3.930919647216797 | dt: 320.30ms | tok/sec:  51152.41\n",
      "step586 | loss: 4.1737775802612305 | dt: 320.36ms | tok/sec:  51142.40\n",
      "step587 | loss: 4.039999961853027 | dt: 320.48ms | tok/sec:  51123.22\n",
      "step588 | loss: 4.107336044311523 | dt: 319.52ms | tok/sec:  51276.72\n",
      "step589 | loss: 4.016746520996094 | dt: 321.06ms | tok/sec:  51030.59\n",
      "step590 | loss: 3.98378324508667 | dt: 319.27ms | tok/sec:  51316.32\n",
      "step591 | loss: 4.027274131774902 | dt: 320.14ms | tok/sec:  51177.48\n",
      "step592 | loss: 3.924583911895752 | dt: 319.79ms | tok/sec:  51233.53\n",
      "step593 | loss: 4.139103889465332 | dt: 320.14ms | tok/sec:  51177.86\n",
      "step594 | loss: 4.283099174499512 | dt: 319.20ms | tok/sec:  51328.54\n",
      "step595 | loss: 4.159457206726074 | dt: 320.84ms | tok/sec:  51065.48\n",
      "step596 | loss: 3.954803228378296 | dt: 319.48ms | tok/sec:  51283.80\n",
      "step597 | loss: 3.835402488708496 | dt: 320.30ms | tok/sec:  51151.80\n",
      "step598 | loss: 3.968125581741333 | dt: 320.06ms | tok/sec:  51190.36\n",
      "step599 | loss: 3.7562856674194336 | dt: 320.26ms | tok/sec:  51159.23\n",
      "step600 | loss: 4.196423530578613 | dt: 320.45ms | tok/sec:  51127.90\n",
      "step601 | loss: 3.867933511734009 | dt: 319.92ms | tok/sec:  51212.79\n",
      "step602 | loss: 3.9762160778045654 | dt: 320.07ms | tok/sec:  51189.45\n",
      "step603 | loss: 3.891937732696533 | dt: 320.22ms | tok/sec:  51165.55\n",
      "step604 | loss: 3.8798296451568604 | dt: 319.44ms | tok/sec:  51290.43\n",
      "step605 | loss: 3.8732705116271973 | dt: 320.93ms | tok/sec:  51051.02\n",
      "step606 | loss: 4.079103946685791 | dt: 319.67ms | tok/sec:  51252.29\n",
      "step607 | loss: 3.967554807662964 | dt: 320.53ms | tok/sec:  51115.20\n",
      "step608 | loss: 4.063055992126465 | dt: 320.14ms | tok/sec:  51177.29\n",
      "step609 | loss: 3.955838680267334 | dt: 320.92ms | tok/sec:  51053.53\n",
      "step610 | loss: 3.9260952472686768 | dt: 319.58ms | tok/sec:  51267.85\n",
      "step611 | loss: 3.9853978157043457 | dt: 320.84ms | tok/sec:  51066.58\n",
      "step612 | loss: 3.9033749103546143 | dt: 319.54ms | tok/sec:  51272.94\n",
      "step613 | loss: 4.094888210296631 | dt: 320.33ms | tok/sec:  51147.57\n",
      "step614 | loss: 4.203516483306885 | dt: 320.01ms | tok/sec:  51197.68\n",
      "step615 | loss: 4.077672958374023 | dt: 320.78ms | tok/sec:  51074.81\n",
      "step616 | loss: 3.8535594940185547 | dt: 319.37ms | tok/sec:  51301.03\n",
      "step617 | loss: 3.7636241912841797 | dt: 320.93ms | tok/sec:  51052.16\n",
      "step618 | loss: 3.90791916847229 | dt: 320.83ms | tok/sec:  51067.15\n",
      "step619 | loss: 3.707750082015991 | dt: 319.91ms | tok/sec:  51214.59\n",
      "step620 | loss: 4.119345188140869 | dt: 319.64ms | tok/sec:  51258.17\n",
      "step621 | loss: 3.818882465362549 | dt: 320.27ms | tok/sec:  51156.64\n",
      "step622 | loss: 3.940138816833496 | dt: 320.09ms | tok/sec:  51184.87\n",
      "step623 | loss: 3.8616654872894287 | dt: 319.78ms | tok/sec:  51235.89\n",
      "step624 | loss: 3.829437255859375 | dt: 320.05ms | tok/sec:  51192.42\n",
      "step625 | loss: 3.779362678527832 | dt: 320.23ms | tok/sec:  51163.30\n",
      "step626 | loss: 4.003847122192383 | dt: 319.43ms | tok/sec:  51292.00\n",
      "step627 | loss: 3.916196346282959 | dt: 320.44ms | tok/sec:  51129.65\n",
      "step628 | loss: 4.007236480712891 | dt: 319.64ms | tok/sec:  51257.33\n",
      "step629 | loss: 3.906778573989868 | dt: 320.69ms | tok/sec:  51089.40\n",
      "step630 | loss: 3.8977699279785156 | dt: 319.45ms | tok/sec:  51288.24\n",
      "step631 | loss: 3.951200008392334 | dt: 319.80ms | tok/sec:  51231.23\n",
      "step632 | loss: 3.8582611083984375 | dt: 319.76ms | tok/sec:  51239.18\n",
      "step633 | loss: 4.066641330718994 | dt: 320.39ms | tok/sec:  51137.98\n",
      "step634 | loss: 4.233294486999512 | dt: 319.43ms | tok/sec:  51290.81\n",
      "step635 | loss: 4.069705009460449 | dt: 319.66ms | tok/sec:  51254.05\n",
      "step636 | loss: 3.8430087566375732 | dt: 319.64ms | tok/sec:  51256.87\n",
      "step637 | loss: 3.718860149383545 | dt: 320.50ms | tok/sec:  51120.86\n",
      "step638 | loss: 3.8318471908569336 | dt: 319.47ms | tok/sec:  51284.72\n",
      "step639 | loss: 3.656492233276367 | dt: 321.03ms | tok/sec:  51035.06\n",
      "step640 | loss: 4.096461772918701 | dt: 319.95ms | tok/sec:  51208.71\n",
      "step641 | loss: 3.7623398303985596 | dt: 320.65ms | tok/sec:  51096.42\n",
      "step642 | loss: 3.886692523956299 | dt: 319.91ms | tok/sec:  51213.79\n",
      "step643 | loss: 3.8355653285980225 | dt: 320.59ms | tok/sec:  51105.73\n",
      "step644 | loss: 3.7800533771514893 | dt: 319.91ms | tok/sec:  51214.55\n",
      "step645 | loss: 3.735596179962158 | dt: 319.52ms | tok/sec:  51277.26\n",
      "step646 | loss: 3.971738815307617 | dt: 319.40ms | tok/sec:  51296.74\n",
      "step647 | loss: 3.842170238494873 | dt: 320.20ms | tok/sec:  51168.25\n",
      "step648 | loss: 3.9637041091918945 | dt: 319.95ms | tok/sec:  51207.91\n",
      "step649 | loss: 3.8872876167297363 | dt: 319.76ms | tok/sec:  51238.95\n",
      "step650 | loss: 3.8267698287963867 | dt: 320.11ms | tok/sec:  51182.81\n",
      "step651 | loss: 3.8630242347717285 | dt: 319.65ms | tok/sec:  51255.54\n",
      "step652 | loss: 3.777226686477661 | dt: 319.94ms | tok/sec:  51209.82\n",
      "step653 | loss: 3.974992275238037 | dt: 320.31ms | tok/sec:  51151.15\n",
      "step654 | loss: 4.094476699829102 | dt: 319.62ms | tok/sec:  51260.28\n",
      "step655 | loss: 4.014009475708008 | dt: 320.75ms | tok/sec:  51079.94\n",
      "step656 | loss: 3.804641008377075 | dt: 320.25ms | tok/sec:  51160.79\n",
      "step657 | loss: 3.6550357341766357 | dt: 320.18ms | tok/sec:  51170.69\n",
      "step658 | loss: 3.7747318744659424 | dt: 319.39ms | tok/sec:  51298.12\n",
      "step659 | loss: 3.591801643371582 | dt: 320.64ms | tok/sec:  51097.45\n",
      "step660 | loss: 4.061638832092285 | dt: 319.99ms | tok/sec:  51201.99\n",
      "step661 | loss: 3.7297377586364746 | dt: 319.58ms | tok/sec:  51267.47\n",
      "step662 | loss: 3.8691065311431885 | dt: 320.10ms | tok/sec:  51184.41\n",
      "step663 | loss: 3.7862610816955566 | dt: 320.02ms | tok/sec:  51197.38\n",
      "step664 | loss: 3.7589328289031982 | dt: 319.54ms | tok/sec:  51273.74\n",
      "step665 | loss: 3.680758476257324 | dt: 320.16ms | tok/sec:  51174.81\n",
      "step666 | loss: 3.911717653274536 | dt: 320.01ms | tok/sec:  51199.10\n",
      "step667 | loss: 3.8174877166748047 | dt: 320.61ms | tok/sec:  51101.89\n",
      "step668 | loss: 3.9021077156066895 | dt: 319.55ms | tok/sec:  51271.33\n",
      "step669 | loss: 3.8394837379455566 | dt: 319.86ms | tok/sec:  51222.60\n",
      "step670 | loss: 3.7792186737060547 | dt: 319.48ms | tok/sec:  51283.15\n",
      "step671 | loss: 3.7916531562805176 | dt: 320.13ms | tok/sec:  51179.84\n",
      "step672 | loss: 3.689023494720459 | dt: 319.93ms | tok/sec:  51210.62\n",
      "step673 | loss: 3.910846710205078 | dt: 320.44ms | tok/sec:  51129.88\n",
      "step674 | loss: 3.9979593753814697 | dt: 319.29ms | tok/sec:  51313.29\n",
      "step675 | loss: 3.8917183876037598 | dt: 320.69ms | tok/sec:  51090.53\n",
      "step676 | loss: 3.695237159729004 | dt: 319.87ms | tok/sec:  51220.73\n",
      "step677 | loss: 3.6281070709228516 | dt: 320.21ms | tok/sec:  51165.63\n",
      "step678 | loss: 3.700310707092285 | dt: 319.48ms | tok/sec:  51283.50\n",
      "step679 | loss: 3.4898157119750977 | dt: 320.35ms | tok/sec:  51143.58\n",
      "step680 | loss: 3.92022705078125 | dt: 319.86ms | tok/sec:  51222.83\n",
      "step681 | loss: 3.6398062705993652 | dt: 320.34ms | tok/sec:  51145.67\n",
      "step682 | loss: 3.7484495639801025 | dt: 319.61ms | tok/sec:  51262.34\n",
      "step683 | loss: 3.647785186767578 | dt: 319.96ms | tok/sec:  51205.96\n",
      "step684 | loss: 3.6037826538085938 | dt: 320.48ms | tok/sec:  51123.68\n",
      "step685 | loss: 3.607168674468994 | dt: 319.70ms | tok/sec:  51247.36\n",
      "step686 | loss: 3.8323252201080322 | dt: 319.69ms | tok/sec:  51249.54\n",
      "step687 | loss: 3.715233564376831 | dt: 320.56ms | tok/sec:  51110.45\n",
      "step688 | loss: 3.8246655464172363 | dt: 319.34ms | tok/sec:  51305.32\n",
      "step689 | loss: 3.7619481086730957 | dt: 320.47ms | tok/sec:  51124.59\n",
      "step690 | loss: 3.706530809402466 | dt: 319.32ms | tok/sec:  51309.69\n",
      "step691 | loss: 3.753019094467163 | dt: 320.30ms | tok/sec:  51151.99\n",
      "step692 | loss: 3.667468547821045 | dt: 319.40ms | tok/sec:  51295.59\n",
      "step693 | loss: 3.8447394371032715 | dt: 320.59ms | tok/sec:  51105.66\n",
      "step694 | loss: 3.948821544647217 | dt: 320.15ms | tok/sec:  51176.56\n",
      "step695 | loss: 3.839550018310547 | dt: 319.72ms | tok/sec:  51244.91\n",
      "step696 | loss: 3.6562137603759766 | dt: 320.73ms | tok/sec:  51083.62\n",
      "step697 | loss: 3.574028491973877 | dt: 320.86ms | tok/sec:  51062.63\n",
      "step698 | loss: 3.7130651473999023 | dt: 320.00ms | tok/sec:  51199.59\n",
      "step699 | loss: 3.455587387084961 | dt: 320.59ms | tok/sec:  51106.26\n",
      "step700 | loss: 3.893051862716675 | dt: 319.52ms | tok/sec:  51276.61\n",
      "step701 | loss: 3.612809181213379 | dt: 319.39ms | tok/sec:  51297.24\n",
      "step702 | loss: 3.703730821609497 | dt: 320.15ms | tok/sec:  51175.99\n",
      "step703 | loss: 3.636704444885254 | dt: 320.29ms | tok/sec:  51153.17\n",
      "step704 | loss: 3.600912094116211 | dt: 320.46ms | tok/sec:  51126.87\n",
      "step705 | loss: 3.5497162342071533 | dt: 320.66ms | tok/sec:  51094.79\n",
      "step706 | loss: 3.769761800765991 | dt: 319.30ms | tok/sec:  51312.06\n",
      "step707 | loss: 3.662761688232422 | dt: 320.52ms | tok/sec:  51117.02\n",
      "step708 | loss: 3.814289093017578 | dt: 320.17ms | tok/sec:  51172.25\n",
      "step709 | loss: 3.7085928916931152 | dt: 320.82ms | tok/sec:  51068.78\n",
      "step710 | loss: 3.659989833831787 | dt: 320.85ms | tok/sec:  51063.81\n",
      "step711 | loss: 3.7338881492614746 | dt: 319.93ms | tok/sec:  51211.61\n",
      "step712 | loss: 3.6354990005493164 | dt: 319.70ms | tok/sec:  51248.31\n",
      "step713 | loss: 3.794053077697754 | dt: 320.58ms | tok/sec:  51106.99\n",
      "step714 | loss: 3.9066832065582275 | dt: 320.56ms | tok/sec:  51111.24\n",
      "step715 | loss: 3.79263973236084 | dt: 320.88ms | tok/sec:  51059.29\n",
      "step716 | loss: 3.600309371948242 | dt: 319.85ms | tok/sec:  51223.98\n",
      "step717 | loss: 3.5150177478790283 | dt: 319.95ms | tok/sec:  51207.60\n",
      "step718 | loss: 3.6607654094696045 | dt: 320.28ms | tok/sec:  51155.95\n",
      "step719 | loss: 3.465658664703369 | dt: 320.42ms | tok/sec:  51133.23\n",
      "step720 | loss: 3.947340965270996 | dt: 320.60ms | tok/sec:  51104.97\n",
      "step721 | loss: 3.6680703163146973 | dt: 320.77ms | tok/sec:  51077.55\n",
      "step722 | loss: 3.679266929626465 | dt: 319.61ms | tok/sec:  51262.23\n",
      "step723 | loss: 3.590023994445801 | dt: 320.61ms | tok/sec:  51101.89\n",
      "step724 | loss: 3.5621049404144287 | dt: 320.24ms | tok/sec:  51161.93\n",
      "step725 | loss: 3.541926622390747 | dt: 320.06ms | tok/sec:  51189.64\n",
      "step726 | loss: 3.7395997047424316 | dt: 321.51ms | tok/sec:  50959.67\n",
      "step727 | loss: 3.6189169883728027 | dt: 319.90ms | tok/sec:  51215.54\n",
      "step728 | loss: 3.7275166511535645 | dt: 321.21ms | tok/sec:  51007.14\n",
      "step729 | loss: 3.617379903793335 | dt: 320.48ms | tok/sec:  51123.22\n",
      "step730 | loss: 3.60117769241333 | dt: 320.14ms | tok/sec:  51177.32\n",
      "step731 | loss: 3.683389186859131 | dt: 320.66ms | tok/sec:  51094.41\n",
      "step732 | loss: 3.5787253379821777 | dt: 320.01ms | tok/sec:  51198.79\n",
      "step733 | loss: 3.723404884338379 | dt: 319.73ms | tok/sec:  51243.50\n",
      "step734 | loss: 3.8586158752441406 | dt: 320.92ms | tok/sec:  51052.54\n",
      "step735 | loss: 3.718844413757324 | dt: 319.86ms | tok/sec:  51222.49\n",
      "step736 | loss: 3.483671188354492 | dt: 319.56ms | tok/sec:  51271.02\n",
      "step737 | loss: 3.4029016494750977 | dt: 319.89ms | tok/sec:  51218.06\n",
      "step738 | loss: 3.6015329360961914 | dt: 320.20ms | tok/sec:  51167.91\n",
      "step739 | loss: 3.3657634258270264 | dt: 319.97ms | tok/sec:  51204.40\n",
      "step740 | loss: 3.7589526176452637 | dt: 319.60ms | tok/sec:  51263.68\n",
      "step741 | loss: 3.5363261699676514 | dt: 320.87ms | tok/sec:  51060.96\n",
      "step742 | loss: 3.5900044441223145 | dt: 319.50ms | tok/sec:  51279.67\n",
      "step743 | loss: 3.5276737213134766 | dt: 320.96ms | tok/sec:  51046.78\n",
      "step744 | loss: 3.521087646484375 | dt: 320.08ms | tok/sec:  51187.69\n",
      "step745 | loss: 3.4729342460632324 | dt: 320.57ms | tok/sec:  51108.62\n",
      "step746 | loss: 3.6946983337402344 | dt: 319.95ms | tok/sec:  51207.34\n",
      "step747 | loss: 3.5404653549194336 | dt: 320.96ms | tok/sec:  51046.74\n",
      "step748 | loss: 3.6061885356903076 | dt: 319.88ms | tok/sec:  51219.36\n",
      "step749 | loss: 3.550797462463379 | dt: 320.84ms | tok/sec:  51065.71\n",
      "step750 | loss: 3.538256883621216 | dt: 319.51ms | tok/sec:  51278.64\n",
      "step751 | loss: 3.5718846321105957 | dt: 319.63ms | tok/sec:  51259.47\n",
      "step752 | loss: 3.4859960079193115 | dt: 320.84ms | tok/sec:  51066.50\n",
      "step753 | loss: 3.7058348655700684 | dt: 321.15ms | tok/sec:  51017.25\n",
      "step754 | loss: 3.8394761085510254 | dt: 319.75ms | tok/sec:  51239.49\n",
      "step755 | loss: 3.6234984397888184 | dt: 319.98ms | tok/sec:  51203.56\n",
      "step756 | loss: 3.4009482860565186 | dt: 319.63ms | tok/sec:  51259.59\n",
      "step757 | loss: 3.33705472946167 | dt: 320.61ms | tok/sec:  51101.97\n",
      "step758 | loss: 3.4638001918792725 | dt: 320.70ms | tok/sec:  51088.07\n",
      "step759 | loss: 3.24895977973938 | dt: 320.02ms | tok/sec:  51196.08\n",
      "step760 | loss: 3.655933141708374 | dt: 319.72ms | tok/sec:  51245.06\n",
      "step761 | loss: 3.4043421745300293 | dt: 321.05ms | tok/sec:  51032.22\n",
      "step762 | loss: 3.5145671367645264 | dt: 320.81ms | tok/sec:  51070.52\n",
      "step763 | loss: 3.5128331184387207 | dt: 319.93ms | tok/sec:  51211.53\n",
      "step764 | loss: 3.455225706100464 | dt: 319.95ms | tok/sec:  51207.34\n",
      "step765 | loss: 3.3757715225219727 | dt: 320.96ms | tok/sec:  51046.28\n",
      "step766 | loss: 3.6118688583374023 | dt: 319.26ms | tok/sec:  51318.69\n",
      "step767 | loss: 3.505054235458374 | dt: 320.40ms | tok/sec:  51136.69\n",
      "step768 | loss: 3.6123528480529785 | dt: 319.65ms | tok/sec:  51255.88\n",
      "step769 | loss: 3.502922773361206 | dt: 319.78ms | tok/sec:  51235.51\n",
      "step770 | loss: 3.4649009704589844 | dt: 319.46ms | tok/sec:  51286.98\n",
      "step771 | loss: 3.532618522644043 | dt: 320.56ms | tok/sec:  51109.99\n",
      "step772 | loss: 3.4399044513702393 | dt: 319.79ms | tok/sec:  51234.06\n",
      "step773 | loss: 3.6595723628997803 | dt: 319.85ms | tok/sec:  51223.25\n",
      "step774 | loss: 3.696418285369873 | dt: 319.80ms | tok/sec:  51232.00\n",
      "step775 | loss: 3.5591671466827393 | dt: 321.02ms | tok/sec:  51037.34\n",
      "step776 | loss: 3.383798837661743 | dt: 319.92ms | tok/sec:  51212.34\n",
      "step777 | loss: 3.3085668087005615 | dt: 319.80ms | tok/sec:  51231.69\n",
      "step778 | loss: 3.4012341499328613 | dt: 320.15ms | tok/sec:  51175.46\n",
      "step779 | loss: 3.188647747039795 | dt: 321.13ms | tok/sec:  51019.57\n",
      "step780 | loss: 3.5578017234802246 | dt: 319.91ms | tok/sec:  51214.17\n",
      "step781 | loss: 3.3197126388549805 | dt: 320.60ms | tok/sec:  51104.33\n",
      "step782 | loss: 3.4109599590301514 | dt: 319.87ms | tok/sec:  51220.54\n",
      "step783 | loss: 3.3349502086639404 | dt: 320.59ms | tok/sec:  51106.53\n",
      "step784 | loss: 3.3128161430358887 | dt: 320.14ms | tok/sec:  51177.29\n",
      "step785 | loss: 3.3792717456817627 | dt: 319.61ms | tok/sec:  51262.34\n",
      "step786 | loss: 3.5303335189819336 | dt: 320.05ms | tok/sec:  51192.19\n",
      "step787 | loss: 3.3796632289886475 | dt: 320.84ms | tok/sec:  51066.24\n",
      "step788 | loss: 3.535210132598877 | dt: 320.10ms | tok/sec:  51184.15\n",
      "step789 | loss: 3.4553916454315186 | dt: 320.63ms | tok/sec:  51098.97\n",
      "step790 | loss: 3.442577838897705 | dt: 320.09ms | tok/sec:  51186.05\n",
      "step791 | loss: 3.4959163665771484 | dt: 320.73ms | tok/sec:  51083.96\n",
      "step792 | loss: 3.3990509510040283 | dt: 320.84ms | tok/sec:  51065.71\n",
      "step793 | loss: 3.569002151489258 | dt: 320.50ms | tok/sec:  51119.68\n",
      "step794 | loss: 3.5850391387939453 | dt: 319.65ms | tok/sec:  51255.80\n",
      "step795 | loss: 3.4845681190490723 | dt: 320.65ms | tok/sec:  51095.51\n",
      "step796 | loss: 3.312434196472168 | dt: 319.37ms | tok/sec:  51301.26\n",
      "step797 | loss: 3.279360294342041 | dt: 321.02ms | tok/sec:  51036.73\n",
      "step798 | loss: 3.4069318771362305 | dt: 319.47ms | tok/sec:  51284.49\n",
      "step799 | loss: 3.2054648399353027 | dt: 320.50ms | tok/sec:  51119.49\n",
      "step800 | loss: 3.626335382461548 | dt: 319.75ms | tok/sec:  51239.37\n",
      "step801 | loss: 3.2924749851226807 | dt: 319.79ms | tok/sec:  51233.11\n",
      "step802 | loss: 3.355008602142334 | dt: 319.85ms | tok/sec:  51223.79\n",
      "step803 | loss: 3.3060221672058105 | dt: 320.24ms | tok/sec:  51161.78\n",
      "step804 | loss: 3.2758848667144775 | dt: 319.48ms | tok/sec:  51283.65\n",
      "step805 | loss: 3.269327163696289 | dt: 319.90ms | tok/sec:  51215.88\n",
      "step806 | loss: 3.4368038177490234 | dt: 320.67ms | tok/sec:  51093.65\n",
      "step807 | loss: 3.3156235218048096 | dt: 320.98ms | tok/sec:  51044.05\n",
      "step808 | loss: 3.4226598739624023 | dt: 319.84ms | tok/sec:  51225.35\n",
      "step809 | loss: 3.33120059967041 | dt: 320.66ms | tok/sec:  51094.87\n",
      "step810 | loss: 3.319174289703369 | dt: 321.11ms | tok/sec:  51023.47\n",
      "step811 | loss: 3.394721031188965 | dt: 319.91ms | tok/sec:  51215.05\n",
      "step812 | loss: 3.2912323474884033 | dt: 320.05ms | tok/sec:  51192.42\n",
      "step813 | loss: 3.4285202026367188 | dt: 320.90ms | tok/sec:  51056.49\n",
      "step814 | loss: 3.562807083129883 | dt: 320.69ms | tok/sec:  51090.04\n",
      "step815 | loss: 3.398162841796875 | dt: 320.76ms | tok/sec:  51078.04\n",
      "step816 | loss: 3.1973342895507812 | dt: 320.14ms | tok/sec:  51176.98\n",
      "step817 | loss: 3.168369770050049 | dt: 320.02ms | tok/sec:  51196.58\n",
      "step818 | loss: 3.28131103515625 | dt: 320.17ms | tok/sec:  51173.55\n",
      "step819 | loss: 3.0700430870056152 | dt: 320.93ms | tok/sec:  51051.82\n",
      "step820 | loss: 3.48004150390625 | dt: 320.60ms | tok/sec:  51103.57\n",
      "step821 | loss: 3.229053497314453 | dt: 320.79ms | tok/sec:  51073.86\n",
      "step822 | loss: 3.2891547679901123 | dt: 320.05ms | tok/sec:  51192.42\n",
      "step823 | loss: 3.1918036937713623 | dt: 319.86ms | tok/sec:  51222.45\n",
      "step824 | loss: 3.1615633964538574 | dt: 320.69ms | tok/sec:  51089.58\n",
      "step825 | loss: 3.196521282196045 | dt: 320.50ms | tok/sec:  51119.49\n",
      "step826 | loss: 3.354450225830078 | dt: 320.59ms | tok/sec:  51106.26\n",
      "step827 | loss: 3.236884117126465 | dt: 321.12ms | tok/sec:  51022.22\n",
      "step828 | loss: 3.3469467163085938 | dt: 319.39ms | tok/sec:  51297.39\n",
      "step829 | loss: 3.264650821685791 | dt: 320.90ms | tok/sec:  51056.45\n",
      "step830 | loss: 3.228024959564209 | dt: 319.95ms | tok/sec:  51208.75\n",
      "step831 | loss: 3.2893624305725098 | dt: 319.83ms | tok/sec:  51227.95\n",
      "step832 | loss: 3.2045443058013916 | dt: 319.65ms | tok/sec:  51255.57\n",
      "step833 | loss: 3.379359245300293 | dt: 319.79ms | tok/sec:  51233.53\n",
      "step834 | loss: 3.408167839050293 | dt: 320.90ms | tok/sec:  51056.07\n",
      "step835 | loss: 3.286010265350342 | dt: 320.76ms | tok/sec:  51078.91\n",
      "step836 | loss: 3.126908540725708 | dt: 319.66ms | tok/sec:  51255.00\n",
      "step837 | loss: 3.073546886444092 | dt: 320.75ms | tok/sec:  51079.90\n",
      "step838 | loss: 3.2296900749206543 | dt: 320.02ms | tok/sec:  51196.31\n",
      "step839 | loss: 3.0213942527770996 | dt: 320.97ms | tok/sec:  51045.83\n",
      "step840 | loss: 3.433645248413086 | dt: 320.27ms | tok/sec:  51156.60\n",
      "step841 | loss: 3.160961866378784 | dt: 320.50ms | tok/sec:  51119.65\n",
      "step842 | loss: 3.228372573852539 | dt: 321.06ms | tok/sec:  51030.32\n",
      "step843 | loss: 3.199812412261963 | dt: 320.85ms | tok/sec:  51065.02\n",
      "step844 | loss: 3.2565951347351074 | dt: 319.29ms | tok/sec:  51313.10\n",
      "step845 | loss: 3.1882731914520264 | dt: 320.68ms | tok/sec:  51091.48\n",
      "step846 | loss: 3.3391144275665283 | dt: 320.47ms | tok/sec:  51124.44\n",
      "step847 | loss: 3.196979522705078 | dt: 320.68ms | tok/sec:  51091.33\n",
      "step848 | loss: 3.2722623348236084 | dt: 319.59ms | tok/sec:  51266.47\n",
      "step849 | loss: 3.2122223377227783 | dt: 320.68ms | tok/sec:  51091.37\n",
      "step850 | loss: 3.140448570251465 | dt: 319.76ms | tok/sec:  51239.10\n",
      "step851 | loss: 3.1896634101867676 | dt: 320.49ms | tok/sec:  51122.04\n",
      "step852 | loss: 3.126093864440918 | dt: 319.63ms | tok/sec:  51258.98\n",
      "step853 | loss: 3.295121669769287 | dt: 320.93ms | tok/sec:  51051.40\n",
      "step854 | loss: 3.3242735862731934 | dt: 319.66ms | tok/sec:  51253.85\n",
      "step855 | loss: 3.21193265914917 | dt: 320.51ms | tok/sec:  51118.96\n",
      "step856 | loss: 2.986605167388916 | dt: 320.26ms | tok/sec:  51158.01\n",
      "step857 | loss: 2.935269594192505 | dt: 319.93ms | tok/sec:  51211.19\n",
      "step858 | loss: 3.192777156829834 | dt: 320.32ms | tok/sec:  51148.98\n",
      "step859 | loss: 2.8871049880981445 | dt: 321.15ms | tok/sec:  51015.93\n",
      "step860 | loss: 3.292090654373169 | dt: 320.08ms | tok/sec:  51186.62\n",
      "step861 | loss: 3.050391674041748 | dt: 320.87ms | tok/sec:  51061.38\n",
      "step862 | loss: 3.188202381134033 | dt: 319.95ms | tok/sec:  51207.79\n",
      "step863 | loss: 3.106177568435669 | dt: 320.50ms | tok/sec:  51119.88\n",
      "step864 | loss: 3.0742506980895996 | dt: 320.12ms | tok/sec:  51180.64\n",
      "step865 | loss: 2.989797592163086 | dt: 321.28ms | tok/sec:  50996.66\n",
      "step866 | loss: 3.1993398666381836 | dt: 319.67ms | tok/sec:  51253.13\n",
      "step867 | loss: 3.1186928749084473 | dt: 321.00ms | tok/sec:  51040.98\n",
      "step868 | loss: 3.193645477294922 | dt: 320.65ms | tok/sec:  51096.08\n",
      "step869 | loss: 3.131119966506958 | dt: 320.61ms | tok/sec:  51102.39\n",
      "step870 | loss: 3.056000232696533 | dt: 320.15ms | tok/sec:  51176.52\n",
      "step871 | loss: 3.104719400405884 | dt: 320.79ms | tok/sec:  51074.66\n",
      "step872 | loss: 3.0369739532470703 | dt: 320.09ms | tok/sec:  51186.28\n",
      "step873 | loss: 3.187108039855957 | dt: 320.71ms | tok/sec:  51087.12\n",
      "step874 | loss: 3.237245559692383 | dt: 319.83ms | tok/sec:  51226.50\n",
      "step875 | loss: 3.0968170166015625 | dt: 320.74ms | tok/sec:  51082.48\n",
      "step876 | loss: 2.9207913875579834 | dt: 320.35ms | tok/sec:  51143.43\n",
      "step877 | loss: 2.897799491882324 | dt: 320.40ms | tok/sec:  51136.69\n",
      "step878 | loss: 3.0503363609313965 | dt: 319.66ms | tok/sec:  51255.23\n",
      "step879 | loss: 2.807192325592041 | dt: 320.76ms | tok/sec:  51077.96\n",
      "step880 | loss: 3.3745920658111572 | dt: 320.77ms | tok/sec:  51076.64\n",
      "step881 | loss: 3.0938706398010254 | dt: 321.00ms | tok/sec:  51041.28\n",
      "step882 | loss: 3.0973763465881348 | dt: 319.49ms | tok/sec:  51281.51\n",
      "step883 | loss: 3.0790038108825684 | dt: 320.79ms | tok/sec:  51073.60\n",
      "step884 | loss: 3.0862441062927246 | dt: 319.34ms | tok/sec:  51305.78\n",
      "step885 | loss: 2.969572067260742 | dt: 320.81ms | tok/sec:  51069.96\n",
      "step886 | loss: 3.123075246810913 | dt: 319.46ms | tok/sec:  51286.22\n",
      "step887 | loss: 3.013930320739746 | dt: 319.87ms | tok/sec:  51221.23\n",
      "step888 | loss: 3.1473066806793213 | dt: 321.01ms | tok/sec:  51039.27\n",
      "step889 | loss: 3.0625948905944824 | dt: 320.70ms | tok/sec:  51087.80\n",
      "step890 | loss: 3.034611225128174 | dt: 319.62ms | tok/sec:  51261.39\n",
      "step891 | loss: 3.1054654121398926 | dt: 320.05ms | tok/sec:  51192.50\n",
      "step892 | loss: 3.003499984741211 | dt: 319.50ms | tok/sec:  51280.09\n",
      "step893 | loss: 3.1729862689971924 | dt: 320.25ms | tok/sec:  51160.10\n",
      "step894 | loss: 3.203636884689331 | dt: 319.60ms | tok/sec:  51263.57\n",
      "step895 | loss: 3.0908148288726807 | dt: 320.50ms | tok/sec:  51120.64\n",
      "step896 | loss: 2.8698570728302 | dt: 321.06ms | tok/sec:  51030.25\n",
      "step897 | loss: 2.835700511932373 | dt: 320.86ms | tok/sec:  51062.63\n",
      "step898 | loss: 2.96174955368042 | dt: 320.77ms | tok/sec:  51076.79\n",
      "step899 | loss: 2.7720470428466797 | dt: 320.36ms | tok/sec:  51142.21\n",
      "step900 | loss: 3.1057357788085938 | dt: 320.10ms | tok/sec:  51184.53\n",
      "step901 | loss: 2.8796863555908203 | dt: 320.77ms | tok/sec:  51076.90\n",
      "step902 | loss: 2.995495080947876 | dt: 320.16ms | tok/sec:  51173.74\n",
      "step903 | loss: 2.9407730102539062 | dt: 320.97ms | tok/sec:  51044.96\n",
      "step904 | loss: 2.904114246368408 | dt: 319.44ms | tok/sec:  51290.50\n",
      "step905 | loss: 2.866115093231201 | dt: 319.97ms | tok/sec:  51205.05\n",
      "step906 | loss: 3.0403900146484375 | dt: 319.66ms | tok/sec:  51254.81\n",
      "step907 | loss: 2.939945936203003 | dt: 319.72ms | tok/sec:  51244.83\n",
      "step908 | loss: 2.9812967777252197 | dt: 320.39ms | tok/sec:  51137.49\n",
      "step909 | loss: 2.9226272106170654 | dt: 321.26ms | tok/sec:  50999.42\n",
      "step910 | loss: 2.9189398288726807 | dt: 319.23ms | tok/sec:  51323.83\n",
      "step911 | loss: 3.0239033699035645 | dt: 320.89ms | tok/sec:  51058.04\n",
      "step912 | loss: 2.913471221923828 | dt: 320.44ms | tok/sec:  51130.18\n",
      "step913 | loss: 3.0722951889038086 | dt: 319.65ms | tok/sec:  51255.96\n",
      "step914 | loss: 3.155595064163208 | dt: 321.21ms | tok/sec:  51007.18\n",
      "step915 | loss: 2.9949562549591064 | dt: 321.18ms | tok/sec:  51012.52\n",
      "step916 | loss: 2.792541027069092 | dt: 319.87ms | tok/sec:  51221.00\n",
      "step917 | loss: 2.7054924964904785 | dt: 320.81ms | tok/sec:  51071.40\n",
      "step918 | loss: 2.860687732696533 | dt: 320.25ms | tok/sec:  51159.80\n",
      "step919 | loss: 2.6760330200195312 | dt: 320.93ms | tok/sec:  51051.93\n",
      "step920 | loss: 3.0431134700775146 | dt: 319.57ms | tok/sec:  51269.26\n",
      "step921 | loss: 2.815809726715088 | dt: 321.08ms | tok/sec:  51028.35\n",
      "step922 | loss: 2.86418080329895 | dt: 320.04ms | tok/sec:  51193.34\n",
      "step923 | loss: 2.8071365356445312 | dt: 320.04ms | tok/sec:  51194.33\n",
      "step924 | loss: 2.8004701137542725 | dt: 320.94ms | tok/sec:  51050.30\n",
      "step925 | loss: 2.7822868824005127 | dt: 320.39ms | tok/sec:  51137.03\n",
      "step926 | loss: 2.9098401069641113 | dt: 319.35ms | tok/sec:  51304.67\n",
      "step927 | loss: 2.7975211143493652 | dt: 320.69ms | tok/sec:  51089.05\n",
      "step928 | loss: 2.930924415588379 | dt: 320.29ms | tok/sec:  51154.39\n",
      "step929 | loss: 2.9161252975463867 | dt: 320.50ms | tok/sec:  51120.45\n",
      "step930 | loss: 2.8641505241394043 | dt: 320.03ms | tok/sec:  51195.85\n",
      "step931 | loss: 2.9548134803771973 | dt: 320.35ms | tok/sec:  51143.77\n",
      "step932 | loss: 2.8587188720703125 | dt: 319.57ms | tok/sec:  51268.35\n",
      "step933 | loss: 2.9791154861450195 | dt: 319.51ms | tok/sec:  51278.48\n",
      "step934 | loss: 2.977952003479004 | dt: 319.97ms | tok/sec:  51205.58\n",
      "step935 | loss: 2.92388653755188 | dt: 320.84ms | tok/sec:  51065.82\n",
      "step936 | loss: 2.8052637577056885 | dt: 319.32ms | tok/sec:  51308.31\n",
      "step937 | loss: 2.708266258239746 | dt: 321.21ms | tok/sec:  51006.58\n",
      "step938 | loss: 2.861464023590088 | dt: 320.96ms | tok/sec:  51046.74\n",
      "step939 | loss: 2.6263551712036133 | dt: 320.71ms | tok/sec:  51086.70\n",
      "step940 | loss: 2.967618942260742 | dt: 320.26ms | tok/sec:  51157.78\n",
      "step941 | loss: 2.787670135498047 | dt: 321.10ms | tok/sec:  51024.57\n",
      "step942 | loss: 2.8351502418518066 | dt: 319.57ms | tok/sec:  51268.54\n",
      "step943 | loss: 2.77154278755188 | dt: 320.83ms | tok/sec:  51067.87\n",
      "step944 | loss: 2.753781795501709 | dt: 319.83ms | tok/sec:  51226.99\n",
      "step945 | loss: 2.7179131507873535 | dt: 320.97ms | tok/sec:  51046.02\n",
      "step946 | loss: 2.836658000946045 | dt: 320.05ms | tok/sec:  51192.69\n",
      "step947 | loss: 2.7454161643981934 | dt: 319.98ms | tok/sec:  51203.83\n",
      "step948 | loss: 2.8789637088775635 | dt: 319.71ms | tok/sec:  51246.94\n",
      "step949 | loss: 2.7736692428588867 | dt: 320.52ms | tok/sec:  51116.60\n",
      "step950 | loss: 2.724544048309326 | dt: 319.60ms | tok/sec:  51263.76\n",
      "step951 | loss: 2.8288142681121826 | dt: 320.70ms | tok/sec:  51087.99\n",
      "step952 | loss: 2.7732293605804443 | dt: 319.63ms | tok/sec:  51258.71\n",
      "step953 | loss: 2.899474859237671 | dt: 320.40ms | tok/sec:  51136.46\n",
      "step954 | loss: 2.910593032836914 | dt: 320.10ms | tok/sec:  51184.60\n",
      "step955 | loss: 2.815648078918457 | dt: 320.79ms | tok/sec:  51074.24\n",
      "step956 | loss: 2.594280481338501 | dt: 320.88ms | tok/sec:  51059.82\n",
      "step957 | loss: 2.565762519836426 | dt: 320.70ms | tok/sec:  51088.37\n",
      "step958 | loss: 2.758908271789551 | dt: 319.60ms | tok/sec:  51264.64\n",
      "step959 | loss: 2.5422279834747314 | dt: 321.06ms | tok/sec:  51031.61\n",
      "step960 | loss: 2.9080731868743896 | dt: 320.11ms | tok/sec:  51182.20\n",
      "step961 | loss: 2.7388572692871094 | dt: 320.57ms | tok/sec:  51108.32\n",
      "step962 | loss: 2.7703540325164795 | dt: 320.68ms | tok/sec:  51091.60\n",
      "step963 | loss: 2.7096047401428223 | dt: 320.29ms | tok/sec:  51153.86\n",
      "step964 | loss: 2.6605591773986816 | dt: 320.19ms | tok/sec:  51168.86\n",
      "step965 | loss: 2.6102476119995117 | dt: 320.37ms | tok/sec:  51140.19\n",
      "step966 | loss: 2.7666921615600586 | dt: 320.23ms | tok/sec:  51162.62\n",
      "step967 | loss: 2.655632972717285 | dt: 320.65ms | tok/sec:  51096.80\n",
      "step968 | loss: 2.7289345264434814 | dt: 319.78ms | tok/sec:  51235.66\n",
      "step969 | loss: 2.6560823917388916 | dt: 320.88ms | tok/sec:  51059.56\n",
      "step970 | loss: 2.6176443099975586 | dt: 319.84ms | tok/sec:  51226.08\n",
      "step971 | loss: 2.6925408840179443 | dt: 320.64ms | tok/sec:  51098.55\n",
      "step972 | loss: 2.607274293899536 | dt: 320.12ms | tok/sec:  51180.75\n",
      "step973 | loss: 2.6938695907592773 | dt: 320.40ms | tok/sec:  51135.70\n",
      "step974 | loss: 2.7271430492401123 | dt: 319.88ms | tok/sec:  51219.66\n",
      "step975 | loss: 2.6281423568725586 | dt: 319.82ms | tok/sec:  51229.25\n",
      "step976 | loss: 2.4486148357391357 | dt: 320.26ms | tok/sec:  51158.54\n",
      "step977 | loss: 2.501453161239624 | dt: 320.30ms | tok/sec:  51152.10\n",
      "step978 | loss: 2.6385717391967773 | dt: 319.45ms | tok/sec:  51287.59\n",
      "step979 | loss: 2.393768787384033 | dt: 320.81ms | tok/sec:  51070.26\n",
      "step980 | loss: 2.7243704795837402 | dt: 320.46ms | tok/sec:  51127.25\n",
      "step981 | loss: 2.5854883193969727 | dt: 319.19ms | tok/sec:  51329.96\n",
      "step982 | loss: 2.5963826179504395 | dt: 321.20ms | tok/sec:  51008.32\n",
      "step983 | loss: 2.538996458053589 | dt: 320.91ms | tok/sec:  51054.66\n",
      "step984 | loss: 2.5159168243408203 | dt: 320.14ms | tok/sec:  51176.83\n",
      "step985 | loss: 2.471611499786377 | dt: 320.01ms | tok/sec:  51197.68\n",
      "step986 | loss: 2.651502847671509 | dt: 321.10ms | tok/sec:  51023.92\n",
      "step987 | loss: 2.536991596221924 | dt: 320.23ms | tok/sec:  51163.34\n",
      "step988 | loss: 2.6000003814697266 | dt: 320.28ms | tok/sec:  51155.80\n",
      "step989 | loss: 2.5519590377807617 | dt: 321.05ms | tok/sec:  51032.56\n",
      "step990 | loss: 2.548257827758789 | dt: 320.04ms | tok/sec:  51193.37\n",
      "step991 | loss: 2.6270527839660645 | dt: 320.67ms | tok/sec:  51093.31\n",
      "step992 | loss: 2.536862373352051 | dt: 320.87ms | tok/sec:  51061.46\n",
      "step993 | loss: 2.641305685043335 | dt: 319.80ms | tok/sec:  51232.72\n",
      "step994 | loss: 2.6197428703308105 | dt: 320.25ms | tok/sec:  51160.44\n",
      "step995 | loss: 2.5292227268218994 | dt: 320.89ms | tok/sec:  51058.27\n",
      "step996 | loss: 2.3543899059295654 | dt: 319.58ms | tok/sec:  51267.05\n",
      "step997 | loss: 2.350431203842163 | dt: 319.63ms | tok/sec:  51259.21\n",
      "step998 | loss: 2.518357038497925 | dt: 319.65ms | tok/sec:  51255.42\n",
      "step999 | loss: 2.352783679962158 | dt: 320.86ms | tok/sec:  51063.20\n",
      "Prediction at step 1000: \n",
      " : This is a fixed text used for prediction.\n",
      "\n",
      "\n",
      "BISague, in night! \n",
      "\n",
      "step1000 | loss: 2.824368953704834 | dt: 319.22ms | tok/sec:  51325.86\n",
      "step1001 | loss: 2.5129103660583496 | dt: 320.13ms | tok/sec:  51179.76\n",
      "step1002 | loss: 2.4989089965820312 | dt: 319.46ms | tok/sec:  51286.60\n",
      "step1003 | loss: 2.533425807952881 | dt: 321.02ms | tok/sec:  51037.87\n",
      "step1004 | loss: 2.5196850299835205 | dt: 319.30ms | tok/sec:  51311.57\n",
      "step1005 | loss: 2.464223623275757 | dt: 320.29ms | tok/sec:  51152.90\n",
      "step1006 | loss: 2.5601446628570557 | dt: 320.49ms | tok/sec:  51121.85\n",
      "step1007 | loss: 2.4379005432128906 | dt: 320.86ms | tok/sec:  51063.35\n",
      "step1008 | loss: 2.504321813583374 | dt: 319.25ms | tok/sec:  51320.30\n",
      "step1009 | loss: 2.4908246994018555 | dt: 319.93ms | tok/sec:  51210.66\n",
      "step1010 | loss: 2.4623863697052 | dt: 319.52ms | tok/sec:  51276.34\n",
      "step1011 | loss: 2.5147995948791504 | dt: 320.09ms | tok/sec:  51184.87\n",
      "step1012 | loss: 2.4425106048583984 | dt: 320.27ms | tok/sec:  51156.67\n",
      "step1013 | loss: 2.584315776824951 | dt: 320.17ms | tok/sec:  51173.36\n",
      "step1014 | loss: 2.600924015045166 | dt: 320.91ms | tok/sec:  51054.59\n",
      "step1015 | loss: 2.4894537925720215 | dt: 320.87ms | tok/sec:  51061.38\n",
      "step1016 | loss: 2.3560924530029297 | dt: 320.03ms | tok/sec:  51195.70\n",
      "step1017 | loss: 2.3207945823669434 | dt: 319.97ms | tok/sec:  51205.31\n",
      "step1018 | loss: 2.5036752223968506 | dt: 320.10ms | tok/sec:  51183.46\n",
      "step1019 | loss: 2.426447868347168 | dt: 320.83ms | tok/sec:  51066.92\n",
      "step1020 | loss: 2.6472220420837402 | dt: 319.91ms | tok/sec:  51214.28\n",
      "step1021 | loss: 2.3717970848083496 | dt: 321.03ms | tok/sec:  51035.29\n",
      "step1022 | loss: 2.450122117996216 | dt: 319.96ms | tok/sec:  51206.31\n",
      "step1023 | loss: 2.4084994792938232 | dt: 321.00ms | tok/sec:  51041.24\n",
      "step1024 | loss: 2.408677577972412 | dt: 319.92ms | tok/sec:  51212.60\n",
      "step1025 | loss: 2.3238792419433594 | dt: 320.80ms | tok/sec:  51072.92\n",
      "step1026 | loss: 2.4608044624328613 | dt: 320.80ms | tok/sec:  51072.50\n",
      "step1027 | loss: 2.3843321800231934 | dt: 320.90ms | tok/sec:  51055.95\n",
      "step1028 | loss: 2.4831626415252686 | dt: 320.18ms | tok/sec:  51171.42\n",
      "step1029 | loss: 2.428417682647705 | dt: 320.20ms | tok/sec:  51168.41\n",
      "step1030 | loss: 2.3781821727752686 | dt: 319.67ms | tok/sec:  51253.36\n",
      "step1031 | loss: 2.4222402572631836 | dt: 320.70ms | tok/sec:  51087.99\n",
      "step1032 | loss: 2.3311314582824707 | dt: 319.71ms | tok/sec:  51246.71\n",
      "step1033 | loss: 2.473658561706543 | dt: 320.84ms | tok/sec:  51065.52\n",
      "step1034 | loss: 2.4897022247314453 | dt: 319.63ms | tok/sec:  51258.63\n",
      "step1035 | loss: 2.489996910095215 | dt: 320.91ms | tok/sec:  51054.78\n",
      "step1036 | loss: 2.3038034439086914 | dt: 319.48ms | tok/sec:  51282.96\n",
      "step1037 | loss: 2.261600971221924 | dt: 320.60ms | tok/sec:  51104.78\n",
      "step1038 | loss: 2.4016542434692383 | dt: 320.88ms | tok/sec:  51059.82\n",
      "step1039 | loss: 2.218545913696289 | dt: 319.85ms | tok/sec:  51223.21\n",
      "step1040 | loss: 2.4728193283081055 | dt: 319.69ms | tok/sec:  51250.15\n",
      "step1041 | loss: 2.3234915733337402 | dt: 320.89ms | tok/sec:  51057.97\n",
      "step1042 | loss: 2.391902446746826 | dt: 319.50ms | tok/sec:  51280.70\n",
      "step1043 | loss: 2.416989803314209 | dt: 320.04ms | tok/sec:  51193.22\n",
      "step1044 | loss: 2.4043946266174316 | dt: 320.24ms | tok/sec:  51162.01\n",
      "step1045 | loss: 2.2689881324768066 | dt: 320.78ms | tok/sec:  51076.14\n",
      "step1046 | loss: 2.410029172897339 | dt: 319.50ms | tok/sec:  51279.63\n",
      "step1047 | loss: 2.3279218673706055 | dt: 319.65ms | tok/sec:  51255.65\n",
      "step1048 | loss: 2.4284896850585938 | dt: 320.33ms | tok/sec:  51146.58\n",
      "step1049 | loss: 2.3976962566375732 | dt: 319.80ms | tok/sec:  51231.73\n",
      "step1050 | loss: 2.3696141242980957 | dt: 320.37ms | tok/sec:  51141.29\n",
      "step1051 | loss: 2.354081630706787 | dt: 320.05ms | tok/sec:  51192.65\n",
      "step1052 | loss: 2.3174996376037598 | dt: 319.79ms | tok/sec:  51234.06\n",
      "step1053 | loss: 2.4266679286956787 | dt: 321.01ms | tok/sec:  51038.40\n",
      "step1054 | loss: 2.3931922912597656 | dt: 321.04ms | tok/sec:  51034.57\n",
      "step1055 | loss: 2.3138842582702637 | dt: 320.92ms | tok/sec:  51053.94\n",
      "step1056 | loss: 2.199634075164795 | dt: 319.55ms | tok/sec:  51271.33\n",
      "step1057 | loss: 2.277461051940918 | dt: 321.20ms | tok/sec:  51008.32\n",
      "step1058 | loss: 2.397033929824829 | dt: 320.15ms | tok/sec:  51176.14\n",
      "step1059 | loss: 2.131903886795044 | dt: 319.85ms | tok/sec:  51224.09\n",
      "step1060 | loss: 2.4571666717529297 | dt: 319.94ms | tok/sec:  51209.01\n",
      "step1061 | loss: 2.35142183303833 | dt: 320.93ms | tok/sec:  51052.24\n",
      "step1062 | loss: 2.307668447494507 | dt: 319.99ms | tok/sec:  51200.93\n",
      "step1063 | loss: 2.2938385009765625 | dt: 320.87ms | tok/sec:  51060.66\n",
      "step1064 | loss: 2.2865676879882812 | dt: 319.81ms | tok/sec:  51231.12\n",
      "step1065 | loss: 2.2368664741516113 | dt: 320.58ms | tok/sec:  51107.18\n",
      "step1066 | loss: 2.376685619354248 | dt: 319.86ms | tok/sec:  51222.76\n",
      "step1067 | loss: 2.2572340965270996 | dt: 320.88ms | tok/sec:  51059.98\n",
      "step1068 | loss: 2.382378578186035 | dt: 320.37ms | tok/sec:  51140.11\n",
      "step1069 | loss: 2.3256044387817383 | dt: 319.91ms | tok/sec:  51215.12\n",
      "step1070 | loss: 2.218360662460327 | dt: 320.77ms | tok/sec:  51077.78\n",
      "step1071 | loss: 2.2759413719177246 | dt: 320.69ms | tok/sec:  51090.61\n",
      "step1072 | loss: 2.237522602081299 | dt: 320.47ms | tok/sec:  51124.44\n",
      "step1073 | loss: 2.3619728088378906 | dt: 320.73ms | tok/sec:  51082.67\n",
      "step1074 | loss: 2.3099822998046875 | dt: 320.68ms | tok/sec:  51091.94\n",
      "step1075 | loss: 2.2099199295043945 | dt: 319.80ms | tok/sec:  51232.38\n",
      "step1076 | loss: 2.0653316974639893 | dt: 320.08ms | tok/sec:  51187.46\n",
      "step1077 | loss: 2.0695760250091553 | dt: 320.74ms | tok/sec:  51081.72\n",
      "step1078 | loss: 2.183908700942993 | dt: 320.90ms | tok/sec:  51056.83\n",
      "step1079 | loss: 2.046351909637451 | dt: 319.64ms | tok/sec:  51257.10\n",
      "step1080 | loss: 2.294747829437256 | dt: 320.89ms | tok/sec:  51058.00\n",
      "step1081 | loss: 2.137664794921875 | dt: 320.94ms | tok/sec:  51050.53\n",
      "step1082 | loss: 2.143564462661743 | dt: 320.14ms | tok/sec:  51178.28\n",
      "step1083 | loss: 2.1612141132354736 | dt: 319.88ms | tok/sec:  51218.44\n",
      "step1084 | loss: 2.2068305015563965 | dt: 320.60ms | tok/sec:  51104.14\n",
      "step1085 | loss: 2.094735622406006 | dt: 320.08ms | tok/sec:  51187.20\n",
      "step1086 | loss: 2.2194528579711914 | dt: 319.57ms | tok/sec:  51269.15\n",
      "step1087 | loss: 2.1171183586120605 | dt: 320.91ms | tok/sec:  51054.85\n",
      "step1088 | loss: 2.200148582458496 | dt: 320.43ms | tok/sec:  51131.40\n",
      "step1089 | loss: 2.132391929626465 | dt: 319.84ms | tok/sec:  51225.16\n",
      "step1090 | loss: 2.1102185249328613 | dt: 319.50ms | tok/sec:  51280.09\n",
      "step1091 | loss: 2.213012933731079 | dt: 321.24ms | tok/sec:  51001.92\n",
      "step1092 | loss: 2.108938217163086 | dt: 320.88ms | tok/sec:  51060.09\n",
      "step1093 | loss: 2.2487239837646484 | dt: 319.50ms | tok/sec:  51279.98\n",
      "step1094 | loss: 2.2040791511535645 | dt: 320.05ms | tok/sec:  51191.62\n",
      "step1095 | loss: 2.0646438598632812 | dt: 320.10ms | tok/sec:  51184.07\n",
      "step1096 | loss: 1.9320942163467407 | dt: 319.62ms | tok/sec:  51260.24\n",
      "step1097 | loss: 1.9247686862945557 | dt: 320.00ms | tok/sec:  51200.09\n",
      "step1098 | loss: 2.093360424041748 | dt: 319.95ms | tok/sec:  51208.02\n",
      "step1099 | loss: 1.961337685585022 | dt: 320.96ms | tok/sec:  51046.28\n",
      "step1100 | loss: 2.13631534576416 | dt: 319.60ms | tok/sec:  51263.72\n",
      "step1101 | loss: 2.0108323097229004 | dt: 321.29ms | tok/sec:  50994.99\n",
      "step1102 | loss: 2.041846513748169 | dt: 320.18ms | tok/sec:  51170.88\n",
      "step1103 | loss: 2.0349998474121094 | dt: 320.94ms | tok/sec:  51050.83\n",
      "step1104 | loss: 2.0037403106689453 | dt: 320.31ms | tok/sec:  51150.28\n",
      "step1105 | loss: 1.9113543033599854 | dt: 320.50ms | tok/sec:  51120.41\n",
      "step1106 | loss: 2.032370090484619 | dt: 319.74ms | tok/sec:  51241.51\n",
      "step1107 | loss: 1.978097915649414 | dt: 320.97ms | tok/sec:  51044.54\n",
      "step1108 | loss: 2.02512526512146 | dt: 319.50ms | tok/sec:  51280.74\n",
      "step1109 | loss: 1.9991106986999512 | dt: 320.16ms | tok/sec:  51173.78\n",
      "step1110 | loss: 2.036811590194702 | dt: 320.15ms | tok/sec:  51175.34\n",
      "step1111 | loss: 2.0822901725769043 | dt: 319.95ms | tok/sec:  51207.56\n",
      "step1112 | loss: 1.9892299175262451 | dt: 320.83ms | tok/sec:  51066.88\n",
      "step1113 | loss: 2.0471599102020264 | dt: 320.93ms | tok/sec:  51051.21\n",
      "step1114 | loss: 2.051837682723999 | dt: 320.06ms | tok/sec:  51189.71\n",
      "step1115 | loss: 1.9760754108428955 | dt: 320.75ms | tok/sec:  51080.51\n",
      "step1116 | loss: 1.8502744436264038 | dt: 320.95ms | tok/sec:  51047.95\n",
      "step1117 | loss: 1.8201911449432373 | dt: 320.51ms | tok/sec:  51117.75\n",
      "step1118 | loss: 1.9743355512619019 | dt: 320.12ms | tok/sec:  51181.21\n",
      "step1119 | loss: 1.794040560722351 | dt: 320.79ms | tok/sec:  51074.17\n",
      "step1120 | loss: 2.0604515075683594 | dt: 320.42ms | tok/sec:  51132.20\n",
      "step1121 | loss: 1.9665822982788086 | dt: 320.35ms | tok/sec:  51144.64\n",
      "step1122 | loss: 1.947995901107788 | dt: 319.61ms | tok/sec:  51261.69\n",
      "step1123 | loss: 1.9540011882781982 | dt: 320.42ms | tok/sec:  51133.49\n",
      "step1124 | loss: 1.9894213676452637 | dt: 321.08ms | tok/sec:  51027.52\n",
      "step1125 | loss: 1.9392169713974 | dt: 320.95ms | tok/sec:  51047.72\n",
      "step1126 | loss: 2.007204055786133 | dt: 319.99ms | tok/sec:  51202.38\n",
      "step1127 | loss: 1.9073446989059448 | dt: 320.45ms | tok/sec:  51128.58\n",
      "step1128 | loss: 1.9414929151535034 | dt: 320.08ms | tok/sec:  51186.82\n",
      "step1129 | loss: 1.9051361083984375 | dt: 320.33ms | tok/sec:  51147.95\n",
      "step1130 | loss: 1.8938496112823486 | dt: 321.12ms | tok/sec:  51020.78\n",
      "step1131 | loss: 1.9609711170196533 | dt: 320.65ms | tok/sec:  51096.16\n",
      "step1132 | loss: 1.9160995483398438 | dt: 319.69ms | tok/sec:  51249.42\n",
      "step1133 | loss: 2.0506930351257324 | dt: 321.60ms | tok/sec:  50945.88\n",
      "step1134 | loss: 2.061048984527588 | dt: 320.30ms | tok/sec:  51151.69\n",
      "step1135 | loss: 1.9246151447296143 | dt: 320.94ms | tok/sec:  51049.96\n",
      "step1136 | loss: 1.8008970022201538 | dt: 319.65ms | tok/sec:  51256.76\n",
      "step1137 | loss: 1.803292989730835 | dt: 320.92ms | tok/sec:  51053.75\n",
      "step1138 | loss: 1.888329267501831 | dt: 319.82ms | tok/sec:  51229.55\n",
      "step1139 | loss: 1.693835973739624 | dt: 320.85ms | tok/sec:  51064.76\n",
      "step1140 | loss: 2.015617847442627 | dt: 320.26ms | tok/sec:  51157.85\n",
      "step1141 | loss: 1.882583498954773 | dt: 320.96ms | tok/sec:  51046.13\n",
      "step1142 | loss: 1.8878114223480225 | dt: 320.15ms | tok/sec:  51176.22\n",
      "step1143 | loss: 1.8978219032287598 | dt: 320.76ms | tok/sec:  51078.84\n",
      "step1144 | loss: 1.880445957183838 | dt: 320.27ms | tok/sec:  51156.64\n",
      "step1145 | loss: 1.8083709478378296 | dt: 320.36ms | tok/sec:  51142.09\n",
      "step1146 | loss: 1.904260277748108 | dt: 320.03ms | tok/sec:  51194.59\n",
      "step1147 | loss: 1.882647156715393 | dt: 320.76ms | tok/sec:  51078.19\n",
      "step1148 | loss: 1.9448102712631226 | dt: 319.72ms | tok/sec:  51245.64\n",
      "step1149 | loss: 1.9343924522399902 | dt: 320.83ms | tok/sec:  51067.56\n",
      "step1150 | loss: 1.8783421516418457 | dt: 319.83ms | tok/sec:  51226.84\n",
      "step1151 | loss: 1.911081314086914 | dt: 320.48ms | tok/sec:  51123.68\n",
      "step1152 | loss: 1.8211802244186401 | dt: 320.40ms | tok/sec:  51135.62\n",
      "step1153 | loss: 1.9662094116210938 | dt: 320.79ms | tok/sec:  51073.94\n",
      "step1154 | loss: 1.9302451610565186 | dt: 320.62ms | tok/sec:  51100.98\n",
      "step1155 | loss: 1.8233203887939453 | dt: 319.99ms | tok/sec:  51202.38\n",
      "step1156 | loss: 1.7468183040618896 | dt: 319.68ms | tok/sec:  51251.06\n",
      "step1157 | loss: 1.7481663227081299 | dt: 319.92ms | tok/sec:  51212.72\n",
      "step1158 | loss: 1.8157848119735718 | dt: 319.77ms | tok/sec:  51236.93\n",
      "step1159 | loss: 1.6248784065246582 | dt: 319.90ms | tok/sec:  51215.73\n",
      "step1160 | loss: 1.880632996559143 | dt: 320.74ms | tok/sec:  51082.41\n",
      "step1161 | loss: 1.8006350994110107 | dt: 319.75ms | tok/sec:  51240.55\n",
      "step1162 | loss: 1.8058912754058838 | dt: 320.47ms | tok/sec:  51125.28\n",
      "step1163 | loss: 1.8249287605285645 | dt: 320.17ms | tok/sec:  51172.06\n",
      "step1164 | loss: 1.8241844177246094 | dt: 319.36ms | tok/sec:  51301.91\n",
      "step1165 | loss: 1.7467597723007202 | dt: 319.82ms | tok/sec:  51228.68\n",
      "step1166 | loss: 1.8484117984771729 | dt: 320.98ms | tok/sec:  51043.71\n",
      "step1167 | loss: 1.771871566772461 | dt: 320.70ms | tok/sec:  51087.91\n",
      "step1168 | loss: 1.8112916946411133 | dt: 319.65ms | tok/sec:  51256.53\n",
      "step1169 | loss: 1.7726255655288696 | dt: 321.06ms | tok/sec:  51030.25\n",
      "step1170 | loss: 1.7792822122573853 | dt: 320.08ms | tok/sec:  51187.84\n",
      "step1171 | loss: 1.8334323167800903 | dt: 320.10ms | tok/sec:  51183.96\n",
      "step1172 | loss: 1.7987970113754272 | dt: 319.77ms | tok/sec:  51237.61\n",
      "step1173 | loss: 1.8701221942901611 | dt: 320.52ms | tok/sec:  51116.26\n",
      "step1174 | loss: 1.8545074462890625 | dt: 320.26ms | tok/sec:  51159.04\n",
      "step1175 | loss: 1.804434061050415 | dt: 320.95ms | tok/sec:  51048.82\n",
      "step1176 | loss: 1.6752889156341553 | dt: 320.92ms | tok/sec:  51052.81\n",
      "step1177 | loss: 1.6285309791564941 | dt: 319.66ms | tok/sec:  51253.85\n",
      "step1178 | loss: 1.7212722301483154 | dt: 319.93ms | tok/sec:  51211.69\n",
      "step1179 | loss: 1.6226011514663696 | dt: 320.72ms | tok/sec:  51085.07\n",
      "step1180 | loss: 1.867394208908081 | dt: 319.85ms | tok/sec:  51223.71\n",
      "step1181 | loss: 1.747368574142456 | dt: 319.92ms | tok/sec:  51212.37\n",
      "step1182 | loss: 1.752964973449707 | dt: 320.57ms | tok/sec:  51108.55\n",
      "step1183 | loss: 1.7704445123672485 | dt: 320.85ms | tok/sec:  51064.41\n",
      "step1184 | loss: 1.7440603971481323 | dt: 320.03ms | tok/sec:  51195.62\n",
      "step1185 | loss: 1.6880958080291748 | dt: 321.11ms | tok/sec:  51023.39\n",
      "step1186 | loss: 1.7816251516342163 | dt: 319.65ms | tok/sec:  51256.03\n",
      "step1187 | loss: 1.7093013525009155 | dt: 320.93ms | tok/sec:  51052.20\n",
      "step1188 | loss: 1.7630420923233032 | dt: 319.49ms | tok/sec:  51281.13\n",
      "step1189 | loss: 1.7195950746536255 | dt: 320.59ms | tok/sec:  51105.16\n",
      "step1190 | loss: 1.6908844709396362 | dt: 319.95ms | tok/sec:  51207.53\n",
      "step1191 | loss: 1.7168474197387695 | dt: 320.72ms | tok/sec:  51085.26\n",
      "step1192 | loss: 1.6749025583267212 | dt: 320.58ms | tok/sec:  51106.80\n",
      "step1193 | loss: 1.7415175437927246 | dt: 321.11ms | tok/sec:  51022.29\n",
      "step1194 | loss: 1.746168613433838 | dt: 320.96ms | tok/sec:  51047.27\n",
      "step1195 | loss: 1.730205774307251 | dt: 320.86ms | tok/sec:  51062.59\n",
      "step1196 | loss: 1.6717342138290405 | dt: 319.59ms | tok/sec:  51266.17\n",
      "step1197 | loss: 1.6357440948486328 | dt: 320.89ms | tok/sec:  51058.15\n",
      "step1198 | loss: 1.6831876039505005 | dt: 320.49ms | tok/sec:  51122.31\n",
      "step1199 | loss: 1.524316430091858 | dt: 319.81ms | tok/sec:  51230.74\n",
      "step1200 | loss: 1.756216049194336 | dt: 319.91ms | tok/sec:  51214.36\n",
      "step1201 | loss: 1.6343564987182617 | dt: 320.72ms | tok/sec:  51085.71\n",
      "step1202 | loss: 1.6814279556274414 | dt: 319.73ms | tok/sec:  51242.81\n",
      "step1203 | loss: 1.7034337520599365 | dt: 319.77ms | tok/sec:  51236.35\n",
      "step1204 | loss: 1.692476749420166 | dt: 319.52ms | tok/sec:  51277.41\n",
      "step1205 | loss: 1.6277120113372803 | dt: 320.46ms | tok/sec:  51126.95\n",
      "step1206 | loss: 1.706881046295166 | dt: 320.05ms | tok/sec:  51191.24\n",
      "step1207 | loss: 1.638530969619751 | dt: 320.49ms | tok/sec:  51121.85\n",
      "step1208 | loss: 1.6700252294540405 | dt: 319.41ms | tok/sec:  51294.29\n",
      "step1209 | loss: 1.6390957832336426 | dt: 320.85ms | tok/sec:  51064.91\n",
      "step1210 | loss: 1.606020450592041 | dt: 319.95ms | tok/sec:  51208.79\n",
      "step1211 | loss: 1.6872011423110962 | dt: 320.73ms | tok/sec:  51083.93\n",
      "step1212 | loss: 1.6236939430236816 | dt: 319.71ms | tok/sec:  51246.55\n",
      "step1213 | loss: 1.633041501045227 | dt: 320.30ms | tok/sec:  51152.18\n",
      "step1214 | loss: 1.6306986808776855 | dt: 320.13ms | tok/sec:  51179.31\n",
      "step1215 | loss: 1.5733106136322021 | dt: 321.08ms | tok/sec:  51026.99\n",
      "step1216 | loss: 1.4761379957199097 | dt: 319.24ms | tok/sec:  51321.99\n",
      "step1217 | loss: 1.4656648635864258 | dt: 319.91ms | tok/sec:  51213.90\n",
      "step1218 | loss: 1.634228229522705 | dt: 320.95ms | tok/sec:  51048.60\n",
      "step1219 | loss: 1.477709174156189 | dt: 320.39ms | tok/sec:  51136.88\n",
      "step1220 | loss: 1.7000629901885986 | dt: 319.32ms | tok/sec:  51309.00\n",
      "step1221 | loss: 1.6217931509017944 | dt: 321.07ms | tok/sec:  51029.34\n",
      "step1222 | loss: 1.6197700500488281 | dt: 320.64ms | tok/sec:  51098.55\n",
      "step1223 | loss: 1.6226110458374023 | dt: 320.37ms | tok/sec:  51141.10\n",
      "step1224 | loss: 1.5854644775390625 | dt: 320.28ms | tok/sec:  51154.88\n",
      "step1225 | loss: 1.4972116947174072 | dt: 320.76ms | tok/sec:  51078.76\n",
      "step1226 | loss: 1.5903236865997314 | dt: 319.57ms | tok/sec:  51268.35\n",
      "step1227 | loss: 1.51166570186615 | dt: 320.73ms | tok/sec:  51083.09\n",
      "step1228 | loss: 1.5226963758468628 | dt: 320.18ms | tok/sec:  51171.61\n",
      "step1229 | loss: 1.5116868019104004 | dt: 319.87ms | tok/sec:  51221.19\n",
      "step1230 | loss: 1.5324442386627197 | dt: 319.58ms | tok/sec:  51267.16\n",
      "step1231 | loss: 1.6420389413833618 | dt: 320.82ms | tok/sec:  51069.69\n",
      "step1232 | loss: 1.5745337009429932 | dt: 320.39ms | tok/sec:  51137.18\n",
      "step1233 | loss: 1.6430611610412598 | dt: 319.96ms | tok/sec:  51206.92\n",
      "step1234 | loss: 1.6189155578613281 | dt: 320.34ms | tok/sec:  51145.82\n",
      "step1235 | loss: 1.4862396717071533 | dt: 319.95ms | tok/sec:  51207.26\n",
      "step1236 | loss: 1.392643928527832 | dt: 319.67ms | tok/sec:  51252.17\n",
      "step1237 | loss: 1.3518023490905762 | dt: 320.82ms | tok/sec:  51068.82\n",
      "step1238 | loss: 1.4622111320495605 | dt: 319.98ms | tok/sec:  51203.71\n",
      "step1239 | loss: 1.3184871673583984 | dt: 319.93ms | tok/sec:  51210.54\n",
      "step1240 | loss: 1.5425941944122314 | dt: 319.74ms | tok/sec:  51240.90\n",
      "step1241 | loss: 1.4743576049804688 | dt: 320.53ms | tok/sec:  51114.74\n",
      "step1242 | loss: 1.4932098388671875 | dt: 319.88ms | tok/sec:  51220.01\n",
      "step1243 | loss: 1.57289457321167 | dt: 321.05ms | tok/sec:  51032.18\n",
      "step1244 | loss: 1.482240080833435 | dt: 319.59ms | tok/sec:  51265.63\n",
      "step1245 | loss: 1.4290064573287964 | dt: 321.00ms | tok/sec:  51041.17\n",
      "step1246 | loss: 1.5037022829055786 | dt: 320.06ms | tok/sec:  51190.59\n",
      "step1247 | loss: 1.3994941711425781 | dt: 320.72ms | tok/sec:  51085.37\n",
      "step1248 | loss: 1.4322823286056519 | dt: 320.85ms | tok/sec:  51064.11\n",
      "step1249 | loss: 1.4525566101074219 | dt: 319.78ms | tok/sec:  51234.75\n",
      "step1250 | loss: 1.4179219007492065 | dt: 320.78ms | tok/sec:  51076.07\n",
      "step1251 | loss: 1.453581690788269 | dt: 320.87ms | tok/sec:  51061.00\n",
      "step1252 | loss: 1.3810820579528809 | dt: 320.54ms | tok/sec:  51114.29\n",
      "step1253 | loss: 1.5129528045654297 | dt: 320.36ms | tok/sec:  51142.89\n",
      "step1254 | loss: 1.5005855560302734 | dt: 320.10ms | tok/sec:  51184.72\n",
      "step1255 | loss: 1.4432029724121094 | dt: 320.42ms | tok/sec:  51132.39\n",
      "step1256 | loss: 1.3676607608795166 | dt: 320.04ms | tok/sec:  51192.80\n",
      "step1257 | loss: 1.3399672508239746 | dt: 320.68ms | tok/sec:  51091.86\n",
      "step1258 | loss: 1.441143274307251 | dt: 320.36ms | tok/sec:  51142.17\n",
      "step1259 | loss: 1.2430894374847412 | dt: 321.00ms | tok/sec:  51041.28\n",
      "step1260 | loss: 1.4312094449996948 | dt: 319.40ms | tok/sec:  51296.51\n",
      "step1261 | loss: 1.3467223644256592 | dt: 320.75ms | tok/sec:  51080.43\n",
      "step1262 | loss: 1.3812892436981201 | dt: 319.63ms | tok/sec:  51259.67\n",
      "step1263 | loss: 1.3302955627441406 | dt: 320.64ms | tok/sec:  51098.44\n",
      "step1264 | loss: 1.3395531177520752 | dt: 319.41ms | tok/sec:  51295.33\n",
      "step1265 | loss: 1.2665811777114868 | dt: 319.85ms | tok/sec:  51224.55\n",
      "step1266 | loss: 1.3397631645202637 | dt: 319.56ms | tok/sec:  51270.87\n",
      "step1267 | loss: 1.3128358125686646 | dt: 320.36ms | tok/sec:  51142.40\n",
      "step1268 | loss: 1.329612374305725 | dt: 321.23ms | tok/sec:  51004.34\n",
      "step1269 | loss: 1.314544916152954 | dt: 320.50ms | tok/sec:  51119.80\n",
      "step1270 | loss: 1.3307050466537476 | dt: 319.36ms | tok/sec:  51303.14\n",
      "step1271 | loss: 1.3734781742095947 | dt: 321.00ms | tok/sec:  51039.99\n",
      "step1272 | loss: 1.280713677406311 | dt: 320.11ms | tok/sec:  51182.77\n",
      "step1273 | loss: 1.412339448928833 | dt: 320.80ms | tok/sec:  51073.03\n",
      "step1274 | loss: 1.3594468832015991 | dt: 320.29ms | tok/sec:  51153.51\n",
      "step1275 | loss: 1.2842590808868408 | dt: 319.68ms | tok/sec:  51251.10\n",
      "step1276 | loss: 1.1856262683868408 | dt: 320.03ms | tok/sec:  51194.52\n",
      "step1277 | loss: 1.1960816383361816 | dt: 319.95ms | tok/sec:  51208.40\n",
      "step1278 | loss: 1.3013880252838135 | dt: 319.96ms | tok/sec:  51207.11\n",
      "step1279 | loss: 1.222846508026123 | dt: 320.50ms | tok/sec:  51120.83\n",
      "step1280 | loss: 1.4326504468917847 | dt: 320.17ms | tok/sec:  51173.25\n",
      "step1281 | loss: 1.3122272491455078 | dt: 319.57ms | tok/sec:  51269.11\n",
      "step1282 | loss: 1.287958025932312 | dt: 319.69ms | tok/sec:  51249.04\n",
      "step1283 | loss: 1.2770047187805176 | dt: 320.57ms | tok/sec:  51108.20\n",
      "step1284 | loss: 1.2564170360565186 | dt: 319.31ms | tok/sec:  51310.15\n",
      "step1285 | loss: 1.1611363887786865 | dt: 320.83ms | tok/sec:  51067.75\n",
      "step1286 | loss: 1.1949951648712158 | dt: 320.72ms | tok/sec:  51085.56\n",
      "step1287 | loss: 1.1608381271362305 | dt: 320.83ms | tok/sec:  51068.29\n",
      "step1288 | loss: 1.180837631225586 | dt: 320.58ms | tok/sec:  51107.44\n",
      "step1289 | loss: 1.1268965005874634 | dt: 319.74ms | tok/sec:  51240.86\n",
      "step1290 | loss: 1.1546223163604736 | dt: 319.96ms | tok/sec:  51205.70\n",
      "step1291 | loss: 1.2022531032562256 | dt: 320.68ms | tok/sec:  51092.17\n",
      "step1292 | loss: 1.1399955749511719 | dt: 319.50ms | tok/sec:  51280.02\n",
      "step1293 | loss: 1.2413970232009888 | dt: 319.93ms | tok/sec:  51210.58\n",
      "step1294 | loss: 1.2147128582000732 | dt: 320.45ms | tok/sec:  51128.05\n",
      "step1295 | loss: 1.16022789478302 | dt: 320.69ms | tok/sec:  51089.55\n",
      "step1296 | loss: 1.094010591506958 | dt: 319.63ms | tok/sec:  51259.82\n",
      "step1297 | loss: 1.071861982345581 | dt: 320.74ms | tok/sec:  51081.46\n",
      "step1298 | loss: 1.1612908840179443 | dt: 319.51ms | tok/sec:  51277.95\n",
      "step1299 | loss: 1.032923698425293 | dt: 319.79ms | tok/sec:  51233.26\n",
      "step1300 | loss: 1.2002090215682983 | dt: 319.44ms | tok/sec:  51289.09\n",
      "step1301 | loss: 1.1133439540863037 | dt: 320.92ms | tok/sec:  51053.72\n",
      "step1302 | loss: 1.1027966737747192 | dt: 319.41ms | tok/sec:  51294.64\n",
      "step1303 | loss: 1.1211347579956055 | dt: 320.41ms | tok/sec:  51134.48\n",
      "step1304 | loss: 1.1202832460403442 | dt: 320.33ms | tok/sec:  51147.92\n",
      "step1305 | loss: 1.064854383468628 | dt: 320.96ms | tok/sec:  51046.62\n",
      "step1306 | loss: 1.121559977531433 | dt: 319.97ms | tok/sec:  51204.86\n",
      "step1307 | loss: 1.076969861984253 | dt: 320.60ms | tok/sec:  51104.97\n",
      "step1308 | loss: 1.0861659049987793 | dt: 320.27ms | tok/sec:  51156.64\n",
      "step1309 | loss: 1.0527540445327759 | dt: 321.11ms | tok/sec:  51022.94\n",
      "step1310 | loss: 1.029954433441162 | dt: 319.97ms | tok/sec:  51204.36\n",
      "step1311 | loss: 1.0633876323699951 | dt: 320.10ms | tok/sec:  51183.31\n",
      "step1312 | loss: 1.0147151947021484 | dt: 320.41ms | tok/sec:  51133.91\n",
      "step1313 | loss: 1.064852237701416 | dt: 320.39ms | tok/sec:  51137.72\n",
      "step1314 | loss: 1.0400784015655518 | dt: 319.74ms | tok/sec:  51241.17\n",
      "step1315 | loss: 0.9906461834907532 | dt: 320.94ms | tok/sec:  51049.58\n",
      "step1316 | loss: 0.9243709444999695 | dt: 319.87ms | tok/sec:  51220.92\n",
      "step1317 | loss: 0.9454832077026367 | dt: 320.76ms | tok/sec:  51079.26\n",
      "step1318 | loss: 0.9779926538467407 | dt: 320.14ms | tok/sec:  51176.87\n",
      "step1319 | loss: 0.9017264246940613 | dt: 320.78ms | tok/sec:  51075.80\n",
      "step1320 | loss: 1.0362236499786377 | dt: 319.70ms | tok/sec:  51247.70\n",
      "step1321 | loss: 0.9679166078567505 | dt: 319.94ms | tok/sec:  51209.21\n",
      "step1322 | loss: 0.9605567455291748 | dt: 320.31ms | tok/sec:  51150.51\n",
      "step1323 | loss: 0.9974584579467773 | dt: 319.61ms | tok/sec:  51262.23\n",
      "step1324 | loss: 0.964268684387207 | dt: 319.43ms | tok/sec:  51291.96\n",
      "step1325 | loss: 0.8998215198516846 | dt: 320.88ms | tok/sec:  51059.67\n",
      "step1326 | loss: 0.9291648864746094 | dt: 319.23ms | tok/sec:  51323.10\n",
      "step1327 | loss: 0.9160736799240112 | dt: 319.81ms | tok/sec:  51229.67\n",
      "step1328 | loss: 0.9467678070068359 | dt: 320.09ms | tok/sec:  51185.18\n",
      "step1329 | loss: 0.964607834815979 | dt: 320.46ms | tok/sec:  51127.14\n",
      "step1330 | loss: 0.9384822249412537 | dt: 320.18ms | tok/sec:  51171.57\n",
      "step1331 | loss: 0.9275940656661987 | dt: 320.97ms | tok/sec:  51045.79\n",
      "step1332 | loss: 0.8913421630859375 | dt: 319.93ms | tok/sec:  51210.88\n",
      "step1333 | loss: 0.9546220898628235 | dt: 320.60ms | tok/sec:  51103.76\n",
      "step1334 | loss: 0.9481821060180664 | dt: 320.44ms | tok/sec:  51129.19\n",
      "step1335 | loss: 0.9182071685791016 | dt: 320.81ms | tok/sec:  51070.15\n",
      "step1336 | loss: 0.8465721607208252 | dt: 320.22ms | tok/sec:  51164.44\n",
      "step1337 | loss: 0.8418385982513428 | dt: 320.99ms | tok/sec:  51042.42\n",
      "step1338 | loss: 0.8446054458618164 | dt: 319.99ms | tok/sec:  51201.23\n",
      "step1339 | loss: 0.779395341873169 | dt: 320.70ms | tok/sec:  51088.48\n",
      "step1340 | loss: 0.9257967472076416 | dt: 320.21ms | tok/sec:  51167.19\n",
      "step1341 | loss: 0.9038376808166504 | dt: 320.41ms | tok/sec:  51133.84\n",
      "step1342 | loss: 0.8673224449157715 | dt: 319.93ms | tok/sec:  51211.92\n",
      "step1343 | loss: 0.8707746863365173 | dt: 321.08ms | tok/sec:  51027.71\n",
      "step1344 | loss: 0.8630884885787964 | dt: 320.14ms | tok/sec:  51177.36\n",
      "step1345 | loss: 0.8061419725418091 | dt: 320.85ms | tok/sec:  51063.66\n",
      "step1346 | loss: 0.8358899354934692 | dt: 320.88ms | tok/sec:  51059.37\n",
      "step1347 | loss: 0.8135948181152344 | dt: 319.72ms | tok/sec:  51244.61\n",
      "step1348 | loss: 0.8197707533836365 | dt: 319.88ms | tok/sec:  51219.89\n",
      "step1349 | loss: 0.7892711758613586 | dt: 320.93ms | tok/sec:  51051.18\n",
      "step1350 | loss: 0.7957877516746521 | dt: 319.92ms | tok/sec:  51212.72\n",
      "step1351 | loss: 0.8191919326782227 | dt: 320.12ms | tok/sec:  51180.72\n",
      "step1352 | loss: 0.8155652284622192 | dt: 319.66ms | tok/sec:  51254.01\n",
      "step1353 | loss: 0.8859190940856934 | dt: 320.50ms | tok/sec:  51120.07\n",
      "step1354 | loss: 0.8239624500274658 | dt: 319.47ms | tok/sec:  51284.65\n",
      "step1355 | loss: 0.8071924448013306 | dt: 319.98ms | tok/sec:  51203.48\n",
      "step1356 | loss: 0.7408891320228577 | dt: 319.85ms | tok/sec:  51223.86\n",
      "step1357 | loss: 0.748295783996582 | dt: 320.95ms | tok/sec:  51049.20\n",
      "step1358 | loss: 0.781356930732727 | dt: 320.19ms | tok/sec:  51170.01\n",
      "step1359 | loss: 0.7102286219596863 | dt: 319.88ms | tok/sec:  51218.82\n",
      "step1360 | loss: 0.8620065450668335 | dt: 319.83ms | tok/sec:  51227.15\n",
      "step1361 | loss: 0.8048118352890015 | dt: 320.95ms | tok/sec:  51048.75\n",
      "step1362 | loss: 0.7797524929046631 | dt: 320.25ms | tok/sec:  51159.53\n",
      "step1363 | loss: 0.7968084812164307 | dt: 320.94ms | tok/sec:  51049.66\n",
      "step1364 | loss: 0.7807806730270386 | dt: 320.87ms | tok/sec:  51061.57\n",
      "step1365 | loss: 0.7419791221618652 | dt: 320.48ms | tok/sec:  51123.60\n",
      "step1366 | loss: 0.7607587575912476 | dt: 319.43ms | tok/sec:  51290.73\n",
      "step1367 | loss: 0.7177900075912476 | dt: 320.06ms | tok/sec:  51190.17\n",
      "step1368 | loss: 0.7156028747558594 | dt: 320.39ms | tok/sec:  51138.13\n",
      "step1369 | loss: 0.6896172761917114 | dt: 320.61ms | tok/sec:  51102.62\n",
      "step1370 | loss: 0.6976237893104553 | dt: 320.02ms | tok/sec:  51196.27\n",
      "step1371 | loss: 0.7095876932144165 | dt: 320.45ms | tok/sec:  51128.28\n",
      "step1372 | loss: 0.6848391890525818 | dt: 320.33ms | tok/sec:  51148.03\n",
      "step1373 | loss: 0.7479649782180786 | dt: 320.82ms | tok/sec:  51068.93\n",
      "step1374 | loss: 0.7164806127548218 | dt: 319.86ms | tok/sec:  51223.18\n",
      "step1375 | loss: 0.7147711515426636 | dt: 320.84ms | tok/sec:  51066.05\n",
      "step1376 | loss: 0.6947689652442932 | dt: 320.68ms | tok/sec:  51091.45\n",
      "step1377 | loss: 0.696641206741333 | dt: 320.10ms | tok/sec:  51183.92\n",
      "step1378 | loss: 0.716727077960968 | dt: 319.35ms | tok/sec:  51303.52\n",
      "step1379 | loss: 0.6414657831192017 | dt: 321.27ms | tok/sec:  50997.38\n",
      "step1380 | loss: 0.7885267734527588 | dt: 319.90ms | tok/sec:  51216.50\n",
      "step1381 | loss: 0.7455997467041016 | dt: 320.56ms | tok/sec:  51110.33\n",
      "step1382 | loss: 0.7144843339920044 | dt: 320.53ms | tok/sec:  51116.03\n",
      "step1383 | loss: 0.7316552996635437 | dt: 320.69ms | tok/sec:  51089.17\n",
      "step1384 | loss: 0.7565433979034424 | dt: 319.91ms | tok/sec:  51214.82\n",
      "step1385 | loss: 0.6785279512405396 | dt: 320.70ms | tok/sec:  51087.91\n",
      "step1386 | loss: 0.6864944100379944 | dt: 319.44ms | tok/sec:  51289.62\n",
      "step1387 | loss: 0.6477059125900269 | dt: 319.85ms | tok/sec:  51224.09\n",
      "step1388 | loss: 0.6719130277633667 | dt: 320.18ms | tok/sec:  51171.19\n",
      "step1389 | loss: 0.6560219526290894 | dt: 320.71ms | tok/sec:  51086.55\n",
      "step1390 | loss: 0.6804090738296509 | dt: 319.75ms | tok/sec:  51239.75\n",
      "step1391 | loss: 0.6870326995849609 | dt: 321.11ms | tok/sec:  51023.50\n",
      "step1392 | loss: 0.6526919007301331 | dt: 319.65ms | tok/sec:  51255.92\n",
      "step1393 | loss: 0.6841468811035156 | dt: 320.43ms | tok/sec:  51131.89\n",
      "step1394 | loss: 0.6620572209358215 | dt: 320.20ms | tok/sec:  51168.14\n",
      "step1395 | loss: 0.6633390188217163 | dt: 320.81ms | tok/sec:  51070.75\n",
      "step1396 | loss: 0.6167656183242798 | dt: 320.77ms | tok/sec:  51076.45\n",
      "step1397 | loss: 0.591084361076355 | dt: 320.22ms | tok/sec:  51165.21\n",
      "step1398 | loss: 0.6045526266098022 | dt: 319.75ms | tok/sec:  51240.48\n",
      "step1399 | loss: 0.5475351810455322 | dt: 320.81ms | tok/sec:  51070.07\n",
      "step1400 | loss: 0.7106459140777588 | dt: 320.91ms | tok/sec:  51054.36\n",
      "step1401 | loss: 0.6826518774032593 | dt: 319.63ms | tok/sec:  51259.13\n",
      "step1402 | loss: 0.6356624960899353 | dt: 320.93ms | tok/sec:  51050.95\n",
      "step1403 | loss: 0.6647857427597046 | dt: 320.69ms | tok/sec:  51089.93\n",
      "step1404 | loss: 0.6390441060066223 | dt: 319.92ms | tok/sec:  51212.91\n",
      "step1405 | loss: 0.6000073552131653 | dt: 320.60ms | tok/sec:  51104.33\n",
      "step1406 | loss: 0.6259202361106873 | dt: 319.98ms | tok/sec:  51203.98\n",
      "step1407 | loss: 0.6000038981437683 | dt: 319.38ms | tok/sec:  51299.81\n",
      "step1408 | loss: 0.5838762521743774 | dt: 320.00ms | tok/sec:  51199.29\n",
      "step1409 | loss: 0.5627058744430542 | dt: 320.35ms | tok/sec:  51143.92\n",
      "step1410 | loss: 0.5872998237609863 | dt: 320.01ms | tok/sec:  51198.94\n",
      "step1411 | loss: 0.5913763046264648 | dt: 319.78ms | tok/sec:  51234.86\n",
      "step1412 | loss: 0.553498387336731 | dt: 319.82ms | tok/sec:  51229.48\n",
      "step1413 | loss: 0.6078091263771057 | dt: 319.47ms | tok/sec:  51284.65\n",
      "step1414 | loss: 0.5900543928146362 | dt: 319.49ms | tok/sec:  51281.70\n",
      "step1415 | loss: 0.5797404646873474 | dt: 320.13ms | tok/sec:  51179.50\n",
      "step1416 | loss: 0.5446306467056274 | dt: 319.83ms | tok/sec:  51227.99\n",
      "step1417 | loss: 0.53821861743927 | dt: 319.98ms | tok/sec:  51203.29\n",
      "step1418 | loss: 0.5736804008483887 | dt: 320.32ms | tok/sec:  51149.52\n",
      "step1419 | loss: 0.5203791260719299 | dt: 320.50ms | tok/sec:  51119.72\n",
      "step1420 | loss: 0.6179962158203125 | dt: 320.18ms | tok/sec:  51171.65\n",
      "step1421 | loss: 0.5578818917274475 | dt: 320.51ms | tok/sec:  51118.01\n",
      "step1422 | loss: 0.5246326923370361 | dt: 320.16ms | tok/sec:  51174.43\n",
      "step1423 | loss: 0.5499739646911621 | dt: 321.13ms | tok/sec:  51019.94\n",
      "step1424 | loss: 0.5354440808296204 | dt: 320.27ms | tok/sec:  51157.06\n",
      "step1425 | loss: 0.5088544487953186 | dt: 320.76ms | tok/sec:  51078.88\n",
      "step1426 | loss: 0.533274233341217 | dt: 319.71ms | tok/sec:  51246.10\n",
      "step1427 | loss: 0.48987507820129395 | dt: 320.56ms | tok/sec:  51110.75\n",
      "step1428 | loss: 0.5018617510795593 | dt: 319.67ms | tok/sec:  51252.36\n",
      "step1429 | loss: 0.5106295943260193 | dt: 319.93ms | tok/sec:  51211.76\n",
      "step1430 | loss: 0.5227468013763428 | dt: 319.64ms | tok/sec:  51257.75\n",
      "step1431 | loss: 0.5202651023864746 | dt: 320.68ms | tok/sec:  51090.99\n",
      "step1432 | loss: 0.4962693750858307 | dt: 319.50ms | tok/sec:  51280.70\n",
      "step1433 | loss: 0.5665842294692993 | dt: 321.00ms | tok/sec:  51040.56\n",
      "step1434 | loss: 0.5470709800720215 | dt: 319.92ms | tok/sec:  51212.45\n",
      "step1435 | loss: 0.4997641146183014 | dt: 319.97ms | tok/sec:  51205.50\n",
      "step1436 | loss: 0.46629488468170166 | dt: 319.83ms | tok/sec:  51226.99\n",
      "step1437 | loss: 0.43613094091415405 | dt: 320.59ms | tok/sec:  51105.12\n",
      "step1438 | loss: 0.4710959196090698 | dt: 319.54ms | tok/sec:  51274.05\n",
      "step1439 | loss: 0.42009979486465454 | dt: 321.20ms | tok/sec:  51008.05\n",
      "step1440 | loss: 0.5309226512908936 | dt: 320.00ms | tok/sec:  51199.48\n",
      "step1441 | loss: 0.5378329157829285 | dt: 320.30ms | tok/sec:  51151.42\n",
      "step1442 | loss: 0.5176504254341125 | dt: 320.41ms | tok/sec:  51135.13\n",
      "step1443 | loss: 0.5105723142623901 | dt: 320.31ms | tok/sec:  51150.35\n",
      "step1444 | loss: 0.49294084310531616 | dt: 319.92ms | tok/sec:  51213.52\n",
      "step1445 | loss: 0.46383994817733765 | dt: 319.89ms | tok/sec:  51216.84\n",
      "step1446 | loss: 0.48505157232284546 | dt: 320.27ms | tok/sec:  51156.45\n",
      "step1447 | loss: 0.44704627990722656 | dt: 320.48ms | tok/sec:  51123.83\n",
      "step1448 | loss: 0.45489394664764404 | dt: 321.13ms | tok/sec:  51020.17\n",
      "step1449 | loss: 0.42703235149383545 | dt: 320.70ms | tok/sec:  51088.07\n",
      "step1450 | loss: 0.4330423176288605 | dt: 320.89ms | tok/sec:  51057.74\n",
      "step1451 | loss: 0.4456753730773926 | dt: 320.80ms | tok/sec:  51071.55\n",
      "step1452 | loss: 0.41742539405822754 | dt: 319.64ms | tok/sec:  51258.44\n",
      "step1453 | loss: 0.4699961841106415 | dt: 320.74ms | tok/sec:  51081.76\n",
      "step1454 | loss: 0.44769716262817383 | dt: 320.95ms | tok/sec:  51048.29\n",
      "step1455 | loss: 0.43914714455604553 | dt: 319.73ms | tok/sec:  51243.46\n",
      "step1456 | loss: 0.4397124946117401 | dt: 320.32ms | tok/sec:  51148.30\n",
      "step1457 | loss: 0.42201200127601624 | dt: 319.99ms | tok/sec:  51201.77\n",
      "step1458 | loss: 0.4324894845485687 | dt: 319.39ms | tok/sec:  51298.50\n",
      "step1459 | loss: 0.3554668426513672 | dt: 319.74ms | tok/sec:  51242.08\n",
      "step1460 | loss: 0.4467747211456299 | dt: 320.75ms | tok/sec:  51080.47\n",
      "step1461 | loss: 0.4242557883262634 | dt: 320.89ms | tok/sec:  51057.55\n",
      "step1462 | loss: 0.4162898063659668 | dt: 319.58ms | tok/sec:  51267.54\n",
      "step1463 | loss: 0.4356711506843567 | dt: 320.22ms | tok/sec:  51164.10\n",
      "step1464 | loss: 0.4399884343147278 | dt: 320.77ms | tok/sec:  51077.21\n",
      "step1465 | loss: 0.4337376356124878 | dt: 320.50ms | tok/sec:  51120.37\n",
      "step1466 | loss: 0.4063381552696228 | dt: 319.91ms | tok/sec:  51213.79\n",
      "step1467 | loss: 0.38461077213287354 | dt: 320.72ms | tok/sec:  51084.84\n",
      "step1468 | loss: 0.39090201258659363 | dt: 319.91ms | tok/sec:  51213.71\n",
      "step1469 | loss: 0.3725616931915283 | dt: 321.52ms | tok/sec:  50957.78\n",
      "step1470 | loss: 0.37976592779159546 | dt: 320.33ms | tok/sec:  51148.03\n",
      "step1471 | loss: 0.39338064193725586 | dt: 319.80ms | tok/sec:  51232.72\n",
      "step1472 | loss: 0.37267062067985535 | dt: 320.05ms | tok/sec:  51191.35\n",
      "step1473 | loss: 0.3705686330795288 | dt: 320.06ms | tok/sec:  51189.87\n",
      "step1474 | loss: 0.3594666123390198 | dt: 319.90ms | tok/sec:  51216.27\n",
      "step1475 | loss: 0.36722490191459656 | dt: 320.97ms | tok/sec:  51045.30\n",
      "step1476 | loss: 0.3518471121788025 | dt: 320.84ms | tok/sec:  51066.62\n",
      "step1477 | loss: 0.32029545307159424 | dt: 320.84ms | tok/sec:  51065.36\n",
      "step1478 | loss: 0.3442513942718506 | dt: 319.77ms | tok/sec:  51236.31\n",
      "step1479 | loss: 0.30814826488494873 | dt: 320.97ms | tok/sec:  51044.88\n",
      "step1480 | loss: 0.390864759683609 | dt: 319.76ms | tok/sec:  51237.96\n",
      "step1481 | loss: 0.37879687547683716 | dt: 320.48ms | tok/sec:  51123.94\n",
      "step1482 | loss: 0.3707079589366913 | dt: 321.16ms | tok/sec:  51015.13\n",
      "step1483 | loss: 0.3559340834617615 | dt: 321.01ms | tok/sec:  51039.42\n",
      "step1484 | loss: 0.3438641428947449 | dt: 319.53ms | tok/sec:  51275.62\n",
      "step1485 | loss: 0.3528110384941101 | dt: 321.05ms | tok/sec:  51032.52\n",
      "step1486 | loss: 0.34158891439437866 | dt: 320.30ms | tok/sec:  51152.37\n",
      "step1487 | loss: 0.32246875762939453 | dt: 320.83ms | tok/sec:  51068.10\n",
      "step1488 | loss: 0.3375244140625 | dt: 320.30ms | tok/sec:  51152.64\n",
      "step1489 | loss: 0.3337116837501526 | dt: 320.39ms | tok/sec:  51137.15\n",
      "step1490 | loss: 0.3341359496116638 | dt: 319.64ms | tok/sec:  51258.14\n",
      "step1491 | loss: 0.32305851578712463 | dt: 320.37ms | tok/sec:  51140.46\n",
      "step1492 | loss: 0.31245172023773193 | dt: 319.85ms | tok/sec:  51224.47\n",
      "step1493 | loss: 0.33278530836105347 | dt: 319.82ms | tok/sec:  51228.22\n",
      "step1494 | loss: 0.32599613070487976 | dt: 319.90ms | tok/sec:  51215.85\n",
      "step1495 | loss: 0.33863580226898193 | dt: 320.11ms | tok/sec:  51183.12\n",
      "step1496 | loss: 0.3206091523170471 | dt: 320.14ms | tok/sec:  51177.13\n",
      "step1497 | loss: 0.27880287170410156 | dt: 320.81ms | tok/sec:  51071.28\n",
      "step1498 | loss: 0.293948769569397 | dt: 319.89ms | tok/sec:  51217.64\n",
      "step1499 | loss: 0.2621546983718872 | dt: 320.42ms | tok/sec:  51132.77\n",
      "Prediction at step 1500: \n",
      " : This is a fixed text used for prediction.A hath nothing that, ho!\n",
      "Ifness \n",
      "\n",
      "step1500 | loss: 0.33771297335624695 | dt: 318.91ms | tok/sec:  51374.25\n",
      "step1501 | loss: 0.3218425214290619 | dt: 319.31ms | tok/sec:  51311.26\n",
      "step1502 | loss: 0.3216014504432678 | dt: 320.43ms | tok/sec:  51131.93\n",
      "step1503 | loss: 0.2993805408477783 | dt: 321.14ms | tok/sec:  51018.47\n",
      "step1504 | loss: 0.29658421874046326 | dt: 319.50ms | tok/sec:  51280.67\n",
      "step1505 | loss: 0.28184187412261963 | dt: 319.45ms | tok/sec:  51288.40\n",
      "step1506 | loss: 0.2774084508419037 | dt: 321.90ms | tok/sec:  50897.21\n",
      "step1507 | loss: 0.28470703959465027 | dt: 320.46ms | tok/sec:  51127.29\n",
      "step1508 | loss: 0.29811978340148926 | dt: 319.68ms | tok/sec:  51251.94\n",
      "step1509 | loss: 0.2741415202617645 | dt: 321.29ms | tok/sec:  50994.58\n",
      "step1510 | loss: 0.2688504755496979 | dt: 320.58ms | tok/sec:  51106.72\n",
      "step1511 | loss: 0.2757243812084198 | dt: 320.88ms | tok/sec:  51060.09\n",
      "step1512 | loss: 0.2552071809768677 | dt: 319.83ms | tok/sec:  51227.91\n",
      "step1513 | loss: 0.30565619468688965 | dt: 321.03ms | tok/sec:  51035.97\n",
      "step1514 | loss: 0.2928621470928192 | dt: 319.72ms | tok/sec:  51244.41\n",
      "step1515 | loss: 0.27555498480796814 | dt: 320.92ms | tok/sec:  51053.45\n",
      "step1516 | loss: 0.26262223720550537 | dt: 321.23ms | tok/sec:  51004.19\n",
      "step1517 | loss: 0.24424730241298676 | dt: 320.20ms | tok/sec:  51168.25\n",
      "step1518 | loss: 0.2620159387588501 | dt: 320.73ms | tok/sec:  51083.43\n",
      "step1519 | loss: 0.23356246948242188 | dt: 320.96ms | tok/sec:  51046.55\n",
      "step1520 | loss: 0.27228569984436035 | dt: 320.15ms | tok/sec:  51176.33\n",
      "step1521 | loss: 0.2539469003677368 | dt: 320.88ms | tok/sec:  51059.07\n",
      "step1522 | loss: 0.23944300413131714 | dt: 319.70ms | tok/sec:  51247.59\n",
      "step1523 | loss: 0.2458297163248062 | dt: 319.76ms | tok/sec:  51237.65\n",
      "step1524 | loss: 0.25287705659866333 | dt: 320.44ms | tok/sec:  51129.92\n",
      "step1525 | loss: 0.259284645318985 | dt: 319.57ms | tok/sec:  51269.46\n",
      "step1526 | loss: 0.2481507509946823 | dt: 320.96ms | tok/sec:  51046.74\n",
      "step1527 | loss: 0.2413385510444641 | dt: 321.08ms | tok/sec:  51027.10\n",
      "step1528 | loss: 0.23514318466186523 | dt: 320.45ms | tok/sec:  51128.39\n",
      "step1529 | loss: 0.21333277225494385 | dt: 320.35ms | tok/sec:  51144.57\n",
      "step1530 | loss: 0.21720954775810242 | dt: 320.37ms | tok/sec:  51141.10\n",
      "step1531 | loss: 0.2185288369655609 | dt: 320.90ms | tok/sec:  51056.30\n",
      "step1532 | loss: 0.20508664846420288 | dt: 320.17ms | tok/sec:  51173.55\n",
      "step1533 | loss: 0.23503026366233826 | dt: 319.95ms | tok/sec:  51207.22\n",
      "step1534 | loss: 0.2137741893529892 | dt: 320.18ms | tok/sec:  51171.91\n",
      "step1535 | loss: 0.21529686450958252 | dt: 319.96ms | tok/sec:  51206.88\n",
      "step1536 | loss: 0.2047458291053772 | dt: 320.35ms | tok/sec:  51144.57\n",
      "step1537 | loss: 0.18954479694366455 | dt: 320.63ms | tok/sec:  51099.27\n",
      "step1538 | loss: 0.20465800166130066 | dt: 320.70ms | tok/sec:  51088.79\n",
      "step1539 | loss: 0.1777336597442627 | dt: 320.93ms | tok/sec:  51051.14\n",
      "step1540 | loss: 0.20222581923007965 | dt: 321.03ms | tok/sec:  51036.20\n",
      "step1541 | loss: 0.19708125293254852 | dt: 320.84ms | tok/sec:  51066.43\n",
      "step1542 | loss: 0.18170523643493652 | dt: 319.56ms | tok/sec:  51270.60\n",
      "step1543 | loss: 0.18099980056285858 | dt: 320.51ms | tok/sec:  51119.00\n",
      "step1544 | loss: 0.17814096808433533 | dt: 320.47ms | tok/sec:  51124.74\n",
      "step1545 | loss: 0.1716189682483673 | dt: 320.95ms | tok/sec:  51047.69\n",
      "step1546 | loss: 0.1671425998210907 | dt: 319.81ms | tok/sec:  51230.62\n",
      "step1547 | loss: 0.16674748063087463 | dt: 320.82ms | tok/sec:  51069.04\n",
      "step1548 | loss: 0.16892766952514648 | dt: 320.13ms | tok/sec:  51179.80\n",
      "step1549 | loss: 0.162704735994339 | dt: 321.36ms | tok/sec:  50983.68\n",
      "step1550 | loss: 0.16839563846588135 | dt: 320.95ms | tok/sec:  51048.52\n",
      "step1551 | loss: 0.1553720235824585 | dt: 320.85ms | tok/sec:  51064.72\n",
      "step1552 | loss: 0.14060774445533752 | dt: 319.87ms | tok/sec:  51221.31\n",
      "step1553 | loss: 0.16033229231834412 | dt: 320.98ms | tok/sec:  51042.95\n",
      "step1554 | loss: 0.15269771218299866 | dt: 319.48ms | tok/sec:  51283.80\n",
      "step1555 | loss: 0.14980006217956543 | dt: 321.11ms | tok/sec:  51023.32\n",
      "step1556 | loss: 0.14428219199180603 | dt: 319.69ms | tok/sec:  51248.85\n",
      "step1557 | loss: 0.1268138885498047 | dt: 320.63ms | tok/sec:  51099.80\n",
      "step1558 | loss: 0.13565605878829956 | dt: 321.03ms | tok/sec:  51035.63\n",
      "step1559 | loss: 0.12208898365497589 | dt: 321.06ms | tok/sec:  51031.39\n",
      "step1560 | loss: 0.1458081156015396 | dt: 319.61ms | tok/sec:  51262.65\n",
      "step1561 | loss: 0.14597810804843903 | dt: 320.58ms | tok/sec:  51107.90\n",
      "step1562 | loss: 0.13516388833522797 | dt: 321.15ms | tok/sec:  51015.97\n",
      "step1563 | loss: 0.13367518782615662 | dt: 320.20ms | tok/sec:  51168.48\n",
      "step1564 | loss: 0.12653054296970367 | dt: 320.11ms | tok/sec:  51182.74\n",
      "step1565 | loss: 0.1215808093547821 | dt: 321.51ms | tok/sec:  50958.92\n",
      "step1566 | loss: 0.12074274569749832 | dt: 320.88ms | tok/sec:  51059.71\n",
      "step1567 | loss: 0.11491670459508896 | dt: 320.44ms | tok/sec:  51129.80\n",
      "step1568 | loss: 0.11254283040761948 | dt: 320.11ms | tok/sec:  51182.58\n",
      "step1569 | loss: 0.10861726105213165 | dt: 320.50ms | tok/sec:  51120.26\n",
      "step1570 | loss: 0.11527395248413086 | dt: 320.88ms | tok/sec:  51059.33\n",
      "step1571 | loss: 0.10752647370100021 | dt: 320.00ms | tok/sec:  51200.58\n",
      "step1572 | loss: 0.09814362227916718 | dt: 321.05ms | tok/sec:  51032.03\n",
      "step1573 | loss: 0.1166534423828125 | dt: 320.48ms | tok/sec:  51123.37\n",
      "step1574 | loss: 0.11349336802959442 | dt: 320.86ms | tok/sec:  51062.94\n",
      "step1575 | loss: 0.11181315034627914 | dt: 320.94ms | tok/sec:  51049.47\n",
      "step1576 | loss: 0.11123000085353851 | dt: 320.16ms | tok/sec:  51174.43\n",
      "step1577 | loss: 0.09199399501085281 | dt: 320.57ms | tok/sec:  51108.85\n",
      "step1578 | loss: 0.09042631834745407 | dt: 320.61ms | tok/sec:  51101.82\n",
      "step1579 | loss: 0.08255510032176971 | dt: 321.02ms | tok/sec:  51038.06\n",
      "step1580 | loss: 0.0946759432554245 | dt: 321.02ms | tok/sec:  51037.15\n",
      "step1581 | loss: 0.08938688039779663 | dt: 320.97ms | tok/sec:  51045.71\n",
      "step1582 | loss: 0.08714407682418823 | dt: 321.00ms | tok/sec:  51040.63\n",
      "step1583 | loss: 0.08641218394041061 | dt: 320.48ms | tok/sec:  51123.91\n",
      "step1584 | loss: 0.08997289836406708 | dt: 320.58ms | tok/sec:  51107.90\n",
      "step1585 | loss: 0.08899891376495361 | dt: 320.47ms | tok/sec:  51124.90\n",
      "step1586 | loss: 0.08829011768102646 | dt: 320.46ms | tok/sec:  51126.49\n",
      "step1587 | loss: 0.08469939231872559 | dt: 320.39ms | tok/sec:  51137.34\n",
      "step1588 | loss: 0.07695618271827698 | dt: 320.27ms | tok/sec:  51156.48\n",
      "step1589 | loss: 0.07269476354122162 | dt: 320.89ms | tok/sec:  51057.28\n",
      "step1590 | loss: 0.07753589004278183 | dt: 320.40ms | tok/sec:  51136.73\n",
      "step1591 | loss: 0.06934476643800735 | dt: 321.06ms | tok/sec:  51030.48\n",
      "step1592 | loss: 0.06727448105812073 | dt: 320.26ms | tok/sec:  51157.85\n",
      "step1593 | loss: 0.07974639534950256 | dt: 320.95ms | tok/sec:  51047.91\n",
      "step1594 | loss: 0.07747854292392731 | dt: 319.71ms | tok/sec:  51246.97\n",
      "step1595 | loss: 0.07492262125015259 | dt: 321.04ms | tok/sec:  51034.83\n",
      "step1596 | loss: 0.0719476044178009 | dt: 319.68ms | tok/sec:  51250.91\n",
      "step1597 | loss: 0.06115908920764923 | dt: 321.00ms | tok/sec:  51039.95\n",
      "step1598 | loss: 0.06427785754203796 | dt: 320.02ms | tok/sec:  51196.46\n",
      "step1599 | loss: 0.05867777764797211 | dt: 319.68ms | tok/sec:  51251.98\n",
      "step1600 | loss: 0.06575950980186462 | dt: 319.69ms | tok/sec:  51249.15\n",
      "step1601 | loss: 0.062136583030223846 | dt: 320.07ms | tok/sec:  51188.72\n",
      "step1602 | loss: 0.05985014885663986 | dt: 320.26ms | tok/sec:  51158.43\n",
      "step1603 | loss: 0.056609831750392914 | dt: 321.35ms | tok/sec:  50984.78\n",
      "step1604 | loss: 0.06101793795824051 | dt: 320.04ms | tok/sec:  51193.22\n",
      "step1605 | loss: 0.057303205132484436 | dt: 319.71ms | tok/sec:  51246.40\n",
      "step1606 | loss: 0.05718592554330826 | dt: 321.00ms | tok/sec:  51040.56\n",
      "step1607 | loss: 0.05341650918126106 | dt: 320.94ms | tok/sec:  51049.36\n",
      "step1608 | loss: 0.05298975855112076 | dt: 320.86ms | tok/sec:  51062.18\n",
      "step1609 | loss: 0.049636244773864746 | dt: 321.13ms | tok/sec:  51020.21\n",
      "step1610 | loss: 0.0518791563808918 | dt: 321.08ms | tok/sec:  51027.60\n",
      "step1611 | loss: 0.04595821350812912 | dt: 320.93ms | tok/sec:  51051.59\n",
      "step1612 | loss: 0.042175088077783585 | dt: 320.16ms | tok/sec:  51173.93\n",
      "step1613 | loss: 0.051327288150787354 | dt: 320.87ms | tok/sec:  51061.11\n",
      "step1614 | loss: 0.04953888803720474 | dt: 320.05ms | tok/sec:  51192.23\n",
      "step1615 | loss: 0.04835275560617447 | dt: 321.27ms | tok/sec:  50998.32\n",
      "step1616 | loss: 0.04872904717922211 | dt: 321.07ms | tok/sec:  51029.19\n",
      "step1617 | loss: 0.04264036938548088 | dt: 320.95ms | tok/sec:  51048.90\n",
      "step1618 | loss: 0.04634229093790054 | dt: 321.19ms | tok/sec:  51010.78\n",
      "step1619 | loss: 0.046388741582632065 | dt: 321.08ms | tok/sec:  51027.56\n",
      "step1620 | loss: 0.04656023532152176 | dt: 319.68ms | tok/sec:  51251.75\n",
      "step1621 | loss: 0.04363306611776352 | dt: 321.15ms | tok/sec:  51017.03\n",
      "step1622 | loss: 0.04360733926296234 | dt: 319.80ms | tok/sec:  51232.61\n",
      "step1623 | loss: 0.03946226090192795 | dt: 320.69ms | tok/sec:  51089.70\n",
      "step1624 | loss: 0.044203728437423706 | dt: 320.04ms | tok/sec:  51193.79\n",
      "step1625 | loss: 0.03819149360060692 | dt: 321.30ms | tok/sec:  50992.38\n",
      "step1626 | loss: 0.03797849267721176 | dt: 320.22ms | tok/sec:  51164.60\n",
      "step1627 | loss: 0.03600795194506645 | dt: 320.94ms | tok/sec:  51050.68\n",
      "step1628 | loss: 0.034579262137413025 | dt: 320.29ms | tok/sec:  51154.16\n",
      "step1629 | loss: 0.03282439708709717 | dt: 319.77ms | tok/sec:  51237.50\n",
      "step1630 | loss: 0.03461654856801033 | dt: 319.89ms | tok/sec:  51217.87\n",
      "step1631 | loss: 0.031195098534226418 | dt: 320.00ms | tok/sec:  51200.47\n",
      "step1632 | loss: 0.030274933204054832 | dt: 320.55ms | tok/sec:  51112.84\n",
      "step1633 | loss: 0.03704395890235901 | dt: 320.89ms | tok/sec:  51057.81\n",
      "step1634 | loss: 0.03698675334453583 | dt: 321.03ms | tok/sec:  51035.59\n",
      "step1635 | loss: 0.03548019751906395 | dt: 319.92ms | tok/sec:  51213.21\n",
      "step1636 | loss: 0.034700047224760056 | dt: 319.90ms | tok/sec:  51215.69\n",
      "step1637 | loss: 0.029548069462180138 | dt: 321.52ms | tok/sec:  50957.94\n",
      "step1638 | loss: 0.03133426606655121 | dt: 319.92ms | tok/sec:  51213.40\n",
      "step1639 | loss: 0.027288058772683144 | dt: 320.19ms | tok/sec:  51169.40\n",
      "step1640 | loss: 0.03215012699365616 | dt: 320.87ms | tok/sec:  51060.54\n",
      "step1641 | loss: 0.028995217755436897 | dt: 321.02ms | tok/sec:  51036.92\n",
      "step1642 | loss: 0.03024870902299881 | dt: 319.45ms | tok/sec:  51287.36\n",
      "step1643 | loss: 0.02776595950126648 | dt: 320.64ms | tok/sec:  51097.03\n",
      "step1644 | loss: 0.03259215131402016 | dt: 321.02ms | tok/sec:  51037.00\n",
      "step1645 | loss: 0.027550656348466873 | dt: 320.79ms | tok/sec:  51074.47\n",
      "step1646 | loss: 0.027930432930588722 | dt: 319.52ms | tok/sec:  51277.11\n",
      "step1647 | loss: 0.027429942041635513 | dt: 321.56ms | tok/sec:  50951.10\n",
      "step1648 | loss: 0.02679743804037571 | dt: 319.99ms | tok/sec:  51201.00\n",
      "step1649 | loss: 0.02529725804924965 | dt: 320.48ms | tok/sec:  51122.92\n",
      "step1650 | loss: 0.025408174842596054 | dt: 321.00ms | tok/sec:  51041.09\n",
      "step1651 | loss: 0.023022187873721123 | dt: 320.76ms | tok/sec:  51078.99\n",
      "step1652 | loss: 0.02273068018257618 | dt: 320.35ms | tok/sec:  51144.53\n",
      "step1653 | loss: 0.02554001472890377 | dt: 320.90ms | tok/sec:  51055.84\n",
      "step1654 | loss: 0.026351626962423325 | dt: 319.85ms | tok/sec:  51224.44\n",
      "step1655 | loss: 0.026207707822322845 | dt: 320.97ms | tok/sec:  51045.68\n",
      "step1656 | loss: 0.025195065885782242 | dt: 320.17ms | tok/sec:  51173.59\n",
      "step1657 | loss: 0.022622421383857727 | dt: 321.08ms | tok/sec:  51028.13\n",
      "step1658 | loss: 0.023760881274938583 | dt: 320.10ms | tok/sec:  51184.41\n",
      "step1659 | loss: 0.019837964326143265 | dt: 320.93ms | tok/sec:  51051.10\n",
      "step1660 | loss: 0.023739922791719437 | dt: 319.89ms | tok/sec:  51217.76\n",
      "step1661 | loss: 0.022026918828487396 | dt: 321.07ms | tok/sec:  51029.83\n",
      "step1662 | loss: 0.023448094725608826 | dt: 320.93ms | tok/sec:  51051.48\n",
      "step1663 | loss: 0.021703574806451797 | dt: 320.46ms | tok/sec:  51126.42\n",
      "step1664 | loss: 0.030655477195978165 | dt: 319.98ms | tok/sec:  51203.60\n",
      "step1665 | loss: 0.02128332480788231 | dt: 320.54ms | tok/sec:  51113.41\n",
      "step1666 | loss: 0.021343816071748734 | dt: 319.73ms | tok/sec:  51242.47\n",
      "step1667 | loss: 0.020866326987743378 | dt: 321.68ms | tok/sec:  50933.35\n",
      "step1668 | loss: 0.02079477161169052 | dt: 319.81ms | tok/sec:  51230.58\n",
      "step1669 | loss: 0.019942697137594223 | dt: 320.98ms | tok/sec:  51043.63\n",
      "step1670 | loss: 0.01995120383799076 | dt: 321.26ms | tok/sec:  50998.44\n",
      "step1671 | loss: 0.017944028601050377 | dt: 320.51ms | tok/sec:  51118.20\n",
      "step1672 | loss: 0.018495215103030205 | dt: 321.11ms | tok/sec:  51023.16\n",
      "step1673 | loss: 0.019769590348005295 | dt: 321.33ms | tok/sec:  50988.03\n",
      "step1674 | loss: 0.020085319876670837 | dt: 319.68ms | tok/sec:  51251.26\n",
      "step1675 | loss: 0.01984769105911255 | dt: 320.96ms | tok/sec:  51046.97\n",
      "step1676 | loss: 0.0189601331949234 | dt: 320.40ms | tok/sec:  51136.12\n",
      "step1677 | loss: 0.01781977154314518 | dt: 320.88ms | tok/sec:  51059.75\n",
      "step1678 | loss: 0.019128242507576942 | dt: 320.64ms | tok/sec:  51098.06\n",
      "step1679 | loss: 0.016420874744653702 | dt: 320.93ms | tok/sec:  51051.90\n",
      "step1680 | loss: 0.01926323026418686 | dt: 320.06ms | tok/sec:  51190.29\n",
      "step1681 | loss: 0.01778995618224144 | dt: 320.93ms | tok/sec:  51051.63\n",
      "step1682 | loss: 0.01927010901272297 | dt: 321.03ms | tok/sec:  51035.78\n",
      "step1683 | loss: 0.01785546913743019 | dt: 320.52ms | tok/sec:  51116.57\n",
      "step1684 | loss: 0.023565292358398438 | dt: 320.15ms | tok/sec:  51175.99\n",
      "step1685 | loss: 0.016830116510391235 | dt: 321.19ms | tok/sec:  51010.70\n",
      "step1686 | loss: 0.016811296343803406 | dt: 320.00ms | tok/sec:  51200.51\n",
      "step1687 | loss: 0.016965128481388092 | dt: 320.62ms | tok/sec:  51100.22\n",
      "step1688 | loss: 0.016579879447817802 | dt: 320.06ms | tok/sec:  51190.74\n",
      "step1689 | loss: 0.016190065070986748 | dt: 319.97ms | tok/sec:  51205.50\n",
      "step1690 | loss: 0.016478314995765686 | dt: 319.86ms | tok/sec:  51222.11\n",
      "step1691 | loss: 0.015545841306447983 | dt: 320.67ms | tok/sec:  51093.50\n",
      "step1692 | loss: 0.015953611582517624 | dt: 320.75ms | tok/sec:  51080.43\n",
      "step1693 | loss: 0.0163288377225399 | dt: 320.87ms | tok/sec:  51061.87\n",
      "step1694 | loss: 0.016369305551052094 | dt: 319.70ms | tok/sec:  51247.89\n",
      "step1695 | loss: 0.016364146023988724 | dt: 321.13ms | tok/sec:  51019.34\n",
      "step1696 | loss: 0.015196384862065315 | dt: 320.07ms | tok/sec:  51188.04\n",
      "step1697 | loss: 0.014739368110895157 | dt: 320.83ms | tok/sec:  51067.26\n",
      "step1698 | loss: 0.01626233197748661 | dt: 319.82ms | tok/sec:  51228.48\n",
      "step1699 | loss: 0.01377925556153059 | dt: 319.69ms | tok/sec:  51249.50\n",
      "step1700 | loss: 0.015862371772527695 | dt: 319.55ms | tok/sec:  51271.87\n",
      "step1701 | loss: 0.014853663742542267 | dt: 320.36ms | tok/sec:  51142.17\n",
      "step1702 | loss: 0.016236871480941772 | dt: 319.94ms | tok/sec:  51209.85\n",
      "step1703 | loss: 0.01534984540194273 | dt: 319.54ms | tok/sec:  51273.24\n",
      "step1704 | loss: 0.024279136210680008 | dt: 319.50ms | tok/sec:  51279.75\n",
      "step1705 | loss: 0.01455000415444374 | dt: 320.86ms | tok/sec:  51063.43\n",
      "step1706 | loss: 0.014414526522159576 | dt: 319.61ms | tok/sec:  51262.80\n",
      "step1707 | loss: 0.014646675437688828 | dt: 319.51ms | tok/sec:  51278.79\n",
      "step1708 | loss: 0.014311392791569233 | dt: 320.76ms | tok/sec:  51078.27\n",
      "step1709 | loss: 0.013937950134277344 | dt: 320.70ms | tok/sec:  51088.90\n",
      "step1710 | loss: 0.01419825293123722 | dt: 320.00ms | tok/sec:  51200.09\n",
      "step1711 | loss: 0.013300985097885132 | dt: 320.07ms | tok/sec:  51188.87\n",
      "step1712 | loss: 0.01407762710005045 | dt: 321.29ms | tok/sec:  50993.78\n",
      "step1713 | loss: 0.014291530475020409 | dt: 320.86ms | tok/sec:  51062.25\n",
      "step1714 | loss: 0.014429628849029541 | dt: 320.14ms | tok/sec:  51176.90\n",
      "step1715 | loss: 0.014233073219656944 | dt: 321.51ms | tok/sec:  50960.01\n",
      "step1716 | loss: 0.01365172490477562 | dt: 319.86ms | tok/sec:  51221.99\n",
      "step1717 | loss: 0.01313619315624237 | dt: 320.89ms | tok/sec:  51057.66\n",
      "step1718 | loss: 0.014440841972827911 | dt: 321.17ms | tok/sec:  51014.00\n",
      "step1719 | loss: 0.012205477803945541 | dt: 320.05ms | tok/sec:  51192.73\n",
      "step1720 | loss: 0.014143666252493858 | dt: 320.45ms | tok/sec:  51128.51\n",
      "step1721 | loss: 0.013065348379313946 | dt: 321.13ms | tok/sec:  51019.98\n",
      "step1722 | loss: 0.014525314792990685 | dt: 319.82ms | tok/sec:  51229.48\n",
      "step1723 | loss: 0.012708542868494987 | dt: 321.07ms | tok/sec:  51029.42\n",
      "step1724 | loss: 0.015276282094419003 | dt: 319.67ms | tok/sec:  51252.10\n",
      "step1725 | loss: 0.012881314381957054 | dt: 320.99ms | tok/sec:  51042.53\n",
      "step1726 | loss: 0.012821308337152004 | dt: 320.82ms | tok/sec:  51068.51\n",
      "step1727 | loss: 0.013271518051624298 | dt: 320.93ms | tok/sec:  51050.91\n",
      "step1728 | loss: 0.012822994962334633 | dt: 319.60ms | tok/sec:  51264.29\n",
      "step1729 | loss: 0.012717200443148613 | dt: 320.90ms | tok/sec:  51056.30\n",
      "step1730 | loss: 0.012862002477049828 | dt: 320.63ms | tok/sec:  51099.23\n",
      "step1731 | loss: 0.012263813987374306 | dt: 320.99ms | tok/sec:  51041.43\n",
      "step1732 | loss: 0.012841437011957169 | dt: 320.58ms | tok/sec:  51107.41\n",
      "step1733 | loss: 0.012705803848803043 | dt: 320.79ms | tok/sec:  51073.79\n",
      "step1734 | loss: 0.01274019107222557 | dt: 319.77ms | tok/sec:  51236.47\n",
      "step1735 | loss: 0.012878986075520515 | dt: 320.55ms | tok/sec:  51112.69\n",
      "step1736 | loss: 0.01191866397857666 | dt: 320.24ms | tok/sec:  51161.13\n",
      "step1737 | loss: 0.011857048608362675 | dt: 320.22ms | tok/sec:  51164.90\n",
      "step1738 | loss: 0.013162970542907715 | dt: 320.11ms | tok/sec:  51182.70\n",
      "step1739 | loss: 0.011157087981700897 | dt: 321.17ms | tok/sec:  51013.92\n",
      "step1740 | loss: 0.012637462466955185 | dt: 320.78ms | tok/sec:  51074.74\n",
      "step1741 | loss: 0.011889372952282429 | dt: 320.63ms | tok/sec:  51100.11\n",
      "step1742 | loss: 0.013163620606064796 | dt: 320.35ms | tok/sec:  51144.76\n",
      "step1743 | loss: 0.011347062885761261 | dt: 321.30ms | tok/sec:  50992.34\n",
      "step1744 | loss: 0.012024137191474438 | dt: 320.08ms | tok/sec:  51187.96\n",
      "step1745 | loss: 0.011654859408736229 | dt: 320.05ms | tok/sec:  51192.38\n",
      "step1746 | loss: 0.011734682135283947 | dt: 320.37ms | tok/sec:  51141.37\n",
      "step1747 | loss: 0.0121846292167902 | dt: 321.07ms | tok/sec:  51028.62\n",
      "step1748 | loss: 0.011688925325870514 | dt: 319.65ms | tok/sec:  51255.84\n",
      "step1749 | loss: 0.011664621531963348 | dt: 320.88ms | tok/sec:  51059.07\n",
      "step1750 | loss: 0.011803580448031425 | dt: 319.82ms | tok/sec:  51229.06\n",
      "step1751 | loss: 0.011053455993533134 | dt: 320.90ms | tok/sec:  51056.98\n",
      "step1752 | loss: 0.011824322864413261 | dt: 319.55ms | tok/sec:  51272.59\n",
      "step1753 | loss: 0.011736351996660233 | dt: 319.97ms | tok/sec:  51205.24\n",
      "step1754 | loss: 0.011768448166549206 | dt: 320.10ms | tok/sec:  51183.54\n",
      "step1755 | loss: 0.01163100078701973 | dt: 320.98ms | tok/sec:  51043.78\n",
      "step1756 | loss: 0.011078808456659317 | dt: 319.88ms | tok/sec:  51219.40\n",
      "step1757 | loss: 0.010911120101809502 | dt: 319.79ms | tok/sec:  51233.83\n",
      "step1758 | loss: 0.012125085107982159 | dt: 320.08ms | tok/sec:  51187.23\n",
      "step1759 | loss: 0.010240135714411736 | dt: 321.20ms | tok/sec:  51008.96\n",
      "step1760 | loss: 0.011723080649971962 | dt: 319.92ms | tok/sec:  51212.22\n",
      "step1761 | loss: 0.010939214378595352 | dt: 320.97ms | tok/sec:  51045.87\n",
      "step1762 | loss: 0.012176241725683212 | dt: 320.18ms | tok/sec:  51171.23\n",
      "step1763 | loss: 0.010548251681029797 | dt: 320.41ms | tok/sec:  51134.44\n",
      "step1764 | loss: 0.0108574777841568 | dt: 319.86ms | tok/sec:  51222.41\n",
      "step1765 | loss: 0.010897877626121044 | dt: 319.92ms | tok/sec:  51212.11\n",
      "step1766 | loss: 0.01078339759260416 | dt: 320.02ms | tok/sec:  51197.00\n",
      "step1767 | loss: 0.011340786702930927 | dt: 320.86ms | tok/sec:  51062.25\n",
      "step1768 | loss: 0.010814289562404156 | dt: 320.27ms | tok/sec:  51157.25\n",
      "step1769 | loss: 0.010843435302376747 | dt: 320.84ms | tok/sec:  51066.43\n",
      "step1770 | loss: 0.010949572548270226 | dt: 319.96ms | tok/sec:  51205.62\n",
      "step1771 | loss: 0.010419094935059547 | dt: 321.06ms | tok/sec:  51030.32\n",
      "step1772 | loss: 0.011062338016927242 | dt: 320.76ms | tok/sec:  51078.27\n",
      "step1773 | loss: 0.01089086290448904 | dt: 319.80ms | tok/sec:  51232.30\n",
      "step1774 | loss: 0.010707873851060867 | dt: 319.80ms | tok/sec:  51231.50\n",
      "step1775 | loss: 0.01090979389846325 | dt: 320.08ms | tok/sec:  51186.59\n",
      "step1776 | loss: 0.01006688829511404 | dt: 319.88ms | tok/sec:  51218.67\n",
      "step1777 | loss: 0.010113203898072243 | dt: 319.76ms | tok/sec:  51238.26\n",
      "step1778 | loss: 0.011371733620762825 | dt: 320.59ms | tok/sec:  51105.81\n",
      "step1779 | loss: 0.009553909301757812 | dt: 320.71ms | tok/sec:  51087.31\n",
      "step1780 | loss: 0.010728524066507816 | dt: 319.74ms | tok/sec:  51241.93\n",
      "step1781 | loss: 0.010163617320358753 | dt: 321.07ms | tok/sec:  51028.66\n",
      "step1782 | loss: 0.011339125223457813 | dt: 321.30ms | tok/sec:  50993.44\n",
      "step1783 | loss: 0.009805627167224884 | dt: 319.91ms | tok/sec:  51214.89\n",
      "step1784 | loss: 0.010259883478283882 | dt: 319.70ms | tok/sec:  51247.55\n",
      "step1785 | loss: 0.010098719969391823 | dt: 321.23ms | tok/sec:  51003.36\n",
      "step1786 | loss: 0.010090315714478493 | dt: 319.52ms | tok/sec:  51276.34\n",
      "step1787 | loss: 0.010599471628665924 | dt: 321.25ms | tok/sec:  51000.37\n",
      "step1788 | loss: 0.010048914700746536 | dt: 320.32ms | tok/sec:  51149.25\n",
      "step1789 | loss: 0.010206225328147411 | dt: 320.74ms | tok/sec:  51081.50\n",
      "step1790 | loss: 0.01021839864552021 | dt: 319.80ms | tok/sec:  51232.57\n",
      "step1791 | loss: 0.009585030376911163 | dt: 320.68ms | tok/sec:  51091.94\n",
      "step1792 | loss: 0.010425865650177002 | dt: 319.90ms | tok/sec:  51215.35\n",
      "step1793 | loss: 0.01010237168520689 | dt: 320.83ms | tok/sec:  51067.34\n",
      "step1794 | loss: 0.010113506577908993 | dt: 320.34ms | tok/sec:  51145.75\n",
      "step1795 | loss: 0.010009145364165306 | dt: 320.97ms | tok/sec:  51045.41\n",
      "step1796 | loss: 0.009506462141871452 | dt: 320.18ms | tok/sec:  51171.80\n",
      "step1797 | loss: 0.00948600098490715 | dt: 321.07ms | tok/sec:  51029.91\n",
      "step1798 | loss: 0.010693060234189034 | dt: 320.06ms | tok/sec:  51189.71\n",
      "step1799 | loss: 0.008902018889784813 | dt: 320.56ms | tok/sec:  51110.86\n",
      "step1800 | loss: 0.010137926787137985 | dt: 320.13ms | tok/sec:  51179.42\n",
      "step1801 | loss: 0.009485799819231033 | dt: 321.01ms | tok/sec:  51038.36\n",
      "step1802 | loss: 0.010647280141711235 | dt: 319.39ms | tok/sec:  51298.20\n",
      "step1803 | loss: 0.009285436943173409 | dt: 320.71ms | tok/sec:  51086.74\n",
      "step1804 | loss: 0.009404506534337997 | dt: 320.78ms | tok/sec:  51076.03\n",
      "step1805 | loss: 0.009520106948912144 | dt: 319.76ms | tok/sec:  51238.30\n",
      "step1806 | loss: 0.009384648874402046 | dt: 320.90ms | tok/sec:  51056.52\n",
      "step1807 | loss: 0.010024260729551315 | dt: 320.32ms | tok/sec:  51148.07\n",
      "step1808 | loss: 0.009450873360037804 | dt: 320.86ms | tok/sec:  51062.78\n",
      "step1809 | loss: 0.009590229019522667 | dt: 320.44ms | tok/sec:  51129.42\n",
      "step1810 | loss: 0.009621767327189445 | dt: 320.79ms | tok/sec:  51074.66\n",
      "step1811 | loss: 0.009123625233769417 | dt: 320.12ms | tok/sec:  51181.40\n",
      "step1812 | loss: 0.009842980653047562 | dt: 320.74ms | tok/sec:  51081.42\n",
      "step1813 | loss: 0.009585639461874962 | dt: 320.55ms | tok/sec:  51112.80\n",
      "step1814 | loss: 0.009300870820879936 | dt: 321.22ms | tok/sec:  51006.31\n",
      "step1815 | loss: 0.009512962773442268 | dt: 321.13ms | tok/sec:  51019.41\n",
      "step1816 | loss: 0.008758380077779293 | dt: 320.02ms | tok/sec:  51196.43\n",
      "step1817 | loss: 0.008880741894245148 | dt: 319.95ms | tok/sec:  51207.49\n",
      "step1818 | loss: 0.010104570537805557 | dt: 320.16ms | tok/sec:  51174.77\n",
      "step1819 | loss: 0.008430240675807 | dt: 320.02ms | tok/sec:  51197.53\n",
      "step1820 | loss: 0.009363260120153427 | dt: 320.70ms | tok/sec:  51088.37\n",
      "step1821 | loss: 0.008912784978747368 | dt: 321.26ms | tok/sec:  50999.57\n",
      "step1822 | loss: 0.010021654888987541 | dt: 320.54ms | tok/sec:  51114.29\n",
      "step1823 | loss: 0.008671916089951992 | dt: 320.88ms | tok/sec:  51058.95\n",
      "step1824 | loss: 0.009053162299096584 | dt: 319.95ms | tok/sec:  51208.37\n",
      "step1825 | loss: 0.008930189535021782 | dt: 321.07ms | tok/sec:  51030.06\n",
      "step1826 | loss: 0.008870905265212059 | dt: 320.86ms | tok/sec:  51062.78\n",
      "step1827 | loss: 0.009479166939854622 | dt: 320.99ms | tok/sec:  51042.61\n",
      "step1828 | loss: 0.008849441073834896 | dt: 319.82ms | tok/sec:  51229.55\n",
      "step1829 | loss: 0.00910157710313797 | dt: 320.76ms | tok/sec:  51078.99\n",
      "step1830 | loss: 0.009089156985282898 | dt: 319.92ms | tok/sec:  51213.06\n",
      "step1831 | loss: 0.008458241820335388 | dt: 321.14ms | tok/sec:  51018.28\n",
      "step1832 | loss: 0.009351487271487713 | dt: 319.98ms | tok/sec:  51203.02\n",
      "step1833 | loss: 0.00890800915658474 | dt: 320.84ms | tok/sec:  51065.40\n",
      "step1834 | loss: 0.008888645097613335 | dt: 320.85ms | tok/sec:  51064.91\n",
      "step1835 | loss: 0.00881164614111185 | dt: 319.97ms | tok/sec:  51205.28\n",
      "step1836 | loss: 0.008357771672308445 | dt: 319.97ms | tok/sec:  51204.82\n",
      "step1837 | loss: 0.008416137658059597 | dt: 320.62ms | tok/sec:  51101.51\n",
      "step1838 | loss: 0.009581027552485466 | dt: 320.41ms | tok/sec:  51134.90\n",
      "step1839 | loss: 0.007916330359876156 | dt: 320.84ms | tok/sec:  51065.36\n",
      "step1840 | loss: 0.008924437686800957 | dt: 320.50ms | tok/sec:  51120.14\n",
      "step1841 | loss: 0.008398022502660751 | dt: 320.77ms | tok/sec:  51076.98\n",
      "step1842 | loss: 0.009485915303230286 | dt: 319.80ms | tok/sec:  51232.27\n",
      "step1843 | loss: 0.008282210677862167 | dt: 320.73ms | tok/sec:  51082.86\n",
      "step1844 | loss: 0.008381417021155357 | dt: 320.67ms | tok/sec:  51092.70\n",
      "step1845 | loss: 0.008519320748746395 | dt: 319.91ms | tok/sec:  51213.90\n",
      "step1846 | loss: 0.008321557193994522 | dt: 320.54ms | tok/sec:  51114.25\n",
      "step1847 | loss: 0.00900710467249155 | dt: 321.30ms | tok/sec:  50993.48\n",
      "step1848 | loss: 0.008394157513976097 | dt: 319.72ms | tok/sec:  51244.95\n",
      "step1849 | loss: 0.00863651279360056 | dt: 321.19ms | tok/sec:  51011.04\n",
      "step1850 | loss: 0.00860604178160429 | dt: 321.78ms | tok/sec:  50916.21\n",
      "step1851 | loss: 0.008130326867103577 | dt: 320.91ms | tok/sec:  51054.82\n",
      "step1852 | loss: 0.00886911153793335 | dt: 320.86ms | tok/sec:  51062.29\n",
      "step1853 | loss: 0.008619816973805428 | dt: 320.04ms | tok/sec:  51192.95\n",
      "step1854 | loss: 0.008210149593651295 | dt: 320.25ms | tok/sec:  51160.52\n",
      "step1855 | loss: 0.008427843451499939 | dt: 321.11ms | tok/sec:  51023.01\n",
      "step1856 | loss: 0.0077793896198272705 | dt: 319.96ms | tok/sec:  51205.96\n",
      "step1857 | loss: 0.00793304294347763 | dt: 320.70ms | tok/sec:  51088.56\n",
      "step1858 | loss: 0.009118104353547096 | dt: 320.85ms | tok/sec:  51063.73\n",
      "step1859 | loss: 0.0075355707667768 | dt: 321.01ms | tok/sec:  51039.27\n",
      "step1860 | loss: 0.008295704610645771 | dt: 320.34ms | tok/sec:  51146.28\n",
      "step1861 | loss: 0.007967907935380936 | dt: 320.99ms | tok/sec:  51041.89\n",
      "step1862 | loss: 0.009004993364214897 | dt: 319.67ms | tok/sec:  51252.67\n",
      "step1863 | loss: 0.007813751697540283 | dt: 320.98ms | tok/sec:  51043.52\n",
      "step1864 | loss: 0.008102544583380222 | dt: 320.74ms | tok/sec:  51082.64\n",
      "step1865 | loss: 0.008030210621654987 | dt: 320.79ms | tok/sec:  51073.22\n",
      "step1866 | loss: 0.007924340665340424 | dt: 319.82ms | tok/sec:  51228.79\n",
      "step1867 | loss: 0.008578860200941563 | dt: 319.74ms | tok/sec:  51242.43\n",
      "step1868 | loss: 0.007905525155365467 | dt: 319.88ms | tok/sec:  51219.05\n",
      "step1869 | loss: 0.008246051147580147 | dt: 321.39ms | tok/sec:  50978.95\n",
      "step1870 | loss: 0.008193130604922771 | dt: 319.95ms | tok/sec:  51207.30\n",
      "step1871 | loss: 0.007590918801724911 | dt: 320.73ms | tok/sec:  51083.24\n",
      "step1872 | loss: 0.008498869836330414 | dt: 321.16ms | tok/sec:  51014.83\n",
      "step1873 | loss: 0.007966614328324795 | dt: 320.07ms | tok/sec:  51189.56\n",
      "step1874 | loss: 0.00794677808880806 | dt: 319.64ms | tok/sec:  51257.98\n",
      "step1875 | loss: 0.007891956716775894 | dt: 320.79ms | tok/sec:  51074.66\n",
      "step1876 | loss: 0.007461091503500938 | dt: 320.72ms | tok/sec:  51085.48\n",
      "step1877 | loss: 0.0075774057768285275 | dt: 320.84ms | tok/sec:  51066.12\n",
      "step1878 | loss: 0.00870535895228386 | dt: 320.56ms | tok/sec:  51110.86\n",
      "step1879 | loss: 0.007132412865757942 | dt: 320.63ms | tok/sec:  51099.50\n",
      "step1880 | loss: 0.007982036098837852 | dt: 320.22ms | tok/sec:  51164.86\n",
      "step1881 | loss: 0.007538739126175642 | dt: 321.03ms | tok/sec:  51035.59\n",
      "step1882 | loss: 0.008563593029975891 | dt: 320.64ms | tok/sec:  51097.83\n",
      "step1883 | loss: 0.007489997427910566 | dt: 321.09ms | tok/sec:  51026.95\n",
      "step1884 | loss: 0.0075948541052639484 | dt: 321.08ms | tok/sec:  51027.37\n",
      "step1885 | loss: 0.007698101457208395 | dt: 320.67ms | tok/sec:  51092.55\n",
      "step1886 | loss: 0.007461557164788246 | dt: 319.96ms | tok/sec:  51206.31\n",
      "step1887 | loss: 0.008189544081687927 | dt: 320.02ms | tok/sec:  51196.73\n",
      "step1888 | loss: 0.0075551788322627544 | dt: 321.10ms | tok/sec:  51024.30\n",
      "step1889 | loss: 0.007872438989579678 | dt: 320.90ms | tok/sec:  51056.26\n",
      "step1890 | loss: 0.007811776362359524 | dt: 320.41ms | tok/sec:  51134.41\n",
      "step1891 | loss: 0.007334328722208738 | dt: 320.82ms | tok/sec:  51069.92\n",
      "step1892 | loss: 0.008109997026622295 | dt: 319.85ms | tok/sec:  51223.41\n",
      "step1893 | loss: 0.007832874543964863 | dt: 320.74ms | tok/sec:  51081.53\n",
      "step1894 | loss: 0.007354819681495428 | dt: 321.12ms | tok/sec:  51021.42\n",
      "step1895 | loss: 0.007562984246760607 | dt: 320.88ms | tok/sec:  51060.20\n",
      "step1896 | loss: 0.006991865579038858 | dt: 320.74ms | tok/sec:  51082.29\n",
      "step1897 | loss: 0.007170027121901512 | dt: 321.42ms | tok/sec:  50973.96\n",
      "step1898 | loss: 0.008340351283550262 | dt: 320.80ms | tok/sec:  51072.65\n",
      "step1899 | loss: 0.006825852207839489 | dt: 320.85ms | tok/sec:  51064.45\n",
      "step1900 | loss: 0.007455350365489721 | dt: 321.53ms | tok/sec:  50956.24\n",
      "step1901 | loss: 0.007218059152364731 | dt: 320.86ms | tok/sec:  51063.28\n",
      "step1902 | loss: 0.008187470957636833 | dt: 321.25ms | tok/sec:  51001.47\n",
      "step1903 | loss: 0.007117297500371933 | dt: 321.27ms | tok/sec:  50998.29\n",
      "step1904 | loss: 0.007339672185480595 | dt: 320.09ms | tok/sec:  51185.25\n",
      "step1905 | loss: 0.007299476768821478 | dt: 321.05ms | tok/sec:  51032.07\n",
      "step1906 | loss: 0.007151945494115353 | dt: 319.63ms | tok/sec:  51259.90\n",
      "step1907 | loss: 0.007859484292566776 | dt: 321.00ms | tok/sec:  51040.37\n",
      "step1908 | loss: 0.007161296904087067 | dt: 320.43ms | tok/sec:  51131.17\n",
      "step1909 | loss: 0.007545409724116325 | dt: 320.24ms | tok/sec:  51161.32\n",
      "step1910 | loss: 0.007466516923159361 | dt: 320.39ms | tok/sec:  51137.26\n",
      "step1911 | loss: 0.006873534061014652 | dt: 321.04ms | tok/sec:  51034.34\n",
      "step1912 | loss: 0.007791188545525074 | dt: 319.73ms | tok/sec:  51243.54\n",
      "step1913 | loss: 0.007234949618577957 | dt: 321.04ms | tok/sec:  51033.70\n",
      "step1914 | loss: 0.007154802791774273 | dt: 320.24ms | tok/sec:  51162.43\n",
      "step1915 | loss: 0.007146413438022137 | dt: 320.36ms | tok/sec:  51142.55\n",
      "step1916 | loss: 0.006728575564920902 | dt: 320.37ms | tok/sec:  51141.56\n",
      "step1917 | loss: 0.006900531239807606 | dt: 321.45ms | tok/sec:  50968.71\n",
      "step1918 | loss: 0.007983235642313957 | dt: 320.73ms | tok/sec:  51083.93\n",
      "step1919 | loss: 0.006498010829091072 | dt: 320.69ms | tok/sec:  51089.70\n",
      "step1920 | loss: 0.00721138808876276 | dt: 320.57ms | tok/sec:  51109.65\n",
      "step1921 | loss: 0.006835073232650757 | dt: 320.94ms | tok/sec:  51049.92\n",
      "step1922 | loss: 0.007826480083167553 | dt: 321.09ms | tok/sec:  51025.55\n",
      "step1923 | loss: 0.006844446994364262 | dt: 321.22ms | tok/sec:  51004.87\n",
      "step1924 | loss: 0.006927980575710535 | dt: 319.83ms | tok/sec:  51227.95\n",
      "step1925 | loss: 0.007026543840765953 | dt: 321.47ms | tok/sec:  50965.95\n",
      "step1926 | loss: 0.006777902599424124 | dt: 321.05ms | tok/sec:  51032.03\n",
      "step1927 | loss: 0.007527943700551987 | dt: 319.78ms | tok/sec:  51235.89\n",
      "step1928 | loss: 0.006862316280603409 | dt: 319.90ms | tok/sec:  51215.73\n",
      "step1929 | loss: 0.007251132279634476 | dt: 320.81ms | tok/sec:  51070.49\n",
      "step1930 | loss: 0.007147935684770346 | dt: 320.14ms | tok/sec:  51177.67\n",
      "step1931 | loss: 0.006669584661722183 | dt: 320.95ms | tok/sec:  51047.88\n",
      "step1932 | loss: 0.0074882060289382935 | dt: 321.02ms | tok/sec:  51037.34\n",
      "step1933 | loss: 0.00712175527587533 | dt: 320.25ms | tok/sec:  51159.34\n",
      "step1934 | loss: 0.006644126959145069 | dt: 320.79ms | tok/sec:  51073.68\n",
      "step1935 | loss: 0.006859779357910156 | dt: 321.13ms | tok/sec:  51020.10\n",
      "step1936 | loss: 0.00634979410097003 | dt: 320.57ms | tok/sec:  51108.62\n",
      "step1937 | loss: 0.006561041809618473 | dt: 320.05ms | tok/sec:  51192.34\n",
      "step1938 | loss: 0.007689892780035734 | dt: 321.20ms | tok/sec:  51008.58\n",
      "step1939 | loss: 0.006230010651051998 | dt: 320.98ms | tok/sec:  51044.01\n",
      "step1940 | loss: 0.00675041601061821 | dt: 320.18ms | tok/sec:  51170.96\n",
      "step1941 | loss: 0.006586283445358276 | dt: 320.56ms | tok/sec:  51110.98\n",
      "step1942 | loss: 0.00752227520570159 | dt: 320.95ms | tok/sec:  51048.33\n",
      "step1943 | loss: 0.006518792826682329 | dt: 319.98ms | tok/sec:  51202.91\n",
      "step1944 | loss: 0.006698162294924259 | dt: 321.09ms | tok/sec:  51025.74\n",
      "step1945 | loss: 0.006696165539324284 | dt: 320.90ms | tok/sec:  51055.88\n",
      "step1946 | loss: 0.006498920731246471 | dt: 320.02ms | tok/sec:  51196.92\n",
      "step1947 | loss: 0.007243330590426922 | dt: 321.40ms | tok/sec:  50976.80\n",
      "step1948 | loss: 0.006543409079313278 | dt: 321.10ms | tok/sec:  51024.11\n",
      "step1949 | loss: 0.006979676894843578 | dt: 320.83ms | tok/sec:  51068.21\n",
      "step1950 | loss: 0.0068656280636787415 | dt: 320.16ms | tok/sec:  51174.62\n",
      "step1951 | loss: 0.0062916455790400505 | dt: 320.36ms | tok/sec:  51142.97\n",
      "step1952 | loss: 0.00722383800894022 | dt: 320.55ms | tok/sec:  51112.73\n",
      "step1953 | loss: 0.0066154426895082 | dt: 321.25ms | tok/sec:  51001.16\n",
      "step1954 | loss: 0.006491297855973244 | dt: 319.92ms | tok/sec:  51213.59\n",
      "step1955 | loss: 0.006541086360812187 | dt: 320.90ms | tok/sec:  51056.60\n",
      "step1956 | loss: 0.0061350190080702305 | dt: 320.43ms | tok/sec:  51131.40\n",
      "step1957 | loss: 0.00632654782384634 | dt: 321.05ms | tok/sec:  51032.94\n",
      "step1958 | loss: 0.007409293204545975 | dt: 319.69ms | tok/sec:  51248.89\n",
      "step1959 | loss: 0.005954748019576073 | dt: 320.68ms | tok/sec:  51091.10\n",
      "step1960 | loss: 0.006563158705830574 | dt: 321.04ms | tok/sec:  51034.91\n",
      "step1961 | loss: 0.006257133558392525 | dt: 321.31ms | tok/sec:  50991.74\n",
      "step1962 | loss: 0.007204425521194935 | dt: 320.10ms | tok/sec:  51184.15\n",
      "step1963 | loss: 0.006318552419543266 | dt: 320.97ms | tok/sec:  51045.64\n",
      "step1964 | loss: 0.006375757046043873 | dt: 320.40ms | tok/sec:  51135.55\n",
      "step1965 | loss: 0.006480255164206028 | dt: 320.98ms | tok/sec:  51043.29\n",
      "step1966 | loss: 0.006207644939422607 | dt: 320.56ms | tok/sec:  51110.22\n",
      "step1967 | loss: 0.006971930153667927 | dt: 321.19ms | tok/sec:  51010.21\n",
      "step1968 | loss: 0.006279068533331156 | dt: 320.76ms | tok/sec:  51078.27\n",
      "step1969 | loss: 0.006706555839627981 | dt: 319.70ms | tok/sec:  51247.93\n",
      "step1970 | loss: 0.006595703307539225 | dt: 320.92ms | tok/sec:  51053.79\n",
      "step1971 | loss: 0.00611477717757225 | dt: 320.74ms | tok/sec:  51081.19\n",
      "step1972 | loss: 0.006955379620194435 | dt: 320.18ms | tok/sec:  51171.68\n",
      "step1973 | loss: 0.0065345605835318565 | dt: 321.05ms | tok/sec:  51032.60\n",
      "step1974 | loss: 0.0060577900148928165 | dt: 320.40ms | tok/sec:  51135.51\n",
      "step1975 | loss: 0.006276053376495838 | dt: 320.24ms | tok/sec:  51161.32\n",
      "step1976 | loss: 0.0058100163005292416 | dt: 321.34ms | tok/sec:  50986.14\n",
      "step1977 | loss: 0.0060450732707977295 | dt: 321.09ms | tok/sec:  51026.35\n",
      "step1978 | loss: 0.007147135213017464 | dt: 320.31ms | tok/sec:  51150.39\n",
      "step1979 | loss: 0.005741636734455824 | dt: 320.67ms | tok/sec:  51093.73\n",
      "step1980 | loss: 0.006161959376186132 | dt: 320.07ms | tok/sec:  51188.57\n",
      "step1981 | loss: 0.006064428947865963 | dt: 320.84ms | tok/sec:  51065.48\n",
      "step1982 | loss: 0.006965480279177427 | dt: 320.38ms | tok/sec:  51139.54\n",
      "step1983 | loss: 0.006029101088643074 | dt: 321.43ms | tok/sec:  50972.00\n",
      "step1984 | loss: 0.006169409491121769 | dt: 320.32ms | tok/sec:  51149.36\n",
      "step1985 | loss: 0.006180821917951107 | dt: 321.13ms | tok/sec:  51020.63\n",
      "step1986 | loss: 0.005958981346338987 | dt: 319.61ms | tok/sec:  51262.72\n",
      "step1987 | loss: 0.006745945196598768 | dt: 321.17ms | tok/sec:  51013.88\n",
      "step1988 | loss: 0.006022654473781586 | dt: 320.94ms | tok/sec:  51049.66\n",
      "step1989 | loss: 0.006483051925897598 | dt: 320.57ms | tok/sec:  51109.53\n",
      "step1990 | loss: 0.006362383719533682 | dt: 320.01ms | tok/sec:  51198.29\n",
      "step1991 | loss: 0.005788047797977924 | dt: 320.81ms | tok/sec:  51070.07\n",
      "step1992 | loss: 0.006726640276610851 | dt: 320.06ms | tok/sec:  51189.67\n",
      "step1993 | loss: 0.006101332604885101 | dt: 321.39ms | tok/sec:  50978.84\n",
      "step1994 | loss: 0.005937736947089434 | dt: 320.21ms | tok/sec:  51165.66\n",
      "step1995 | loss: 0.0060244472697377205 | dt: 319.59ms | tok/sec:  51265.52\n",
      "step1996 | loss: 0.005646483041346073 | dt: 319.86ms | tok/sec:  51221.92\n",
      "step1997 | loss: 0.00585051067173481 | dt: 320.68ms | tok/sec:  51091.71\n",
      "step1998 | loss: 0.00689949793741107 | dt: 319.90ms | tok/sec:  51215.50\n",
      "step1999 | loss: 0.005506597459316254 | dt: 320.69ms | tok/sec:  51089.70\n",
      "Prediction at step 2000: \n",
      " : This is a fixed text used for prediction. to behold not mind arw victory:\n",
      "Are \n",
      "\n",
      "step2000 | loss: 0.006027103401720524 | dt: 319.35ms | tok/sec:  51304.63\n",
      "step2001 | loss: 0.005765407811850309 | dt: 319.73ms | tok/sec:  51243.38\n",
      "step2002 | loss: 0.006676678545773029 | dt: 321.50ms | tok/sec:  50960.81\n",
      "step2003 | loss: 0.005880656652152538 | dt: 320.95ms | tok/sec:  51048.71\n",
      "step2004 | loss: 0.005915012210607529 | dt: 319.16ms | tok/sec:  51334.33\n",
      "step2005 | loss: 0.005999801214784384 | dt: 320.40ms | tok/sec:  51136.84\n",
      "step2006 | loss: 0.005702490918338299 | dt: 320.82ms | tok/sec:  51069.16\n",
      "step2007 | loss: 0.006501801311969757 | dt: 319.56ms | tok/sec:  51270.79\n",
      "step2008 | loss: 0.005778745748102665 | dt: 320.64ms | tok/sec:  51098.17\n",
      "step2009 | loss: 0.006268354132771492 | dt: 321.63ms | tok/sec:  50941.09\n",
      "step2010 | loss: 0.0061408719047904015 | dt: 319.46ms | tok/sec:  51285.87\n",
      "step2011 | loss: 0.005655838642269373 | dt: 320.74ms | tok/sec:  51081.95\n",
      "step2012 | loss: 0.006504989229142666 | dt: 321.29ms | tok/sec:  50995.03\n",
      "step2013 | loss: 0.006030261050909758 | dt: 321.18ms | tok/sec:  51012.03\n",
      "step2014 | loss: 0.005553427152335644 | dt: 320.92ms | tok/sec:  51053.41\n",
      "step2015 | loss: 0.005775830242782831 | dt: 321.35ms | tok/sec:  50984.48\n",
      "step2016 | loss: 0.005349873565137386 | dt: 320.83ms | tok/sec:  51067.91\n",
      "step2017 | loss: 0.005612821318209171 | dt: 319.93ms | tok/sec:  51210.88\n",
      "step2018 | loss: 0.006691379938274622 | dt: 320.03ms | tok/sec:  51194.86\n",
      "step2019 | loss: 0.0053258128464221954 | dt: 321.34ms | tok/sec:  50986.14\n",
      "step2020 | loss: 0.005667258519679308 | dt: 320.30ms | tok/sec:  51151.27\n",
      "step2021 | loss: 0.005607846193015575 | dt: 321.06ms | tok/sec:  51031.46\n",
      "step2022 | loss: 0.006486109457910061 | dt: 321.12ms | tok/sec:  51021.00\n",
      "step2023 | loss: 0.005597598850727081 | dt: 320.85ms | tok/sec:  51063.58\n",
      "step2024 | loss: 0.00571223720908165 | dt: 320.34ms | tok/sec:  51145.59\n",
      "step2025 | loss: 0.005756984930485487 | dt: 320.85ms | tok/sec:  51064.64\n",
      "step2026 | loss: 0.00550677627325058 | dt: 319.72ms | tok/sec:  51245.52\n",
      "step2027 | loss: 0.006294967141002417 | dt: 321.11ms | tok/sec:  51023.13\n",
      "step2028 | loss: 0.005590309388935566 | dt: 319.96ms | tok/sec:  51206.46\n",
      "step2029 | loss: 0.006073541007936001 | dt: 320.77ms | tok/sec:  51077.05\n",
      "step2030 | loss: 0.005929150618612766 | dt: 320.79ms | tok/sec:  51073.98\n",
      "step2031 | loss: 0.005355987697839737 | dt: 320.86ms | tok/sec:  51062.59\n",
      "step2032 | loss: 0.006311208009719849 | dt: 320.68ms | tok/sec:  51091.03\n",
      "step2033 | loss: 0.005662897601723671 | dt: 320.95ms | tok/sec:  51048.29\n",
      "step2034 | loss: 0.005462056025862694 | dt: 319.68ms | tok/sec:  51250.80\n",
      "step2035 | loss: 0.005592102184891701 | dt: 320.92ms | tok/sec:  51052.62\n",
      "step2036 | loss: 0.005213929805904627 | dt: 320.38ms | tok/sec:  51139.16\n",
      "step2037 | loss: 0.00542985275387764 | dt: 320.14ms | tok/sec:  51177.48\n",
      "step2038 | loss: 0.006460976786911488 | dt: 320.85ms | tok/sec:  51065.10\n",
      "step2039 | loss: 0.005126085598021746 | dt: 321.25ms | tok/sec:  51000.18\n",
      "step2040 | loss: 0.00555593054741621 | dt: 320.46ms | tok/sec:  51126.91\n",
      "step2041 | loss: 0.005357333924621344 | dt: 319.78ms | tok/sec:  51235.78\n",
      "step2042 | loss: 0.006240949034690857 | dt: 321.23ms | tok/sec:  51004.49\n",
      "step2043 | loss: 0.005497387610375881 | dt: 321.38ms | tok/sec:  50980.13\n",
      "step2044 | loss: 0.005517478100955486 | dt: 319.76ms | tok/sec:  51238.57\n",
      "step2045 | loss: 0.005577695555984974 | dt: 321.29ms | tok/sec:  50994.27\n",
      "step2046 | loss: 0.005282998085021973 | dt: 320.66ms | tok/sec:  51094.64\n",
      "step2047 | loss: 0.006103680469095707 | dt: 320.08ms | tok/sec:  51187.27\n",
      "step2048 | loss: 0.0053434548899531364 | dt: 319.65ms | tok/sec:  51256.07\n",
      "step2049 | loss: 0.005880021024495363 | dt: 321.19ms | tok/sec:  51010.93\n",
      "step2050 | loss: 0.005742122884839773 | dt: 319.75ms | tok/sec:  51239.52\n",
      "step2051 | loss: 0.005252419970929623 | dt: 320.24ms | tok/sec:  51162.27\n",
      "step2052 | loss: 0.006106873042881489 | dt: 319.86ms | tok/sec:  51221.80\n",
      "step2053 | loss: 0.005615743808448315 | dt: 319.86ms | tok/sec:  51222.30\n",
      "step2054 | loss: 0.005117353983223438 | dt: 319.84ms | tok/sec:  51226.23\n",
      "step2055 | loss: 0.005352380685508251 | dt: 321.20ms | tok/sec:  51007.94\n",
      "step2056 | loss: 0.004956511780619621 | dt: 319.80ms | tok/sec:  51232.69\n",
      "step2057 | loss: 0.0052354359067976475 | dt: 320.66ms | tok/sec:  51094.64\n",
      "step2058 | loss: 0.006291729398071766 | dt: 320.43ms | tok/sec:  51130.56\n",
      "step2059 | loss: 0.0049600787460803986 | dt: 320.88ms | tok/sec:  51058.80\n",
      "step2060 | loss: 0.005241322331130505 | dt: 320.66ms | tok/sec:  51094.49\n",
      "step2061 | loss: 0.005216909572482109 | dt: 321.01ms | tok/sec:  51038.32\n",
      "step2062 | loss: 0.006070390809327364 | dt: 320.72ms | tok/sec:  51085.60\n",
      "step2063 | loss: 0.005237270146608353 | dt: 320.32ms | tok/sec:  51149.14\n",
      "step2064 | loss: 0.005325303412973881 | dt: 320.06ms | tok/sec:  51190.74\n",
      "step2065 | loss: 0.005386394448578358 | dt: 320.86ms | tok/sec:  51063.54\n",
      "step2066 | loss: 0.005094612017273903 | dt: 320.35ms | tok/sec:  51143.39\n",
      "step2067 | loss: 0.00591310765594244 | dt: 320.61ms | tok/sec:  51102.65\n",
      "step2068 | loss: 0.00520748645067215 | dt: 320.85ms | tok/sec:  51063.69\n",
      "step2069 | loss: 0.005720588378608227 | dt: 321.50ms | tok/sec:  50961.34\n",
      "step2070 | loss: 0.0055566346272826195 | dt: 320.92ms | tok/sec:  51052.81\n",
      "step2071 | loss: 0.00498955650255084 | dt: 320.85ms | tok/sec:  51064.19\n",
      "step2072 | loss: 0.0059436592273414135 | dt: 321.39ms | tok/sec:  50979.11\n",
      "step2073 | loss: 0.005277092102915049 | dt: 320.91ms | tok/sec:  51055.27\n",
      "step2074 | loss: 0.005046650767326355 | dt: 319.84ms | tok/sec:  51226.31\n",
      "step2075 | loss: 0.005198644008487463 | dt: 320.79ms | tok/sec:  51074.40\n",
      "step2076 | loss: 0.004849107936024666 | dt: 320.01ms | tok/sec:  51198.45\n",
      "step2077 | loss: 0.0050961896777153015 | dt: 320.87ms | tok/sec:  51061.95\n",
      "step2078 | loss: 0.006089333910495043 | dt: 320.33ms | tok/sec:  51147.54\n",
      "step2079 | loss: 0.004784524440765381 | dt: 320.55ms | tok/sec:  51111.47\n",
      "step2080 | loss: 0.005155298858880997 | dt: 320.60ms | tok/sec:  51103.64\n",
      "step2081 | loss: 0.005000439006835222 | dt: 320.03ms | tok/sec:  51194.79\n",
      "step2082 | loss: 0.005852920468896627 | dt: 319.92ms | tok/sec:  51213.37\n",
      "step2083 | loss: 0.005150726065039635 | dt: 321.00ms | tok/sec:  51040.98\n",
      "step2084 | loss: 0.005169376730918884 | dt: 320.24ms | tok/sec:  51162.35\n",
      "step2085 | loss: 0.005223975982517004 | dt: 321.08ms | tok/sec:  51028.13\n",
      "step2086 | loss: 0.0048990268260240555 | dt: 320.79ms | tok/sec:  51073.86\n",
      "step2087 | loss: 0.005756279453635216 | dt: 320.86ms | tok/sec:  51062.06\n",
      "step2088 | loss: 0.0049750711768865585 | dt: 320.71ms | tok/sec:  51085.94\n",
      "step2089 | loss: 0.0055413879454135895 | dt: 320.83ms | tok/sec:  51067.87\n",
      "step2090 | loss: 0.005384568590670824 | dt: 319.78ms | tok/sec:  51236.01\n",
      "step2091 | loss: 0.004897579550743103 | dt: 321.09ms | tok/sec:  51026.80\n",
      "step2092 | loss: 0.0057738227769732475 | dt: 319.89ms | tok/sec:  51218.25\n",
      "step2093 | loss: 0.005241383332759142 | dt: 320.89ms | tok/sec:  51058.38\n",
      "step2094 | loss: 0.004738918039947748 | dt: 321.05ms | tok/sec:  51033.05\n",
      "step2095 | loss: 0.004986431449651718 | dt: 319.97ms | tok/sec:  51205.31\n",
      "step2096 | loss: 0.004609130322933197 | dt: 320.86ms | tok/sec:  51063.24\n",
      "step2097 | loss: 0.0049018822610378265 | dt: 321.51ms | tok/sec:  50958.96\n",
      "step2098 | loss: 0.005960560403764248 | dt: 319.61ms | tok/sec:  51262.88\n",
      "step2099 | loss: 0.004646604880690575 | dt: 320.95ms | tok/sec:  51048.14\n",
      "step2100 | loss: 0.004869159776717424 | dt: 320.29ms | tok/sec:  51153.59\n",
      "step2101 | loss: 0.004877072758972645 | dt: 320.18ms | tok/sec:  51170.77\n",
      "step2102 | loss: 0.005715693347156048 | dt: 321.16ms | tok/sec:  51015.78\n",
      "step2103 | loss: 0.004917849786579609 | dt: 320.07ms | tok/sec:  51188.07\n",
      "step2104 | loss: 0.004982293583452702 | dt: 320.40ms | tok/sec:  51135.70\n",
      "step2105 | loss: 0.005066167563199997 | dt: 321.21ms | tok/sec:  51006.42\n",
      "step2106 | loss: 0.004750574938952923 | dt: 320.61ms | tok/sec:  51103.22\n",
      "step2107 | loss: 0.005579871125519276 | dt: 320.68ms | tok/sec:  51091.26\n",
      "step2108 | loss: 0.004868087824434042 | dt: 320.55ms | tok/sec:  51112.69\n",
      "step2109 | loss: 0.005409846547991037 | dt: 321.04ms | tok/sec:  51033.81\n",
      "step2110 | loss: 0.005238540004938841 | dt: 319.95ms | tok/sec:  51207.98\n",
      "step2111 | loss: 0.004662965424358845 | dt: 320.02ms | tok/sec:  51197.23\n",
      "step2112 | loss: 0.005615019705146551 | dt: 320.70ms | tok/sec:  51087.50\n",
      "step2113 | loss: 0.004956438206136227 | dt: 320.94ms | tok/sec:  51049.81\n",
      "step2114 | loss: 0.004688784945756197 | dt: 320.04ms | tok/sec:  51192.99\n",
      "step2115 | loss: 0.004870560951530933 | dt: 320.69ms | tok/sec:  51089.62\n",
      "step2116 | loss: 0.004538840614259243 | dt: 320.60ms | tok/sec:  51103.83\n",
      "step2117 | loss: 0.0047811903059482574 | dt: 321.19ms | tok/sec:  51009.98\n",
      "step2118 | loss: 0.005756717175245285 | dt: 320.95ms | tok/sec:  51048.82\n",
      "step2119 | loss: 0.004491234198212624 | dt: 320.73ms | tok/sec:  51083.36\n",
      "step2120 | loss: 0.004799369722604752 | dt: 320.52ms | tok/sec:  51116.60\n",
      "step2121 | loss: 0.00468753557652235 | dt: 321.07ms | tok/sec:  51029.34\n",
      "step2122 | loss: 0.005522589199244976 | dt: 319.40ms | tok/sec:  51296.28\n",
      "step2123 | loss: 0.0048531233333051205 | dt: 321.35ms | tok/sec:  50985.61\n",
      "step2124 | loss: 0.004895303398370743 | dt: 320.91ms | tok/sec:  51054.82\n",
      "step2125 | loss: 0.004911238327622414 | dt: 320.98ms | tok/sec:  51043.44\n",
      "step2126 | loss: 0.004582015797495842 | dt: 320.94ms | tok/sec:  51049.85\n",
      "step2127 | loss: 0.0054462142288684845 | dt: 321.36ms | tok/sec:  50983.49\n",
      "step2128 | loss: 0.00464912224560976 | dt: 320.97ms | tok/sec:  51045.18\n",
      "step2129 | loss: 0.005250285845249891 | dt: 320.37ms | tok/sec:  51140.42\n",
      "step2130 | loss: 0.0050780149176716805 | dt: 320.29ms | tok/sec:  51154.05\n",
      "step2131 | loss: 0.0045907385647296906 | dt: 320.96ms | tok/sec:  51046.09\n",
      "step2132 | loss: 0.005470496602356434 | dt: 320.83ms | tok/sec:  51066.92\n",
      "step2133 | loss: 0.004914811812341213 | dt: 320.84ms | tok/sec:  51066.46\n",
      "step2134 | loss: 0.004411831498146057 | dt: 319.89ms | tok/sec:  51217.26\n",
      "step2135 | loss: 0.004671788774430752 | dt: 320.76ms | tok/sec:  51078.69\n",
      "step2136 | loss: 0.004301279783248901 | dt: 321.07ms | tok/sec:  51029.98\n",
      "step2137 | loss: 0.004615680314600468 | dt: 320.87ms | tok/sec:  51061.15\n",
      "step2138 | loss: 0.005675203166902065 | dt: 320.99ms | tok/sec:  51042.26\n",
      "step2139 | loss: 0.004379583057016134 | dt: 321.30ms | tok/sec:  50992.84\n",
      "step2140 | loss: 0.00455300509929657 | dt: 320.72ms | tok/sec:  51084.42\n",
      "step2141 | loss: 0.004590017721056938 | dt: 320.66ms | tok/sec:  51094.07\n",
      "step2142 | loss: 0.005399593152105808 | dt: 320.64ms | tok/sec:  51097.49\n",
      "step2143 | loss: 0.00464229891076684 | dt: 320.71ms | tok/sec:  51086.09\n",
      "step2144 | loss: 0.004674709402024746 | dt: 319.55ms | tok/sec:  51271.71\n",
      "step2145 | loss: 0.004773521795868874 | dt: 321.21ms | tok/sec:  51006.39\n",
      "step2146 | loss: 0.0044366177171468735 | dt: 320.68ms | tok/sec:  51090.84\n",
      "step2147 | loss: 0.005296035204082727 | dt: 320.87ms | tok/sec:  51061.68\n",
      "step2148 | loss: 0.0045698173344135284 | dt: 321.37ms | tok/sec:  50981.79\n",
      "step2149 | loss: 0.005133136175572872 | dt: 321.16ms | tok/sec:  51015.66\n",
      "step2150 | loss: 0.004947291221469641 | dt: 320.28ms | tok/sec:  51155.49\n",
      "step2151 | loss: 0.004380311816930771 | dt: 321.10ms | tok/sec:  51024.60\n",
      "step2152 | loss: 0.005347561556845903 | dt: 320.71ms | tok/sec:  51085.90\n",
      "step2153 | loss: 0.004663239233195782 | dt: 320.30ms | tok/sec:  51152.60\n",
      "step2154 | loss: 0.0043829865753650665 | dt: 320.80ms | tok/sec:  51072.92\n",
      "step2155 | loss: 0.004568962380290031 | dt: 320.45ms | tok/sec:  51128.36\n",
      "step2156 | loss: 0.004259807523339987 | dt: 319.47ms | tok/sec:  51285.30\n",
      "step2157 | loss: 0.004502119496464729 | dt: 321.02ms | tok/sec:  51037.68\n",
      "step2158 | loss: 0.005457735620439053 | dt: 320.90ms | tok/sec:  51057.13\n",
      "step2159 | loss: 0.004231380298733711 | dt: 320.86ms | tok/sec:  51063.43\n",
      "step2160 | loss: 0.0044797793962061405 | dt: 320.18ms | tok/sec:  51171.15\n",
      "step2161 | loss: 0.004417546093463898 | dt: 320.74ms | tok/sec:  51082.64\n",
      "step2162 | loss: 0.005231786519289017 | dt: 321.11ms | tok/sec:  51022.41\n",
      "step2163 | loss: 0.004582630004733801 | dt: 320.48ms | tok/sec:  51123.07\n",
      "step2164 | loss: 0.004630008712410927 | dt: 319.68ms | tok/sec:  51251.22\n",
      "step2165 | loss: 0.0046366616152226925 | dt: 320.80ms | tok/sec:  51071.93\n",
      "step2166 | loss: 0.004288946744054556 | dt: 320.20ms | tok/sec:  51167.26\n",
      "step2167 | loss: 0.005176487844437361 | dt: 320.08ms | tok/sec:  51187.39\n",
      "step2168 | loss: 0.004363446496427059 | dt: 320.79ms | tok/sec:  51073.86\n",
      "step2169 | loss: 0.004984915256500244 | dt: 321.02ms | tok/sec:  51036.84\n",
      "step2170 | loss: 0.004816386383026838 | dt: 319.74ms | tok/sec:  51240.94\n",
      "step2171 | loss: 0.00432702898979187 | dt: 321.04ms | tok/sec:  51033.66\n",
      "step2172 | loss: 0.005220471415668726 | dt: 320.31ms | tok/sec:  51150.35\n",
      "step2173 | loss: 0.004631549119949341 | dt: 320.91ms | tok/sec:  51054.32\n",
      "step2174 | loss: 0.004119683988392353 | dt: 320.76ms | tok/sec:  51078.46\n",
      "step2175 | loss: 0.004399425350129604 | dt: 321.19ms | tok/sec:  51010.25\n",
      "step2176 | loss: 0.004026264883577824 | dt: 321.06ms | tok/sec:  51030.55\n",
      "step2177 | loss: 0.004349717870354652 | dt: 320.90ms | tok/sec:  51056.52\n",
      "step2178 | loss: 0.005411219783127308 | dt: 320.72ms | tok/sec:  51085.37\n",
      "step2179 | loss: 0.0041322261095047 | dt: 320.80ms | tok/sec:  51072.80\n",
      "step2180 | loss: 0.0042657144367694855 | dt: 319.79ms | tok/sec:  51233.64\n",
      "step2181 | loss: 0.004335464909672737 | dt: 321.03ms | tok/sec:  51035.29\n",
      "step2182 | loss: 0.005113570019602776 | dt: 320.13ms | tok/sec:  51179.72\n",
      "step2183 | loss: 0.00439818250015378 | dt: 320.90ms | tok/sec:  51056.14\n",
      "step2184 | loss: 0.00441668089479208 | dt: 320.54ms | tok/sec:  51113.75\n",
      "step2185 | loss: 0.004524967633187771 | dt: 320.14ms | tok/sec:  51177.44\n",
      "step2186 | loss: 0.004166841506958008 | dt: 320.78ms | tok/sec:  51075.19\n",
      "step2187 | loss: 0.005033155903220177 | dt: 320.71ms | tok/sec:  51087.04\n",
      "step2188 | loss: 0.004296509549021721 | dt: 319.95ms | tok/sec:  51207.45\n",
      "step2189 | loss: 0.004888225346803665 | dt: 320.53ms | tok/sec:  51115.62\n",
      "step2190 | loss: 0.0046942951157689095 | dt: 320.54ms | tok/sec:  51112.99\n",
      "step2191 | loss: 0.004131636582314968 | dt: 320.98ms | tok/sec:  51044.05\n",
      "step2192 | loss: 0.0050851888954639435 | dt: 319.79ms | tok/sec:  51234.40\n",
      "step2193 | loss: 0.004408522974699736 | dt: 321.05ms | tok/sec:  51033.28\n",
      "step2194 | loss: 0.004105616360902786 | dt: 320.43ms | tok/sec:  51131.48\n",
      "step2195 | loss: 0.0042884210124611855 | dt: 320.86ms | tok/sec:  51063.05\n",
      "step2196 | loss: 0.004018029198050499 | dt: 321.13ms | tok/sec:  51019.83\n",
      "step2197 | loss: 0.004261750727891922 | dt: 321.17ms | tok/sec:  51012.86\n",
      "step2198 | loss: 0.005221487954258919 | dt: 320.49ms | tok/sec:  51121.02\n",
      "step2199 | loss: 0.004009692929685116 | dt: 321.32ms | tok/sec:  50989.05\n",
      "step2200 | loss: 0.004213863983750343 | dt: 319.82ms | tok/sec:  51228.90\n",
      "step2201 | loss: 0.004166814032942057 | dt: 321.35ms | tok/sec:  50984.89\n",
      "step2202 | loss: 0.004977565724402666 | dt: 320.45ms | tok/sec:  51128.74\n",
      "step2203 | loss: 0.004351526498794556 | dt: 321.07ms | tok/sec:  51029.49\n",
      "step2204 | loss: 0.004398250952363014 | dt: 319.86ms | tok/sec:  51222.99\n",
      "step2205 | loss: 0.004398714751005173 | dt: 321.08ms | tok/sec:  51026.99\n",
      "step2206 | loss: 0.004038869868963957 | dt: 320.39ms | tok/sec:  51137.83\n",
      "step2207 | loss: 0.004933590069413185 | dt: 319.97ms | tok/sec:  51204.82\n",
      "step2208 | loss: 0.00411627721041441 | dt: 320.44ms | tok/sec:  51130.41\n",
      "step2209 | loss: 0.0047632381319999695 | dt: 320.44ms | tok/sec:  51129.23\n",
      "step2210 | loss: 0.00457663182169199 | dt: 320.30ms | tok/sec:  51152.14\n",
      "step2211 | loss: 0.004082904197275639 | dt: 321.07ms | tok/sec:  51029.07\n",
      "step2212 | loss: 0.00498039647936821 | dt: 320.56ms | tok/sec:  51110.56\n",
      "step2213 | loss: 0.004383020102977753 | dt: 321.17ms | tok/sec:  51013.39\n",
      "step2214 | loss: 0.00386469392105937 | dt: 319.98ms | tok/sec:  51203.25\n",
      "step2215 | loss: 0.004159057512879372 | dt: 320.76ms | tok/sec:  51078.61\n",
      "step2216 | loss: 0.003786578308790922 | dt: 320.64ms | tok/sec:  51097.11\n",
      "step2217 | loss: 0.004150640219449997 | dt: 319.93ms | tok/sec:  51210.85\n",
      "step2218 | loss: 0.005155803170055151 | dt: 320.53ms | tok/sec:  51115.58\n",
      "step2219 | loss: 0.0039140088483691216 | dt: 321.15ms | tok/sec:  51016.46\n",
      "step2220 | loss: 0.004005096387118101 | dt: 320.78ms | tok/sec:  51075.38\n",
      "step2221 | loss: 0.00409514456987381 | dt: 321.12ms | tok/sec:  51021.80\n",
      "step2222 | loss: 0.004869363270699978 | dt: 319.89ms | tok/sec:  51217.37\n",
      "step2223 | loss: 0.0041771139949560165 | dt: 319.83ms | tok/sec:  51227.38\n",
      "step2224 | loss: 0.004187345504760742 | dt: 320.40ms | tok/sec:  51136.08\n",
      "step2225 | loss: 0.004297290928661823 | dt: 320.55ms | tok/sec:  51112.00\n",
      "step2226 | loss: 0.0039321668446063995 | dt: 319.75ms | tok/sec:  51240.17\n",
      "step2227 | loss: 0.004812234081327915 | dt: 321.01ms | tok/sec:  51038.78\n",
      "step2228 | loss: 0.00406187679618597 | dt: 321.17ms | tok/sec:  51013.96\n",
      "step2229 | loss: 0.0046693915501236916 | dt: 320.65ms | tok/sec:  51095.62\n",
      "step2230 | loss: 0.0044596088118851185 | dt: 320.13ms | tok/sec:  51178.62\n",
      "step2231 | loss: 0.003901808988302946 | dt: 321.45ms | tok/sec:  50969.09\n",
      "step2232 | loss: 0.004869893193244934 | dt: 320.82ms | tok/sec:  51068.74\n",
      "step2233 | loss: 0.004172263666987419 | dt: 321.12ms | tok/sec:  51021.23\n",
      "step2234 | loss: 0.0038592482451349497 | dt: 320.59ms | tok/sec:  51105.47\n",
      "step2235 | loss: 0.004049070179462433 | dt: 321.14ms | tok/sec:  51017.63\n",
      "step2236 | loss: 0.0037955427542328835 | dt: 320.10ms | tok/sec:  51183.42\n",
      "step2237 | loss: 0.004056498408317566 | dt: 321.07ms | tok/sec:  51029.45\n",
      "step2238 | loss: 0.004991825670003891 | dt: 319.82ms | tok/sec:  51228.71\n",
      "step2239 | loss: 0.0038010254502296448 | dt: 321.04ms | tok/sec:  51034.83\n",
      "step2240 | loss: 0.003977412357926369 | dt: 320.36ms | tok/sec:  51142.13\n",
      "step2241 | loss: 0.003947549499571323 | dt: 320.77ms | tok/sec:  51077.28\n",
      "step2242 | loss: 0.004750538617372513 | dt: 320.90ms | tok/sec:  51056.60\n",
      "step2243 | loss: 0.004140879958868027 | dt: 320.04ms | tok/sec:  51193.15\n",
      "step2244 | loss: 0.00416689645498991 | dt: 320.04ms | tok/sec:  51192.88\n",
      "step2245 | loss: 0.00418024230748415 | dt: 320.69ms | tok/sec:  51089.05\n",
      "step2246 | loss: 0.003799562342464924 | dt: 320.69ms | tok/sec:  51089.77\n",
      "step2247 | loss: 0.004728134721517563 | dt: 321.29ms | tok/sec:  50994.73\n",
      "step2248 | loss: 0.003891542786732316 | dt: 320.27ms | tok/sec:  51156.37\n",
      "step2249 | loss: 0.0045632654801011086 | dt: 319.93ms | tok/sec:  51211.15\n",
      "step2250 | loss: 0.004353522323071957 | dt: 321.17ms | tok/sec:  51012.90\n",
      "step2251 | loss: 0.003863615682348609 | dt: 320.45ms | tok/sec:  51128.36\n",
      "step2252 | loss: 0.004770858213305473 | dt: 320.45ms | tok/sec:  51127.86\n",
      "step2253 | loss: 0.004163543693721294 | dt: 321.24ms | tok/sec:  51002.11\n",
      "step2254 | loss: 0.003634388092905283 | dt: 320.73ms | tok/sec:  51083.17\n",
      "step2255 | loss: 0.003965472802519798 | dt: 320.83ms | tok/sec:  51067.00\n",
      "step2256 | loss: 0.0035712828394025564 | dt: 321.07ms | tok/sec:  51029.30\n",
      "step2257 | loss: 0.00392252067103982 | dt: 320.01ms | tok/sec:  51198.22\n",
      "step2258 | loss: 0.0049454933032393456 | dt: 320.54ms | tok/sec:  51114.29\n",
      "step2259 | loss: 0.003720466513186693 | dt: 320.95ms | tok/sec:  51047.80\n",
      "step2260 | loss: 0.0037706943694502115 | dt: 319.88ms | tok/sec:  51218.90\n",
      "step2261 | loss: 0.003896718379110098 | dt: 321.04ms | tok/sec:  51034.61\n",
      "step2262 | loss: 0.004643962252885103 | dt: 320.06ms | tok/sec:  51190.78\n",
      "step2263 | loss: 0.003998754546046257 | dt: 320.85ms | tok/sec:  51064.19\n",
      "step2264 | loss: 0.0039881374686956406 | dt: 319.72ms | tok/sec:  51245.25\n",
      "step2265 | loss: 0.004091260489076376 | dt: 320.74ms | tok/sec:  51081.31\n",
      "step2266 | loss: 0.003716672072187066 | dt: 321.04ms | tok/sec:  51034.34\n",
      "step2267 | loss: 0.004598949104547501 | dt: 320.48ms | tok/sec:  51123.68\n",
      "step2268 | loss: 0.0038507706485688686 | dt: 321.02ms | tok/sec:  51037.60\n",
      "step2269 | loss: 0.004465804435312748 | dt: 320.99ms | tok/sec:  51042.26\n",
      "step2270 | loss: 0.0042726569809019566 | dt: 320.64ms | tok/sec:  51098.06\n",
      "step2271 | loss: 0.0037087469827383757 | dt: 321.10ms | tok/sec:  51024.26\n",
      "step2272 | loss: 0.004661782644689083 | dt: 320.96ms | tok/sec:  51046.28\n",
      "step2273 | loss: 0.003962927497923374 | dt: 320.46ms | tok/sec:  51127.10\n",
      "step2274 | loss: 0.0036299186758697033 | dt: 319.73ms | tok/sec:  51243.00\n",
      "step2275 | loss: 0.003808648092672229 | dt: 320.03ms | tok/sec:  51195.09\n",
      "step2276 | loss: 0.0036161213647574186 | dt: 319.91ms | tok/sec:  51214.97\n",
      "step2277 | loss: 0.0038613060023635626 | dt: 320.89ms | tok/sec:  51058.69\n",
      "step2278 | loss: 0.004813919309526682 | dt: 320.35ms | tok/sec:  51144.53\n",
      "step2279 | loss: 0.0036104037426412106 | dt: 321.42ms | tok/sec:  50973.92\n",
      "step2280 | loss: 0.0037648337893188 | dt: 321.36ms | tok/sec:  50984.06\n",
      "step2281 | loss: 0.0037467717193067074 | dt: 320.90ms | tok/sec:  51057.05\n",
      "step2282 | loss: 0.004542551469057798 | dt: 319.91ms | tok/sec:  51214.97\n",
      "step2283 | loss: 0.003945451229810715 | dt: 321.34ms | tok/sec:  50985.80\n",
      "step2284 | loss: 0.003967496566474438 | dt: 320.53ms | tok/sec:  51115.81\n",
      "step2285 | loss: 0.003995385952293873 | dt: 320.03ms | tok/sec:  51195.17\n",
      "step2286 | loss: 0.00359862158074975 | dt: 321.26ms | tok/sec:  50999.65\n",
      "step2287 | loss: 0.004525044932961464 | dt: 320.19ms | tok/sec:  51169.40\n",
      "step2288 | loss: 0.0036998046562075615 | dt: 320.82ms | tok/sec:  51068.78\n",
      "step2289 | loss: 0.0043782638385891914 | dt: 321.00ms | tok/sec:  51040.94\n",
      "step2290 | loss: 0.004164503421634436 | dt: 320.25ms | tok/sec:  51160.33\n",
      "step2291 | loss: 0.0036696246825158596 | dt: 320.99ms | tok/sec:  51042.19\n",
      "step2292 | loss: 0.004572960548102856 | dt: 320.44ms | tok/sec:  51129.50\n",
      "step2293 | loss: 0.003957309760153294 | dt: 320.87ms | tok/sec:  51060.73\n",
      "step2294 | loss: 0.0034284659195691347 | dt: 320.91ms | tok/sec:  51054.55\n",
      "step2295 | loss: 0.0038096143398433924 | dt: 321.35ms | tok/sec:  50985.04\n",
      "step2296 | loss: 0.0033785041887313128 | dt: 320.06ms | tok/sec:  51189.79\n",
      "step2297 | loss: 0.003753762925043702 | dt: 320.88ms | tok/sec:  51060.09\n",
      "step2298 | loss: 0.004745853133499622 | dt: 320.84ms | tok/sec:  51066.65\n",
      "step2299 | loss: 0.0035430663265287876 | dt: 320.76ms | tok/sec:  51078.38\n",
      "step2300 | loss: 0.0035644369199872017 | dt: 321.13ms | tok/sec:  51020.51\n",
      "step2301 | loss: 0.0037184960674494505 | dt: 320.96ms | tok/sec:  51047.16\n",
      "step2302 | loss: 0.004448287654668093 | dt: 320.90ms | tok/sec:  51056.41\n",
      "step2303 | loss: 0.003816718002781272 | dt: 321.11ms | tok/sec:  51022.79\n",
      "step2304 | loss: 0.0038045526016503572 | dt: 320.34ms | tok/sec:  51146.13\n",
      "step2305 | loss: 0.0039003954734653234 | dt: 320.13ms | tok/sec:  51178.43\n",
      "step2306 | loss: 0.0035282359458506107 | dt: 321.49ms | tok/sec:  50962.62\n",
      "step2307 | loss: 0.004413235932588577 | dt: 319.70ms | tok/sec:  51248.04\n",
      "step2308 | loss: 0.003651008475571871 | dt: 320.41ms | tok/sec:  51134.10\n",
      "step2309 | loss: 0.004295366816222668 | dt: 321.12ms | tok/sec:  51021.99\n",
      "step2310 | loss: 0.004080899991095066 | dt: 320.32ms | tok/sec:  51148.56\n",
      "step2311 | loss: 0.003538621123880148 | dt: 321.03ms | tok/sec:  51036.20\n",
      "step2312 | loss: 0.00449712947010994 | dt: 320.92ms | tok/sec:  51052.77\n",
      "step2313 | loss: 0.0037804325111210346 | dt: 321.02ms | tok/sec:  51037.03\n",
      "step2314 | loss: 0.003440104192122817 | dt: 320.04ms | tok/sec:  51193.22\n",
      "step2315 | loss: 0.0036076828837394714 | dt: 320.60ms | tok/sec:  51104.17\n",
      "step2316 | loss: 0.003438750747591257 | dt: 320.24ms | tok/sec:  51161.82\n",
      "step2317 | loss: 0.003688597120344639 | dt: 320.12ms | tok/sec:  51180.26\n",
      "step2318 | loss: 0.004631642252206802 | dt: 320.71ms | tok/sec:  51085.98\n",
      "step2319 | loss: 0.003452047472819686 | dt: 320.96ms | tok/sec:  51047.00\n",
      "step2320 | loss: 0.0035670893266797066 | dt: 320.20ms | tok/sec:  51167.72\n",
      "step2321 | loss: 0.0035769634414464235 | dt: 320.66ms | tok/sec:  51093.84\n",
      "step2322 | loss: 0.004356216173619032 | dt: 320.72ms | tok/sec:  51084.88\n",
      "step2323 | loss: 0.0037910824175924063 | dt: 321.00ms | tok/sec:  51039.88\n",
      "step2324 | loss: 0.0037878428120166063 | dt: 320.65ms | tok/sec:  51095.93\n",
      "step2325 | loss: 0.0038095780182629824 | dt: 321.00ms | tok/sec:  51039.72\n",
      "step2326 | loss: 0.0034103163052350283 | dt: 321.15ms | tok/sec:  51017.10\n",
      "step2327 | loss: 0.004351026378571987 | dt: 320.08ms | tok/sec:  51186.70\n",
      "step2328 | loss: 0.003523169783875346 | dt: 320.10ms | tok/sec:  51183.92\n",
      "step2329 | loss: 0.004218535963445902 | dt: 321.39ms | tok/sec:  50979.29\n",
      "step2330 | loss: 0.004002861678600311 | dt: 319.74ms | tok/sec:  51240.90\n",
      "step2331 | loss: 0.0034896384458988905 | dt: 320.79ms | tok/sec:  51074.02\n",
      "step2332 | loss: 0.004410960245877504 | dt: 320.61ms | tok/sec:  51101.89\n",
      "step2333 | loss: 0.003785098437219858 | dt: 321.00ms | tok/sec:  51040.29\n",
      "step2334 | loss: 0.003245387692004442 | dt: 320.73ms | tok/sec:  51082.86\n",
      "step2335 | loss: 0.0036559980362653732 | dt: 320.12ms | tok/sec:  51180.49\n",
      "step2336 | loss: 0.003207233501598239 | dt: 320.51ms | tok/sec:  51117.82\n",
      "step2337 | loss: 0.003588490653783083 | dt: 319.99ms | tok/sec:  51201.12\n",
      "step2338 | loss: 0.004553024657070637 | dt: 320.63ms | tok/sec:  51098.78\n",
      "step2339 | loss: 0.003384408075362444 | dt: 321.13ms | tok/sec:  51019.83\n",
      "step2340 | loss: 0.0033822814002633095 | dt: 321.01ms | tok/sec:  51038.44\n",
      "step2341 | loss: 0.0035463301464915276 | dt: 320.63ms | tok/sec:  51099.73\n",
      "step2342 | loss: 0.004265859257429838 | dt: 320.07ms | tok/sec:  51188.11\n",
      "step2343 | loss: 0.0036474191583693027 | dt: 320.94ms | tok/sec:  51050.49\n",
      "step2344 | loss: 0.0036530233919620514 | dt: 320.09ms | tok/sec:  51185.71\n",
      "step2345 | loss: 0.0037507161032408476 | dt: 320.98ms | tok/sec:  51043.36\n",
      "step2346 | loss: 0.0033528096973896027 | dt: 319.95ms | tok/sec:  51208.10\n",
      "step2347 | loss: 0.004239736124873161 | dt: 321.20ms | tok/sec:  51008.58\n",
      "step2348 | loss: 0.0034687265288084745 | dt: 319.83ms | tok/sec:  51227.26\n",
      "step2349 | loss: 0.004137562587857246 | dt: 319.67ms | tok/sec:  51253.09\n",
      "step2350 | loss: 0.00391394505277276 | dt: 320.41ms | tok/sec:  51134.86\n",
      "step2351 | loss: 0.0033759393263608217 | dt: 321.16ms | tok/sec:  51014.30\n",
      "step2352 | loss: 0.004339829087257385 | dt: 320.24ms | tok/sec:  51161.02\n",
      "step2353 | loss: 0.0036071669310331345 | dt: 320.84ms | tok/sec:  51065.33\n",
      "step2354 | loss: 0.003268239554017782 | dt: 320.25ms | tok/sec:  51159.72\n",
      "step2355 | loss: 0.0034456741996109486 | dt: 320.04ms | tok/sec:  51194.14\n",
      "step2356 | loss: 0.003282469231635332 | dt: 320.27ms | tok/sec:  51156.33\n",
      "step2357 | loss: 0.003528397995978594 | dt: 320.82ms | tok/sec:  51069.16\n",
      "step2358 | loss: 0.004466724582016468 | dt: 321.22ms | tok/sec:  51005.25\n",
      "step2359 | loss: 0.003304668003693223 | dt: 321.37ms | tok/sec:  50981.30\n",
      "step2360 | loss: 0.0033824671991169453 | dt: 320.17ms | tok/sec:  51172.25\n",
      "step2361 | loss: 0.0034143170341849327 | dt: 320.71ms | tok/sec:  51086.17\n",
      "step2362 | loss: 0.004196007736027241 | dt: 320.27ms | tok/sec:  51157.40\n",
      "step2363 | loss: 0.0036441884003579617 | dt: 321.15ms | tok/sec:  51017.22\n",
      "step2364 | loss: 0.003612429602071643 | dt: 319.64ms | tok/sec:  51256.95\n",
      "step2365 | loss: 0.003644014010205865 | dt: 320.80ms | tok/sec:  51072.92\n",
      "step2366 | loss: 0.0032377338502556086 | dt: 320.96ms | tok/sec:  51047.35\n",
      "step2367 | loss: 0.004190066363662481 | dt: 319.88ms | tok/sec:  51219.05\n",
      "step2368 | loss: 0.003382591065019369 | dt: 319.87ms | tok/sec:  51220.54\n",
      "step2369 | loss: 0.004057938698679209 | dt: 321.10ms | tok/sec:  51025.02\n",
      "step2370 | loss: 0.003838007804006338 | dt: 319.60ms | tok/sec:  51263.53\n",
      "step2371 | loss: 0.003323800629004836 | dt: 320.14ms | tok/sec:  51177.55\n",
      "step2372 | loss: 0.004241271875798702 | dt: 319.83ms | tok/sec:  51227.26\n",
      "step2373 | loss: 0.003628320060670376 | dt: 320.77ms | tok/sec:  51076.48\n",
      "step2374 | loss: 0.00307279615662992 | dt: 320.28ms | tok/sec:  51155.27\n",
      "step2375 | loss: 0.0034730194602161646 | dt: 321.23ms | tok/sec:  51004.53\n",
      "step2376 | loss: 0.00305023230612278 | dt: 320.47ms | tok/sec:  51124.36\n",
      "step2377 | loss: 0.003432611934840679 | dt: 320.86ms | tok/sec:  51062.71\n",
      "step2378 | loss: 0.004411124624311924 | dt: 320.16ms | tok/sec:  51174.85\n",
      "step2379 | loss: 0.0032419166527688503 | dt: 319.92ms | tok/sec:  51213.29\n",
      "step2380 | loss: 0.0032256185077130795 | dt: 319.81ms | tok/sec:  51230.58\n",
      "step2381 | loss: 0.003402894362807274 | dt: 320.95ms | tok/sec:  51049.13\n",
      "step2382 | loss: 0.0040993657894432545 | dt: 320.81ms | tok/sec:  51070.52\n",
      "step2383 | loss: 0.0035001160576939583 | dt: 320.83ms | tok/sec:  51067.07\n",
      "step2384 | loss: 0.0035118611995130777 | dt: 320.23ms | tok/sec:  51163.03\n",
      "step2385 | loss: 0.003601429285481572 | dt: 320.58ms | tok/sec:  51107.90\n",
      "step2386 | loss: 0.0031949286349117756 | dt: 319.82ms | tok/sec:  51228.48\n",
      "step2387 | loss: 0.0040951804257929325 | dt: 321.41ms | tok/sec:  50975.40\n",
      "step2388 | loss: 0.0033038691617548466 | dt: 319.67ms | tok/sec:  51252.75\n",
      "step2389 | loss: 0.003989546559751034 | dt: 320.25ms | tok/sec:  51159.34\n",
      "step2390 | loss: 0.003775621298700571 | dt: 320.59ms | tok/sec:  51105.62\n",
      "step2391 | loss: 0.0032274003606289625 | dt: 320.83ms | tok/sec:  51067.37\n",
      "step2392 | loss: 0.004195435903966427 | dt: 321.14ms | tok/sec:  51018.39\n",
      "step2393 | loss: 0.0034396015107631683 | dt: 321.11ms | tok/sec:  51022.56\n",
      "step2394 | loss: 0.003098970279097557 | dt: 320.37ms | tok/sec:  51140.72\n",
      "step2395 | loss: 0.003293027402833104 | dt: 320.88ms | tok/sec:  51059.52\n",
      "step2396 | loss: 0.0031299712136387825 | dt: 321.07ms | tok/sec:  51029.87\n",
      "step2397 | loss: 0.003385238815099001 | dt: 319.97ms | tok/sec:  51204.28\n",
      "step2398 | loss: 0.004320508800446987 | dt: 319.82ms | tok/sec:  51228.79\n",
      "step2399 | loss: 0.0031647118739783764 | dt: 320.69ms | tok/sec:  51089.40\n",
      "step2400 | loss: 0.003222420811653137 | dt: 320.60ms | tok/sec:  51104.71\n",
      "step2401 | loss: 0.0032691368833184242 | dt: 320.91ms | tok/sec:  51054.02\n",
      "step2402 | loss: 0.0040378570556640625 | dt: 320.77ms | tok/sec:  51076.64\n",
      "step2403 | loss: 0.0035111485049128532 | dt: 321.11ms | tok/sec:  51023.32\n",
      "step2404 | loss: 0.0034687970764935017 | dt: 319.61ms | tok/sec:  51262.65\n",
      "step2405 | loss: 0.0034955330193042755 | dt: 321.18ms | tok/sec:  51011.91\n",
      "step2406 | loss: 0.0030782464891672134 | dt: 320.20ms | tok/sec:  51167.30\n",
      "step2407 | loss: 0.004053165204823017 | dt: 320.85ms | tok/sec:  51064.26\n",
      "step2408 | loss: 0.003233695635572076 | dt: 320.33ms | tok/sec:  51146.58\n",
      "step2409 | loss: 0.003920102957636118 | dt: 320.51ms | tok/sec:  51118.32\n",
      "step2410 | loss: 0.0037078256718814373 | dt: 320.62ms | tok/sec:  51101.06\n",
      "step2411 | loss: 0.0031713489443063736 | dt: 321.24ms | tok/sec:  51002.49\n",
      "step2412 | loss: 0.00410865806043148 | dt: 320.61ms | tok/sec:  51102.01\n",
      "step2413 | loss: 0.0034915690775960684 | dt: 320.16ms | tok/sec:  51173.97\n",
      "step2414 | loss: 0.002923551481217146 | dt: 320.75ms | tok/sec:  51080.62\n",
      "step2415 | loss: 0.003315230133011937 | dt: 321.29ms | tok/sec:  50994.20\n",
      "step2416 | loss: 0.002907158574089408 | dt: 319.60ms | tok/sec:  51263.80\n",
      "step2417 | loss: 0.003300555981695652 | dt: 320.52ms | tok/sec:  51117.25\n",
      "step2418 | loss: 0.0042690616101026535 | dt: 320.56ms | tok/sec:  51110.18\n",
      "step2419 | loss: 0.0031102709472179413 | dt: 320.84ms | tok/sec:  51065.25\n",
      "step2420 | loss: 0.003084010910242796 | dt: 319.86ms | tok/sec:  51222.34\n",
      "step2421 | loss: 0.0032665047328919172 | dt: 321.49ms | tok/sec:  50961.98\n",
      "step2422 | loss: 0.003969849087297916 | dt: 320.01ms | tok/sec:  51198.71\n",
      "step2423 | loss: 0.003365891519933939 | dt: 320.88ms | tok/sec:  51060.05\n",
      "step2424 | loss: 0.003375311614945531 | dt: 319.79ms | tok/sec:  51233.64\n",
      "step2425 | loss: 0.0034662180114537477 | dt: 320.00ms | tok/sec:  51200.54\n",
      "step2426 | loss: 0.0030464809387922287 | dt: 319.80ms | tok/sec:  51232.72\n",
      "step2427 | loss: 0.003953222185373306 | dt: 319.99ms | tok/sec:  51200.96\n",
      "step2428 | loss: 0.0031583551317453384 | dt: 319.75ms | tok/sec:  51240.67\n",
      "step2429 | loss: 0.003856097813695669 | dt: 321.04ms | tok/sec:  51034.23\n",
      "step2430 | loss: 0.003628801554441452 | dt: 320.59ms | tok/sec:  51105.16\n",
      "step2431 | loss: 0.003098516259342432 | dt: 320.94ms | tok/sec:  51049.51\n",
      "step2432 | loss: 0.004051606636494398 | dt: 320.67ms | tok/sec:  51093.12\n",
      "step2433 | loss: 0.003304293379187584 | dt: 321.04ms | tok/sec:  51034.61\n",
      "step2434 | loss: 0.0029414668679237366 | dt: 320.81ms | tok/sec:  51071.21\n",
      "step2435 | loss: 0.003152240766212344 | dt: 320.87ms | tok/sec:  51060.77\n",
      "step2436 | loss: 0.002994027454406023 | dt: 320.93ms | tok/sec:  51051.82\n",
      "step2437 | loss: 0.0032619298435747623 | dt: 321.00ms | tok/sec:  51040.03\n",
      "step2438 | loss: 0.004175030626356602 | dt: 319.74ms | tok/sec:  51241.01\n",
      "step2439 | loss: 0.0030415034852921963 | dt: 320.58ms | tok/sec:  51107.82\n",
      "step2440 | loss: 0.0030682336073368788 | dt: 320.44ms | tok/sec:  51129.00\n",
      "step2441 | loss: 0.0031331765931099653 | dt: 320.39ms | tok/sec:  51137.07\n",
      "step2442 | loss: 0.003904554061591625 | dt: 320.54ms | tok/sec:  51114.10\n",
      "step2443 | loss: 0.0033863941207528114 | dt: 321.55ms | tok/sec:  50952.57\n",
      "step2444 | loss: 0.003330026287585497 | dt: 320.33ms | tok/sec:  51147.92\n",
      "step2445 | loss: 0.003365367418155074 | dt: 321.20ms | tok/sec:  51008.81\n",
      "step2446 | loss: 0.0029489099979400635 | dt: 321.31ms | tok/sec:  50992.00\n",
      "step2447 | loss: 0.0039231423288583755 | dt: 319.78ms | tok/sec:  51234.90\n",
      "step2448 | loss: 0.0030990501400083303 | dt: 321.34ms | tok/sec:  50985.88\n",
      "step2449 | loss: 0.0037909329403191805 | dt: 320.18ms | tok/sec:  51171.30\n",
      "step2450 | loss: 0.0035683384630829096 | dt: 319.77ms | tok/sec:  51237.35\n",
      "step2451 | loss: 0.0030407204758375883 | dt: 320.41ms | tok/sec:  51134.06\n",
      "step2452 | loss: 0.003964717499911785 | dt: 320.86ms | tok/sec:  51063.39\n",
      "step2453 | loss: 0.0033511980436742306 | dt: 320.62ms | tok/sec:  51101.48\n",
      "step2454 | loss: 0.0027950946241617203 | dt: 320.15ms | tok/sec:  51175.42\n",
      "step2455 | loss: 0.003169398522004485 | dt: 321.06ms | tok/sec:  51030.93\n",
      "step2456 | loss: 0.002783713862299919 | dt: 320.80ms | tok/sec:  51073.03\n",
      "step2457 | loss: 0.003183867083862424 | dt: 319.89ms | tok/sec:  51217.91\n",
      "step2458 | loss: 0.00414570327848196 | dt: 321.02ms | tok/sec:  51037.79\n",
      "step2459 | loss: 0.002991155721247196 | dt: 320.91ms | tok/sec:  51054.25\n",
      "step2460 | loss: 0.002957582473754883 | dt: 320.43ms | tok/sec:  51131.36\n",
      "step2461 | loss: 0.003142399713397026 | dt: 321.42ms | tok/sec:  50974.11\n",
      "step2462 | loss: 0.003820139914751053 | dt: 320.82ms | tok/sec:  51068.63\n",
      "step2463 | loss: 0.003237532451748848 | dt: 320.48ms | tok/sec:  51123.15\n",
      "step2464 | loss: 0.00323448795825243 | dt: 320.26ms | tok/sec:  51158.77\n",
      "step2465 | loss: 0.003338485024869442 | dt: 320.95ms | tok/sec:  51048.41\n",
      "step2466 | loss: 0.0029089872259646654 | dt: 320.99ms | tok/sec:  51041.81\n",
      "step2467 | loss: 0.0038311153184622526 | dt: 320.46ms | tok/sec:  51126.99\n",
      "step2468 | loss: 0.003021104959771037 | dt: 321.08ms | tok/sec:  51027.41\n",
      "step2469 | loss: 0.0037438878789544106 | dt: 320.84ms | tok/sec:  51066.54\n",
      "step2470 | loss: 0.0035102313850075006 | dt: 321.34ms | tok/sec:  50986.18\n",
      "step2471 | loss: 0.002977140713483095 | dt: 320.31ms | tok/sec:  51150.16\n",
      "step2472 | loss: 0.003936040215194225 | dt: 320.05ms | tok/sec:  51191.81\n",
      "step2473 | loss: 0.0031784046441316605 | dt: 321.32ms | tok/sec:  50989.66\n",
      "step2474 | loss: 0.0027986126951873302 | dt: 320.27ms | tok/sec:  51156.45\n",
      "step2475 | loss: 0.0030262223444879055 | dt: 321.45ms | tok/sec:  50969.58\n",
      "step2476 | loss: 0.0028619931545108557 | dt: 321.08ms | tok/sec:  51028.39\n",
      "step2477 | loss: 0.0031347202602773905 | dt: 320.77ms | tok/sec:  51077.17\n",
      "step2478 | loss: 0.00404458399862051 | dt: 320.33ms | tok/sec:  51146.81\n",
      "step2479 | loss: 0.002926294691860676 | dt: 321.02ms | tok/sec:  51036.92\n",
      "step2480 | loss: 0.002925490029156208 | dt: 320.99ms | tok/sec:  51041.70\n",
      "step2481 | loss: 0.0030096566770225763 | dt: 320.60ms | tok/sec:  51103.91\n",
      "step2482 | loss: 0.0037638330832123756 | dt: 320.29ms | tok/sec:  51153.44\n",
      "step2483 | loss: 0.0032517770305275917 | dt: 320.09ms | tok/sec:  51185.56\n",
      "step2484 | loss: 0.0032241549342870712 | dt: 320.51ms | tok/sec:  51118.32\n",
      "step2485 | loss: 0.0032506827265024185 | dt: 321.26ms | tok/sec:  50999.80\n",
      "step2486 | loss: 0.002816553460434079 | dt: 320.75ms | tok/sec:  51080.28\n",
      "step2487 | loss: 0.003788790898397565 | dt: 319.70ms | tok/sec:  51247.39\n",
      "step2488 | loss: 0.0029727162327617407 | dt: 320.72ms | tok/sec:  51084.34\n",
      "step2489 | loss: 0.0036782247480005026 | dt: 321.25ms | tok/sec:  51000.10\n",
      "step2490 | loss: 0.003454641904681921 | dt: 319.89ms | tok/sec:  51216.88\n",
      "step2491 | loss: 0.0029090670868754387 | dt: 319.80ms | tok/sec:  51231.54\n",
      "step2492 | loss: 0.0038621246349066496 | dt: 320.03ms | tok/sec:  51195.85\n",
      "step2493 | loss: 0.0032162393908947706 | dt: 320.83ms | tok/sec:  51066.84\n",
      "step2494 | loss: 0.002665626583620906 | dt: 319.91ms | tok/sec:  51214.82\n",
      "step2495 | loss: 0.003035556524991989 | dt: 321.23ms | tok/sec:  51003.77\n",
      "step2496 | loss: 0.0026728478260338306 | dt: 320.15ms | tok/sec:  51175.38\n",
      "step2497 | loss: 0.0030716094188392162 | dt: 321.13ms | tok/sec:  51019.30\n",
      "step2498 | loss: 0.0040339697152376175 | dt: 320.00ms | tok/sec:  51199.55\n",
      "step2499 | loss: 0.002882172353565693 | dt: 321.29ms | tok/sec:  50994.24\n",
      "Prediction at step 2500: \n",
      " : This is a fixed text used for prediction.LEONTES: first with all your hands of \n",
      "\n",
      "step2500 | loss: 0.002849507611244917 | dt: 318.57ms | tok/sec:  51429.80\n",
      "step2501 | loss: 0.0030410769395530224 | dt: 319.02ms | tok/sec:  51356.85\n",
      "step2502 | loss: 0.0036984423641115427 | dt: 320.54ms | tok/sec:  51113.18\n",
      "step2503 | loss: 0.003146955044940114 | dt: 321.73ms | tok/sec:  50924.03\n",
      "step2504 | loss: 0.0031192186288535595 | dt: 320.05ms | tok/sec:  51192.50\n",
      "step2505 | loss: 0.0032226897310465574 | dt: 320.38ms | tok/sec:  51140.00\n",
      "step2506 | loss: 0.002784352283924818 | dt: 321.73ms | tok/sec:  50924.10\n",
      "step2507 | loss: 0.0037058982998132706 | dt: 320.56ms | tok/sec:  51110.60\n",
      "step2508 | loss: 0.0029021548107266426 | dt: 319.65ms | tok/sec:  51256.72\n",
      "step2509 | loss: 0.0036265014205127954 | dt: 320.65ms | tok/sec:  51095.51\n",
      "step2510 | loss: 0.003390414174646139 | dt: 320.82ms | tok/sec:  51069.31\n",
      "step2511 | loss: 0.00286924303509295 | dt: 319.92ms | tok/sec:  51212.64\n",
      "step2512 | loss: 0.003826842177659273 | dt: 321.32ms | tok/sec:  50990.19\n",
      "step2513 | loss: 0.0030605460051447153 | dt: 321.41ms | tok/sec:  50976.16\n",
      "step2514 | loss: 0.002676373813301325 | dt: 319.60ms | tok/sec:  51264.29\n",
      "step2515 | loss: 0.002915964461863041 | dt: 320.65ms | tok/sec:  51095.66\n",
      "step2516 | loss: 0.0027560750022530556 | dt: 320.77ms | tok/sec:  51076.71\n",
      "step2517 | loss: 0.0030255967285484076 | dt: 320.68ms | tok/sec:  51091.83\n",
      "step2518 | loss: 0.003922013565897942 | dt: 320.05ms | tok/sec:  51192.46\n",
      "step2519 | loss: 0.0028290667105466127 | dt: 321.44ms | tok/sec:  50970.33\n",
      "step2520 | loss: 0.0028011882677674294 | dt: 319.78ms | tok/sec:  51234.71\n",
      "step2521 | loss: 0.0028959233313798904 | dt: 320.98ms | tok/sec:  51044.46\n",
      "step2522 | loss: 0.003657687921077013 | dt: 320.80ms | tok/sec:  51072.27\n",
      "step2523 | loss: 0.0031407889910042286 | dt: 321.02ms | tok/sec:  51038.02\n",
      "step2524 | loss: 0.003124877344816923 | dt: 320.03ms | tok/sec:  51194.56\n",
      "step2525 | loss: 0.0031283567659556866 | dt: 321.11ms | tok/sec:  51023.28\n",
      "step2526 | loss: 0.0027004217263311148 | dt: 320.28ms | tok/sec:  51156.03\n",
      "step2527 | loss: 0.0036806147545576096 | dt: 320.95ms | tok/sec:  51048.60\n",
      "step2528 | loss: 0.002861347049474716 | dt: 320.04ms | tok/sec:  51193.95\n",
      "step2529 | loss: 0.003570677014067769 | dt: 320.91ms | tok/sec:  51054.10\n",
      "step2530 | loss: 0.0033461772836744785 | dt: 319.59ms | tok/sec:  51266.32\n",
      "step2531 | loss: 0.002796970773488283 | dt: 320.23ms | tok/sec:  51162.77\n",
      "step2532 | loss: 0.003742730710655451 | dt: 321.03ms | tok/sec:  51035.33\n",
      "step2533 | loss: 0.0030995591077953577 | dt: 319.68ms | tok/sec:  51251.87\n",
      "step2534 | loss: 0.0025433162227272987 | dt: 320.93ms | tok/sec:  51051.86\n",
      "step2535 | loss: 0.0029029364231973886 | dt: 321.02ms | tok/sec:  51038.09\n",
      "step2536 | loss: 0.0025577410124242306 | dt: 320.74ms | tok/sec:  51081.88\n",
      "step2537 | loss: 0.002967660780996084 | dt: 320.97ms | tok/sec:  51046.02\n",
      "step2538 | loss: 0.003933657892048359 | dt: 319.95ms | tok/sec:  51207.64\n",
      "step2539 | loss: 0.002775496570393443 | dt: 320.30ms | tok/sec:  51152.71\n",
      "step2540 | loss: 0.0027558160945773125 | dt: 320.43ms | tok/sec:  51130.91\n",
      "step2541 | loss: 0.0029465612024068832 | dt: 320.83ms | tok/sec:  51066.77\n",
      "step2542 | loss: 0.003590561915189028 | dt: 320.46ms | tok/sec:  51126.61\n",
      "step2543 | loss: 0.0030419889371842146 | dt: 320.35ms | tok/sec:  51144.57\n",
      "step2544 | loss: 0.003015045076608658 | dt: 319.86ms | tok/sec:  51223.02\n",
      "step2545 | loss: 0.0031198831275105476 | dt: 321.17ms | tok/sec:  51013.85\n",
      "step2546 | loss: 0.0026723011396825314 | dt: 319.94ms | tok/sec:  51209.63\n",
      "step2547 | loss: 0.0036017680540680885 | dt: 320.95ms | tok/sec:  51048.29\n",
      "step2548 | loss: 0.002791046164929867 | dt: 319.94ms | tok/sec:  51209.17\n",
      "step2549 | loss: 0.0035282596945762634 | dt: 319.84ms | tok/sec:  51225.12\n",
      "step2550 | loss: 0.0032784738577902317 | dt: 320.12ms | tok/sec:  51180.72\n",
      "step2551 | loss: 0.002769517246633768 | dt: 320.04ms | tok/sec:  51193.26\n",
      "step2552 | loss: 0.0037121495697647333 | dt: 319.78ms | tok/sec:  51235.89\n",
      "step2553 | loss: 0.002951594302430749 | dt: 320.95ms | tok/sec:  51048.26\n",
      "step2554 | loss: 0.002559516578912735 | dt: 320.96ms | tok/sec:  51046.51\n",
      "step2555 | loss: 0.0028153799939900637 | dt: 320.97ms | tok/sec:  51045.03\n",
      "step2556 | loss: 0.0026580248959362507 | dt: 320.19ms | tok/sec:  51169.13\n",
      "step2557 | loss: 0.0029314677231013775 | dt: 321.10ms | tok/sec:  51025.21\n",
      "step2558 | loss: 0.003813045332208276 | dt: 320.88ms | tok/sec:  51060.28\n",
      "step2559 | loss: 0.0027389496099203825 | dt: 320.02ms | tok/sec:  51197.53\n",
      "step2560 | loss: 0.002669594017788768 | dt: 320.86ms | tok/sec:  51062.25\n",
      "step2561 | loss: 0.0027961861342191696 | dt: 320.99ms | tok/sec:  51041.77\n",
      "step2562 | loss: 0.0035471301525831223 | dt: 320.88ms | tok/sec:  51060.05\n",
      "step2563 | loss: 0.003046175930649042 | dt: 319.99ms | tok/sec:  51201.16\n",
      "step2564 | loss: 0.0030297422781586647 | dt: 320.92ms | tok/sec:  51053.03\n",
      "step2565 | loss: 0.00303514557890594 | dt: 320.27ms | tok/sec:  51157.21\n",
      "step2566 | loss: 0.0025921091437339783 | dt: 319.90ms | tok/sec:  51216.76\n",
      "step2567 | loss: 0.0035750337410718203 | dt: 320.75ms | tok/sec:  51080.13\n",
      "step2568 | loss: 0.0027535133995115757 | dt: 321.22ms | tok/sec:  51004.99\n",
      "step2569 | loss: 0.0034656827338039875 | dt: 321.13ms | tok/sec:  51020.36\n",
      "step2570 | loss: 0.0032540252432227135 | dt: 320.04ms | tok/sec:  51194.17\n",
      "step2571 | loss: 0.0026878761127591133 | dt: 321.33ms | tok/sec:  50987.54\n",
      "step2572 | loss: 0.003639307338744402 | dt: 321.21ms | tok/sec:  51007.30\n",
      "step2573 | loss: 0.0029929480515420437 | dt: 320.37ms | tok/sec:  51141.26\n",
      "step2574 | loss: 0.0024421364068984985 | dt: 321.19ms | tok/sec:  51010.89\n",
      "step2575 | loss: 0.0027971453964710236 | dt: 321.29ms | tok/sec:  50994.69\n",
      "step2576 | loss: 0.0024650786072015762 | dt: 319.53ms | tok/sec:  51275.31\n",
      "step2577 | loss: 0.0028672763146460056 | dt: 321.11ms | tok/sec:  51023.35\n",
      "step2578 | loss: 0.0038325046189129353 | dt: 320.21ms | tok/sec:  51166.31\n",
      "step2579 | loss: 0.002687632804736495 | dt: 320.80ms | tok/sec:  51072.54\n",
      "step2580 | loss: 0.0026383548974990845 | dt: 319.96ms | tok/sec:  51206.84\n",
      "step2581 | loss: 0.002839741762727499 | dt: 320.91ms | tok/sec:  51054.48\n",
      "step2582 | loss: 0.003478439524769783 | dt: 320.38ms | tok/sec:  51139.12\n",
      "step2583 | loss: 0.002945698332041502 | dt: 321.07ms | tok/sec:  51029.30\n",
      "step2584 | loss: 0.002911593997851014 | dt: 320.11ms | tok/sec:  51181.97\n",
      "step2585 | loss: 0.003014158923178911 | dt: 320.89ms | tok/sec:  51058.19\n",
      "step2586 | loss: 0.002557954518124461 | dt: 321.08ms | tok/sec:  51027.63\n",
      "step2587 | loss: 0.0035054783802479506 | dt: 320.79ms | tok/sec:  51073.18\n",
      "step2588 | loss: 0.0026902207173407078 | dt: 320.15ms | tok/sec:  51175.27\n",
      "step2589 | loss: 0.0034390592481940985 | dt: 320.70ms | tok/sec:  51088.45\n",
      "step2590 | loss: 0.0031933640129864216 | dt: 320.83ms | tok/sec:  51067.75\n",
      "step2591 | loss: 0.0026753200218081474 | dt: 321.32ms | tok/sec:  50989.24\n",
      "step2592 | loss: 0.003613499691709876 | dt: 319.49ms | tok/sec:  51281.55\n",
      "step2593 | loss: 0.0028544790111482143 | dt: 321.36ms | tok/sec:  50982.96\n",
      "step2594 | loss: 0.0024460554122924805 | dt: 320.18ms | tok/sec:  51170.65\n",
      "step2595 | loss: 0.0027173864655196667 | dt: 319.70ms | tok/sec:  51248.01\n",
      "step2596 | loss: 0.0025734491646289825 | dt: 321.09ms | tok/sec:  51025.55\n",
      "step2597 | loss: 0.0028211597818881273 | dt: 321.38ms | tok/sec:  50980.69\n",
      "step2598 | loss: 0.003706671530380845 | dt: 320.20ms | tok/sec:  51168.71\n",
      "step2599 | loss: 0.002636342542245984 | dt: 321.07ms | tok/sec:  51029.15\n",
      "step2600 | loss: 0.002562387380748987 | dt: 321.17ms | tok/sec:  51013.66\n",
      "step2601 | loss: 0.002711049746721983 | dt: 320.52ms | tok/sec:  51117.52\n",
      "step2602 | loss: 0.0034518251195549965 | dt: 319.70ms | tok/sec:  51247.93\n",
      "step2603 | loss: 0.002943118568509817 | dt: 321.06ms | tok/sec:  51030.40\n",
      "step2604 | loss: 0.0029425134416669607 | dt: 320.22ms | tok/sec:  51165.05\n",
      "step2605 | loss: 0.002948181005194783 | dt: 321.06ms | tok/sec:  51030.86\n",
      "step2606 | loss: 0.00250092800706625 | dt: 320.93ms | tok/sec:  51052.39\n",
      "step2607 | loss: 0.0034836996346712112 | dt: 320.08ms | tok/sec:  51187.01\n",
      "step2608 | loss: 0.002653509844094515 | dt: 320.19ms | tok/sec:  51169.36\n",
      "step2609 | loss: 0.0033747386187314987 | dt: 321.40ms | tok/sec:  50976.31\n",
      "step2610 | loss: 0.003156084567308426 | dt: 320.28ms | tok/sec:  51156.03\n",
      "step2611 | loss: 0.0025931282434612513 | dt: 320.12ms | tok/sec:  51181.29\n",
      "step2612 | loss: 0.003551856381818652 | dt: 320.25ms | tok/sec:  51159.42\n",
      "step2613 | loss: 0.0028858559671789408 | dt: 320.96ms | tok/sec:  51046.21\n",
      "step2614 | loss: 0.002346230437979102 | dt: 320.73ms | tok/sec:  51084.12\n",
      "step2615 | loss: 0.002692215843126178 | dt: 321.23ms | tok/sec:  51004.53\n",
      "step2616 | loss: 0.0023640254512429237 | dt: 320.77ms | tok/sec:  51076.67\n",
      "step2617 | loss: 0.0027851061895489693 | dt: 320.79ms | tok/sec:  51074.21\n",
      "step2618 | loss: 0.003758329665288329 | dt: 320.36ms | tok/sec:  51142.97\n",
      "step2619 | loss: 0.002593056298792362 | dt: 321.31ms | tok/sec:  50991.36\n",
      "step2620 | loss: 0.002542845904827118 | dt: 319.57ms | tok/sec:  51268.81\n",
      "step2621 | loss: 0.0027397004887461662 | dt: 321.45ms | tok/sec:  50969.54\n",
      "step2622 | loss: 0.003385811345651746 | dt: 320.52ms | tok/sec:  51117.56\n",
      "step2623 | loss: 0.002870064228773117 | dt: 320.91ms | tok/sec:  51055.20\n",
      "step2624 | loss: 0.002823737682774663 | dt: 320.04ms | tok/sec:  51193.26\n",
      "step2625 | loss: 0.002920526312664151 | dt: 321.22ms | tok/sec:  51005.82\n",
      "step2626 | loss: 0.0024669929407536983 | dt: 320.23ms | tok/sec:  51162.96\n",
      "step2627 | loss: 0.003418514272198081 | dt: 321.08ms | tok/sec:  51027.79\n",
      "step2628 | loss: 0.0026034293696284294 | dt: 319.97ms | tok/sec:  51204.70\n",
      "step2629 | loss: 0.0033417055383324623 | dt: 320.76ms | tok/sec:  51079.14\n",
      "step2630 | loss: 0.0030971337109804153 | dt: 321.22ms | tok/sec:  51004.99\n",
      "step2631 | loss: 0.002592729404568672 | dt: 321.19ms | tok/sec:  51010.67\n",
      "step2632 | loss: 0.003518146462738514 | dt: 321.09ms | tok/sec:  51025.93\n",
      "step2633 | loss: 0.0027595264837145805 | dt: 320.66ms | tok/sec:  51094.75\n",
      "step2634 | loss: 0.002343251369893551 | dt: 320.66ms | tok/sec:  51094.90\n",
      "step2635 | loss: 0.0026301743928343058 | dt: 320.48ms | tok/sec:  51123.30\n",
      "step2636 | loss: 0.0024931763764470816 | dt: 320.21ms | tok/sec:  51167.03\n",
      "step2637 | loss: 0.0027475091628730297 | dt: 320.90ms | tok/sec:  51056.30\n",
      "step2638 | loss: 0.0036109713837504387 | dt: 319.84ms | tok/sec:  51226.27\n",
      "step2639 | loss: 0.002561831846833229 | dt: 320.86ms | tok/sec:  51062.52\n",
      "step2640 | loss: 0.0024653729051351547 | dt: 321.06ms | tok/sec:  51031.12\n",
      "step2641 | loss: 0.002619873732328415 | dt: 320.92ms | tok/sec:  51052.81\n",
      "step2642 | loss: 0.0033669460099190474 | dt: 319.53ms | tok/sec:  51275.35\n",
      "step2643 | loss: 0.002866602037101984 | dt: 320.58ms | tok/sec:  51107.98\n",
      "step2644 | loss: 0.0028326641768217087 | dt: 321.02ms | tok/sec:  51036.96\n",
      "step2645 | loss: 0.0028512622229754925 | dt: 320.80ms | tok/sec:  51072.84\n",
      "step2646 | loss: 0.002395711373537779 | dt: 321.26ms | tok/sec:  50998.82\n",
      "step2647 | loss: 0.0033966980408877134 | dt: 321.42ms | tok/sec:  50973.66\n",
      "step2648 | loss: 0.002557378262281418 | dt: 320.68ms | tok/sec:  51091.90\n",
      "step2649 | loss: 0.0032906881533563137 | dt: 320.96ms | tok/sec:  51047.31\n",
      "step2650 | loss: 0.0030718727502971888 | dt: 320.80ms | tok/sec:  51071.55\n",
      "step2651 | loss: 0.0025000523310154676 | dt: 320.48ms | tok/sec:  51123.37\n",
      "step2652 | loss: 0.003464425913989544 | dt: 320.43ms | tok/sec:  51131.36\n",
      "step2653 | loss: 0.00280726607888937 | dt: 321.40ms | tok/sec:  50977.25\n",
      "step2654 | loss: 0.002254289807751775 | dt: 320.73ms | tok/sec:  51083.51\n",
      "step2655 | loss: 0.0026024747639894485 | dt: 321.03ms | tok/sec:  51035.78\n",
      "step2656 | loss: 0.0022760669235140085 | dt: 319.87ms | tok/sec:  51220.50\n",
      "step2657 | loss: 0.0026993786450475454 | dt: 320.99ms | tok/sec:  51041.70\n",
      "step2658 | loss: 0.003678972367197275 | dt: 319.94ms | tok/sec:  51210.35\n",
      "step2659 | loss: 0.002514554187655449 | dt: 320.95ms | tok/sec:  51048.33\n",
      "step2660 | loss: 0.0024303924292325974 | dt: 320.30ms | tok/sec:  51151.80\n",
      "step2661 | loss: 0.002647051587700844 | dt: 320.84ms | tok/sec:  51065.55\n",
      "step2662 | loss: 0.0032919012010097504 | dt: 319.72ms | tok/sec:  51245.52\n",
      "step2663 | loss: 0.002793037798255682 | dt: 320.62ms | tok/sec:  51101.25\n",
      "step2664 | loss: 0.002747554797679186 | dt: 320.67ms | tok/sec:  51092.28\n",
      "step2665 | loss: 0.002836915198713541 | dt: 320.78ms | tok/sec:  51075.91\n",
      "step2666 | loss: 0.002368287183344364 | dt: 321.14ms | tok/sec:  51018.09\n",
      "step2667 | loss: 0.003324199002236128 | dt: 321.42ms | tok/sec:  50973.89\n",
      "step2668 | loss: 0.0025092358700931072 | dt: 319.65ms | tok/sec:  51256.53\n",
      "step2669 | loss: 0.003263549879193306 | dt: 321.20ms | tok/sec:  51008.17\n",
      "step2670 | loss: 0.0030117183923721313 | dt: 319.97ms | tok/sec:  51204.86\n",
      "step2671 | loss: 0.0025096391327679157 | dt: 319.94ms | tok/sec:  51210.08\n",
      "step2672 | loss: 0.0034286384470760822 | dt: 320.10ms | tok/sec:  51184.79\n",
      "step2673 | loss: 0.0026731728576123714 | dt: 321.33ms | tok/sec:  50988.71\n",
      "step2674 | loss: 0.0022476078011095524 | dt: 320.01ms | tok/sec:  51198.68\n",
      "step2675 | loss: 0.00254081841558218 | dt: 320.12ms | tok/sec:  51180.49\n",
      "step2676 | loss: 0.002412580419331789 | dt: 320.58ms | tok/sec:  51108.13\n",
      "step2677 | loss: 0.0026752790436148643 | dt: 319.92ms | tok/sec:  51213.37\n",
      "step2678 | loss: 0.003517279401421547 | dt: 320.70ms | tok/sec:  51088.03\n",
      "step2679 | loss: 0.0024892317596822977 | dt: 320.97ms | tok/sec:  51045.07\n",
      "step2680 | loss: 0.002367196371778846 | dt: 319.70ms | tok/sec:  51248.73\n",
      "step2681 | loss: 0.002545238472521305 | dt: 321.12ms | tok/sec:  51021.61\n",
      "step2682 | loss: 0.0032745031639933586 | dt: 319.72ms | tok/sec:  51245.18\n",
      "step2683 | loss: 0.0027791839092969894 | dt: 320.88ms | tok/sec:  51059.94\n",
      "step2684 | loss: 0.002757347421720624 | dt: 320.16ms | tok/sec:  51174.81\n",
      "step2685 | loss: 0.0027795021887868643 | dt: 321.01ms | tok/sec:  51039.27\n",
      "step2686 | loss: 0.0023171091452240944 | dt: 320.29ms | tok/sec:  51153.02\n",
      "step2687 | loss: 0.003314817091450095 | dt: 320.98ms | tok/sec:  51042.91\n",
      "step2688 | loss: 0.002478478942066431 | dt: 320.12ms | tok/sec:  51181.06\n",
      "step2689 | loss: 0.0032122302800416946 | dt: 320.83ms | tok/sec:  51067.79\n",
      "step2690 | loss: 0.002985349390655756 | dt: 320.91ms | tok/sec:  51054.59\n",
      "step2691 | loss: 0.002426973544061184 | dt: 320.01ms | tok/sec:  51198.03\n",
      "step2692 | loss: 0.0033939285203814507 | dt: 320.41ms | tok/sec:  51134.41\n",
      "step2693 | loss: 0.002726932056248188 | dt: 320.69ms | tok/sec:  51090.27\n",
      "step2694 | loss: 0.0021651110146194696 | dt: 320.03ms | tok/sec:  51194.63\n",
      "step2695 | loss: 0.0025091497227549553 | dt: 320.95ms | tok/sec:  51047.91\n",
      "step2696 | loss: 0.0022090072743594646 | dt: 319.96ms | tok/sec:  51206.38\n",
      "step2697 | loss: 0.0026186108589172363 | dt: 320.60ms | tok/sec:  51103.83\n",
      "step2698 | loss: 0.0035998718813061714 | dt: 320.24ms | tok/sec:  51161.47\n",
      "step2699 | loss: 0.0024439916014671326 | dt: 321.20ms | tok/sec:  51008.28\n",
      "step2700 | loss: 0.0023387314286082983 | dt: 320.37ms | tok/sec:  51140.53\n",
      "step2701 | loss: 0.002565397648140788 | dt: 320.90ms | tok/sec:  51055.65\n",
      "step2702 | loss: 0.003204604145139456 | dt: 319.98ms | tok/sec:  51202.87\n",
      "step2703 | loss: 0.002715268637984991 | dt: 321.23ms | tok/sec:  51003.40\n",
      "step2704 | loss: 0.002669675275683403 | dt: 320.78ms | tok/sec:  51075.76\n",
      "step2705 | loss: 0.0027581783942878246 | dt: 320.89ms | tok/sec:  51058.08\n",
      "step2706 | loss: 0.0022876374423503876 | dt: 320.37ms | tok/sec:  51141.56\n",
      "step2707 | loss: 0.0032551484182476997 | dt: 320.97ms | tok/sec:  51045.64\n",
      "step2708 | loss: 0.0024372858460992575 | dt: 320.70ms | tok/sec:  51087.91\n",
      "step2709 | loss: 0.003197549609467387 | dt: 320.61ms | tok/sec:  51103.07\n",
      "step2710 | loss: 0.002948132809251547 | dt: 320.71ms | tok/sec:  51087.27\n",
      "step2711 | loss: 0.0024251684080809355 | dt: 320.12ms | tok/sec:  51180.83\n",
      "step2712 | loss: 0.003354671411216259 | dt: 320.55ms | tok/sec:  51112.35\n",
      "step2713 | loss: 0.002590652322396636 | dt: 321.12ms | tok/sec:  51020.66\n",
      "step2714 | loss: 0.002165744546800852 | dt: 319.87ms | tok/sec:  51221.04\n",
      "step2715 | loss: 0.0024765285197645426 | dt: 320.77ms | tok/sec:  51077.59\n",
      "step2716 | loss: 0.002330139046534896 | dt: 321.00ms | tok/sec:  51039.99\n",
      "step2717 | loss: 0.002595218364149332 | dt: 321.00ms | tok/sec:  51040.03\n",
      "step2718 | loss: 0.0034409724175930023 | dt: 319.74ms | tok/sec:  51241.51\n",
      "step2719 | loss: 0.0024084681645035744 | dt: 320.97ms | tok/sec:  51045.34\n",
      "step2720 | loss: 0.0022833035327494144 | dt: 321.09ms | tok/sec:  51026.69\n",
      "step2721 | loss: 0.00247186329215765 | dt: 320.73ms | tok/sec:  51083.39\n",
      "step2722 | loss: 0.0031962187495082617 | dt: 319.83ms | tok/sec:  51227.07\n",
      "step2723 | loss: 0.0027142087928950787 | dt: 320.53ms | tok/sec:  51116.00\n",
      "step2724 | loss: 0.002691333880648017 | dt: 320.21ms | tok/sec:  51166.69\n",
      "step2725 | loss: 0.002700548619031906 | dt: 319.82ms | tok/sec:  51229.59\n",
      "step2726 | loss: 0.0022370913065969944 | dt: 320.46ms | tok/sec:  51126.61\n",
      "step2727 | loss: 0.003233194351196289 | dt: 320.42ms | tok/sec:  51133.19\n",
      "step2728 | loss: 0.002386435866355896 | dt: 320.07ms | tok/sec:  51188.15\n",
      "step2729 | loss: 0.003144559683278203 | dt: 320.64ms | tok/sec:  51097.90\n",
      "step2730 | loss: 0.0029171304777264595 | dt: 321.14ms | tok/sec:  51017.71\n",
      "step2731 | loss: 0.002347649075090885 | dt: 321.09ms | tok/sec:  51026.65\n",
      "step2732 | loss: 0.0033217216841876507 | dt: 320.40ms | tok/sec:  51135.40\n",
      "step2733 | loss: 0.002631549956277013 | dt: 321.46ms | tok/sec:  50967.76\n",
      "step2734 | loss: 0.0020854766480624676 | dt: 320.28ms | tok/sec:  51155.61\n",
      "step2735 | loss: 0.0024359282106161118 | dt: 319.96ms | tok/sec:  51205.77\n",
      "step2736 | loss: 0.0021222818177193403 | dt: 319.94ms | tok/sec:  51209.24\n",
      "step2737 | loss: 0.002546076662838459 | dt: 320.75ms | tok/sec:  51080.70\n",
      "step2738 | loss: 0.003531349590048194 | dt: 319.62ms | tok/sec:  51261.20\n",
      "step2739 | loss: 0.0023708564694970846 | dt: 321.19ms | tok/sec:  51011.08\n",
      "step2740 | loss: 0.002265751361846924 | dt: 320.84ms | tok/sec:  51065.21\n",
      "step2741 | loss: 0.0024913966190069914 | dt: 320.81ms | tok/sec:  51070.07\n",
      "step2742 | loss: 0.003130693454295397 | dt: 321.16ms | tok/sec:  51015.82\n",
      "step2743 | loss: 0.0026395705062896013 | dt: 321.29ms | tok/sec:  50994.99\n",
      "step2744 | loss: 0.0025996097829192877 | dt: 320.00ms | tok/sec:  51200.09\n",
      "step2745 | loss: 0.0026831980794668198 | dt: 320.93ms | tok/sec:  51051.97\n",
      "step2746 | loss: 0.0022145092952996492 | dt: 321.09ms | tok/sec:  51026.80\n",
      "step2747 | loss: 0.0031727184541523457 | dt: 320.95ms | tok/sec:  51048.52\n",
      "step2748 | loss: 0.0023698294535279274 | dt: 319.97ms | tok/sec:  51204.28\n",
      "step2749 | loss: 0.0031273297499865294 | dt: 320.98ms | tok/sec:  51043.93\n",
      "step2750 | loss: 0.0028679100796580315 | dt: 320.27ms | tok/sec:  51156.22\n",
      "step2751 | loss: 0.002355096396058798 | dt: 320.77ms | tok/sec:  51077.02\n",
      "step2752 | loss: 0.0032871291041374207 | dt: 320.61ms | tok/sec:  51102.54\n",
      "step2753 | loss: 0.0025189549196511507 | dt: 321.04ms | tok/sec:  51034.11\n",
      "step2754 | loss: 0.0020815206225961447 | dt: 320.11ms | tok/sec:  51182.28\n",
      "step2755 | loss: 0.002395098330453038 | dt: 321.57ms | tok/sec:  50950.34\n",
      "step2756 | loss: 0.0022585715632885695 | dt: 321.22ms | tok/sec:  51005.33\n",
      "step2757 | loss: 0.002526652067899704 | dt: 319.65ms | tok/sec:  51255.96\n",
      "step2758 | loss: 0.0033665355294942856 | dt: 319.97ms | tok/sec:  51204.89\n",
      "step2759 | loss: 0.002346230670809746 | dt: 321.26ms | tok/sec:  50998.93\n",
      "step2760 | loss: 0.0022029727697372437 | dt: 319.86ms | tok/sec:  51222.72\n",
      "step2761 | loss: 0.002400644589215517 | dt: 320.81ms | tok/sec:  51070.68\n",
      "step2762 | loss: 0.003122256603091955 | dt: 320.49ms | tok/sec:  51121.43\n",
      "step2763 | loss: 0.0026419623754918575 | dt: 321.05ms | tok/sec:  51033.05\n",
      "step2764 | loss: 0.00262658903375268 | dt: 319.90ms | tok/sec:  51215.58\n",
      "step2765 | loss: 0.002632640767842531 | dt: 321.37ms | tok/sec:  50982.40\n",
      "step2766 | loss: 0.0021611289121210575 | dt: 319.78ms | tok/sec:  51235.13\n",
      "step2767 | loss: 0.003160434076562524 | dt: 320.46ms | tok/sec:  51125.85\n",
      "step2768 | loss: 0.0023126229643821716 | dt: 320.07ms | tok/sec:  51189.33\n",
      "step2769 | loss: 0.0030779638327658176 | dt: 320.98ms | tok/sec:  51043.36\n",
      "step2770 | loss: 0.0028468375094234943 | dt: 319.54ms | tok/sec:  51274.47\n",
      "step2771 | loss: 0.0022854057606309652 | dt: 320.99ms | tok/sec:  51042.57\n",
      "step2772 | loss: 0.003257562406361103 | dt: 320.22ms | tok/sec:  51165.36\n",
      "step2773 | loss: 0.0025634807534515858 | dt: 320.89ms | tok/sec:  51057.51\n",
      "step2774 | loss: 0.0020077181980013847 | dt: 320.86ms | tok/sec:  51063.01\n",
      "step2775 | loss: 0.0023541245609521866 | dt: 321.39ms | tok/sec:  50977.89\n",
      "step2776 | loss: 0.002063977997750044 | dt: 319.80ms | tok/sec:  51231.58\n",
      "step2777 | loss: 0.002476005582138896 | dt: 320.11ms | tok/sec:  51181.86\n",
      "step2778 | loss: 0.003446564543992281 | dt: 319.66ms | tok/sec:  51254.47\n",
      "step2779 | loss: 0.002304843859747052 | dt: 319.81ms | tok/sec:  51230.78\n",
      "step2780 | loss: 0.0021948451176285744 | dt: 319.93ms | tok/sec:  51211.88\n",
      "step2781 | loss: 0.002424973761662841 | dt: 320.12ms | tok/sec:  51181.17\n",
      "step2782 | loss: 0.003066344652324915 | dt: 320.99ms | tok/sec:  51042.19\n",
      "step2783 | loss: 0.0025873540434986353 | dt: 321.26ms | tok/sec:  50999.46\n",
      "step2784 | loss: 0.0025225987192243338 | dt: 319.39ms | tok/sec:  51298.16\n",
      "step2785 | loss: 0.002608564682304859 | dt: 321.11ms | tok/sec:  51022.67\n",
      "step2786 | loss: 0.0021287871059030294 | dt: 320.89ms | tok/sec:  51058.65\n",
      "step2787 | loss: 0.0031093184370547533 | dt: 320.21ms | tok/sec:  51166.69\n",
      "step2788 | loss: 0.0022986074909567833 | dt: 321.29ms | tok/sec:  50994.84\n",
      "step2789 | loss: 0.003050327766686678 | dt: 320.32ms | tok/sec:  51149.59\n",
      "step2790 | loss: 0.002791897626593709 | dt: 319.99ms | tok/sec:  51200.81\n",
      "step2791 | loss: 0.0022904896177351475 | dt: 321.58ms | tok/sec:  50948.15\n",
      "step2792 | loss: 0.0032145639415830374 | dt: 319.92ms | tok/sec:  51212.45\n",
      "step2793 | loss: 0.0024535134434700012 | dt: 320.41ms | tok/sec:  51134.75\n",
      "step2794 | loss: 0.0020140893757343292 | dt: 319.98ms | tok/sec:  51203.86\n",
      "step2795 | loss: 0.0023240461014211178 | dt: 320.10ms | tok/sec:  51183.61\n",
      "step2796 | loss: 0.002191685838624835 | dt: 319.61ms | tok/sec:  51261.69\n",
      "step2797 | loss: 0.002456075744703412 | dt: 320.23ms | tok/sec:  51162.69\n",
      "step2798 | loss: 0.003301264252513647 | dt: 319.69ms | tok/sec:  51248.96\n",
      "step2799 | loss: 0.0022848460357636213 | dt: 320.91ms | tok/sec:  51054.06\n",
      "step2800 | loss: 0.0021384083665907383 | dt: 321.24ms | tok/sec:  51002.87\n",
      "step2801 | loss: 0.002333344193175435 | dt: 321.00ms | tok/sec:  51040.26\n",
      "step2802 | loss: 0.0030531827360391617 | dt: 320.07ms | tok/sec:  51188.61\n",
      "step2803 | loss: 0.002568954136222601 | dt: 320.22ms | tok/sec:  51165.55\n",
      "step2804 | loss: 0.0025545565877109766 | dt: 320.08ms | tok/sec:  51187.27\n",
      "step2805 | loss: 0.002565931063145399 | dt: 320.89ms | tok/sec:  51058.65\n",
      "step2806 | loss: 0.002087128348648548 | dt: 320.26ms | tok/sec:  51158.88\n",
      "step2807 | loss: 0.003088560188189149 | dt: 321.24ms | tok/sec:  51002.60\n",
      "step2808 | loss: 0.0022408778313547373 | dt: 321.00ms | tok/sec:  51040.44\n",
      "step2809 | loss: 0.003007009159773588 | dt: 320.85ms | tok/sec:  51063.81\n",
      "step2810 | loss: 0.002776935463771224 | dt: 321.62ms | tok/sec:  50941.96\n",
      "step2811 | loss: 0.0022119851782917976 | dt: 320.83ms | tok/sec:  51067.41\n",
      "step2812 | loss: 0.003182934131473303 | dt: 319.88ms | tok/sec:  51218.75\n",
      "step2813 | loss: 0.0024911444634199142 | dt: 321.09ms | tok/sec:  51026.65\n",
      "step2814 | loss: 0.0019401282770559192 | dt: 321.27ms | tok/sec:  50997.15\n",
      "step2815 | loss: 0.0022904269862920046 | dt: 320.74ms | tok/sec:  51081.46\n",
      "step2816 | loss: 0.0019945662934333086 | dt: 321.39ms | tok/sec:  50978.01\n",
      "step2817 | loss: 0.0024153583217412233 | dt: 321.42ms | tok/sec:  50974.53\n",
      "step2818 | loss: 0.0033807260915637016 | dt: 319.70ms | tok/sec:  51248.66\n",
      "step2819 | loss: 0.0022452264092862606 | dt: 321.24ms | tok/sec:  51002.11\n",
      "step2820 | loss: 0.00210780743509531 | dt: 320.63ms | tok/sec:  51099.92\n",
      "step2821 | loss: 0.002358779776841402 | dt: 319.84ms | tok/sec:  51225.05\n",
      "step2822 | loss: 0.002991738962009549 | dt: 320.12ms | tok/sec:  51180.11\n",
      "step2823 | loss: 0.002536613494157791 | dt: 320.67ms | tok/sec:  51092.89\n",
      "step2824 | loss: 0.002465477678924799 | dt: 320.64ms | tok/sec:  51098.21\n",
      "step2825 | loss: 0.002543605398386717 | dt: 320.04ms | tok/sec:  51193.15\n",
      "step2826 | loss: 0.0020687906071543694 | dt: 321.01ms | tok/sec:  51039.38\n",
      "step2827 | loss: 0.0030512851662933826 | dt: 321.05ms | tok/sec:  51033.05\n",
      "step2828 | loss: 0.002228805096819997 | dt: 320.81ms | tok/sec:  51069.96\n",
      "step2829 | loss: 0.002996408846229315 | dt: 319.98ms | tok/sec:  51203.63\n",
      "step2830 | loss: 0.0027351672761142254 | dt: 320.06ms | tok/sec:  51190.82\n",
      "step2831 | loss: 0.002223221119493246 | dt: 320.96ms | tok/sec:  51047.53\n",
      "step2832 | loss: 0.003146500326693058 | dt: 320.33ms | tok/sec:  51147.65\n",
      "step2833 | loss: 0.0023925669956952333 | dt: 319.49ms | tok/sec:  51281.32\n",
      "step2834 | loss: 0.0019457186572253704 | dt: 319.80ms | tok/sec:  51232.23\n",
      "step2835 | loss: 0.002254734979942441 | dt: 320.28ms | tok/sec:  51154.54\n",
      "step2836 | loss: 0.002121445955708623 | dt: 320.45ms | tok/sec:  51127.33\n",
      "step2837 | loss: 0.0024013924412429333 | dt: 320.90ms | tok/sec:  51056.98\n",
      "step2838 | loss: 0.0032332981936633587 | dt: 320.90ms | tok/sec:  51056.71\n",
      "step2839 | loss: 0.0022263629361987114 | dt: 320.59ms | tok/sec:  51106.34\n",
      "step2840 | loss: 0.0020707861986011267 | dt: 320.94ms | tok/sec:  51049.54\n",
      "step2841 | loss: 0.0022801391314715147 | dt: 321.45ms | tok/sec:  50968.59\n",
      "step2842 | loss: 0.0029880842193961143 | dt: 321.11ms | tok/sec:  51023.66\n",
      "step2843 | loss: 0.0025079012848436832 | dt: 320.85ms | tok/sec:  51064.45\n",
      "step2844 | loss: 0.002500209491699934 | dt: 320.86ms | tok/sec:  51062.37\n",
      "step2845 | loss: 0.0025068754330277443 | dt: 320.79ms | tok/sec:  51073.60\n",
      "step2846 | loss: 0.0020314170978963375 | dt: 320.18ms | tok/sec:  51171.42\n",
      "step2847 | loss: 0.0030321748927235603 | dt: 321.28ms | tok/sec:  50995.60\n",
      "step2848 | loss: 0.002182526746764779 | dt: 320.39ms | tok/sec:  51137.79\n",
      "step2849 | loss: 0.0029555773362517357 | dt: 319.78ms | tok/sec:  51235.13\n",
      "step2850 | loss: 0.0027171573601663113 | dt: 320.93ms | tok/sec:  51051.78\n",
      "step2851 | loss: 0.0021504766773432493 | dt: 320.92ms | tok/sec:  51053.30\n",
      "step2852 | loss: 0.0031268117018043995 | dt: 319.83ms | tok/sec:  51226.99\n",
      "step2853 | loss: 0.002425333485007286 | dt: 320.98ms | tok/sec:  51043.36\n",
      "step2854 | loss: 0.0018706455593928695 | dt: 320.97ms | tok/sec:  51045.07\n",
      "step2855 | loss: 0.002227738266810775 | dt: 320.66ms | tok/sec:  51094.41\n",
      "step2856 | loss: 0.0019379040459170938 | dt: 320.68ms | tok/sec:  51091.14\n",
      "step2857 | loss: 0.002361036604270339 | dt: 321.26ms | tok/sec:  50999.88\n",
      "step2858 | loss: 0.0033261855132877827 | dt: 321.12ms | tok/sec:  51021.57\n",
      "step2859 | loss: 0.0021923743188381195 | dt: 319.99ms | tok/sec:  51201.80\n",
      "step2860 | loss: 0.0020483487751334906 | dt: 320.49ms | tok/sec:  51122.23\n",
      "step2861 | loss: 0.002300830092281103 | dt: 320.51ms | tok/sec:  51117.78\n",
      "step2862 | loss: 0.0029320032335817814 | dt: 319.75ms | tok/sec:  51240.67\n",
      "step2863 | loss: 0.0024761324748396873 | dt: 321.04ms | tok/sec:  51034.46\n",
      "step2864 | loss: 0.002397333737462759 | dt: 320.68ms | tok/sec:  51092.13\n",
      "step2865 | loss: 0.002478896640241146 | dt: 321.21ms | tok/sec:  51006.42\n",
      "step2866 | loss: 0.0020055538043379784 | dt: 321.17ms | tok/sec:  51014.19\n",
      "step2867 | loss: 0.0029857303015887737 | dt: 321.30ms | tok/sec:  50993.44\n",
      "step2868 | loss: 0.002163310069590807 | dt: 349.70ms | tok/sec:  46851.62\n",
      "step2869 | loss: 0.002930406481027603 | dt: 319.78ms | tok/sec:  51234.79\n",
      "step2870 | loss: 0.0026868265122175217 | dt: 319.15ms | tok/sec:  51336.21\n",
      "step2871 | loss: 0.002163045108318329 | dt: 322.08ms | tok/sec:  50869.25\n",
      "step2872 | loss: 0.003092581406235695 | dt: 319.64ms | tok/sec:  51258.14\n",
      "step2873 | loss: 0.0023278812877833843 | dt: 320.32ms | tok/sec:  51148.15\n",
      "step2874 | loss: 0.0018837894313037395 | dt: 321.50ms | tok/sec:  50961.07\n",
      "step2875 | loss: 0.0021921012084931135 | dt: 320.91ms | tok/sec:  51054.44\n",
      "step2876 | loss: 0.0020654317922890186 | dt: 319.88ms | tok/sec:  51219.78\n",
      "step2877 | loss: 0.002343791536986828 | dt: 321.05ms | tok/sec:  51032.37\n",
      "step2878 | loss: 0.0031788237392902374 | dt: 321.31ms | tok/sec:  50991.47\n",
      "step2879 | loss: 0.0021669231355190277 | dt: 321.03ms | tok/sec:  51035.40\n",
      "step2880 | loss: 0.0020056471694260836 | dt: 320.81ms | tok/sec:  51070.94\n",
      "step2881 | loss: 0.0022191519383341074 | dt: 321.32ms | tok/sec:  50990.07\n",
      "step2882 | loss: 0.002921986859291792 | dt: 319.93ms | tok/sec:  51210.66\n",
      "step2883 | loss: 0.002443875651806593 | dt: 320.92ms | tok/sec:  51053.30\n",
      "step2884 | loss: 0.002432438777759671 | dt: 320.55ms | tok/sec:  51111.85\n",
      "step2885 | loss: 0.0024473192170262337 | dt: 320.99ms | tok/sec:  51041.73\n",
      "step2886 | loss: 0.00196570111438632 | dt: 320.16ms | tok/sec:  51174.62\n",
      "step2887 | loss: 0.0029693010728806257 | dt: 321.15ms | tok/sec:  51016.84\n",
      "step2888 | loss: 0.0021204669028520584 | dt: 320.92ms | tok/sec:  51052.69\n",
      "step2889 | loss: 0.002895485609769821 | dt: 320.96ms | tok/sec:  51046.93\n",
      "step2890 | loss: 0.002669697627425194 | dt: 320.37ms | tok/sec:  51140.65\n",
      "step2891 | loss: 0.002106672152876854 | dt: 320.85ms | tok/sec:  51063.66\n",
      "step2892 | loss: 0.0030755186453461647 | dt: 321.13ms | tok/sec:  51019.30\n",
      "step2893 | loss: 0.0023675106931477785 | dt: 321.07ms | tok/sec:  51029.83\n",
      "step2894 | loss: 0.0018117229919880629 | dt: 320.12ms | tok/sec:  51180.75\n",
      "step2895 | loss: 0.0021708589047193527 | dt: 320.78ms | tok/sec:  51075.84\n",
      "step2896 | loss: 0.0018846591701731086 | dt: 320.16ms | tok/sec:  51174.66\n",
      "step2897 | loss: 0.0023064729757606983 | dt: 320.92ms | tok/sec:  51053.75\n",
      "step2898 | loss: 0.0032555004581809044 | dt: 320.05ms | tok/sec:  51191.66\n",
      "step2899 | loss: 0.002134984824806452 | dt: 320.33ms | tok/sec:  51147.80\n",
      "step2900 | loss: 0.001977105624973774 | dt: 320.98ms | tok/sec:  51043.89\n",
      "step2901 | loss: 0.0022332309745252132 | dt: 319.56ms | tok/sec:  51270.37\n",
      "step2902 | loss: 0.002884048968553543 | dt: 320.73ms | tok/sec:  51083.24\n",
      "step2903 | loss: 0.002421797951683402 | dt: 321.20ms | tok/sec:  51008.66\n",
      "step2904 | loss: 0.002339645754545927 | dt: 319.74ms | tok/sec:  51241.32\n",
      "step2905 | loss: 0.002424192149192095 | dt: 321.31ms | tok/sec:  50991.25\n",
      "step2906 | loss: 0.001933329738676548 | dt: 321.28ms | tok/sec:  50996.66\n",
      "step2907 | loss: 0.0029290576931089163 | dt: 320.99ms | tok/sec:  51042.34\n",
      "step2908 | loss: 0.002112728077918291 | dt: 320.12ms | tok/sec:  51180.94\n",
      "step2909 | loss: 0.0028775054961442947 | dt: 321.28ms | tok/sec:  50996.43\n",
      "step2910 | loss: 0.00261884112842381 | dt: 320.05ms | tok/sec:  51192.46\n",
      "step2911 | loss: 0.0020959540270268917 | dt: 319.96ms | tok/sec:  51205.92\n",
      "step2912 | loss: 0.003039509989321232 | dt: 320.25ms | tok/sec:  51160.10\n",
      "step2913 | loss: 0.002267447765916586 | dt: 321.01ms | tok/sec:  51039.53\n",
      "step2914 | loss: 0.0018123895861208439 | dt: 321.10ms | tok/sec:  51024.98\n",
      "step2915 | loss: 0.00213735643774271 | dt: 320.79ms | tok/sec:  51074.09\n",
      "step2916 | loss: 0.002007592935115099 | dt: 320.23ms | tok/sec:  51163.72\n",
      "step2917 | loss: 0.002295485930517316 | dt: 321.18ms | tok/sec:  51012.56\n",
      "step2918 | loss: 0.0031214789487421513 | dt: 320.08ms | tok/sec:  51186.59\n",
      "step2919 | loss: 0.0021188827231526375 | dt: 320.97ms | tok/sec:  51045.56\n",
      "step2920 | loss: 0.0019539750646799803 | dt: 319.98ms | tok/sec:  51203.56\n",
      "step2921 | loss: 0.002171228639781475 | dt: 321.13ms | tok/sec:  51020.55\n",
      "step2922 | loss: 0.0028610089793801308 | dt: 319.77ms | tok/sec:  51237.46\n",
      "step2923 | loss: 0.002401915844529867 | dt: 321.57ms | tok/sec:  50950.00\n",
      "step2924 | loss: 0.0023872614838182926 | dt: 319.85ms | tok/sec:  51224.70\n",
      "step2925 | loss: 0.002392970025539398 | dt: 320.93ms | tok/sec:  51051.02\n",
      "step2926 | loss: 0.0019125298131257296 | dt: 320.10ms | tok/sec:  51184.57\n",
      "step2927 | loss: 0.0029190503992140293 | dt: 321.21ms | tok/sec:  51007.71\n",
      "step2928 | loss: 0.0020628231577575207 | dt: 319.66ms | tok/sec:  51254.31\n",
      "step2929 | loss: 0.0028477751184254885 | dt: 320.15ms | tok/sec:  51176.71\n",
      "step2930 | loss: 0.0026046247221529484 | dt: 321.17ms | tok/sec:  51013.39\n",
      "step2931 | loss: 0.0020412064623087645 | dt: 320.87ms | tok/sec:  51060.70\n",
      "step2932 | loss: 0.003001414705067873 | dt: 320.10ms | tok/sec:  51184.57\n",
      "step2933 | loss: 0.0023125968873500824 | dt: 321.36ms | tok/sec:  50983.83\n",
      "step2934 | loss: 0.0017549862386658788 | dt: 321.30ms | tok/sec:  50993.48\n",
      "step2935 | loss: 0.002113778842613101 | dt: 320.01ms | tok/sec:  51197.95\n",
      "step2936 | loss: 0.0018372420454397798 | dt: 320.34ms | tok/sec:  51145.63\n",
      "step2937 | loss: 0.0022569983266294003 | dt: 320.57ms | tok/sec:  51108.17\n",
      "step2938 | loss: 0.0031996360048651695 | dt: 320.43ms | tok/sec:  51130.91\n",
      "step2939 | loss: 0.002089905319735408 | dt: 320.83ms | tok/sec:  51066.92\n",
      "step2940 | loss: 0.0019169452134519815 | dt: 320.35ms | tok/sec:  51143.88\n",
      "step2941 | loss: 0.002189092803746462 | dt: 321.06ms | tok/sec:  51031.69\n",
      "step2942 | loss: 0.0028228573501110077 | dt: 319.75ms | tok/sec:  51240.36\n",
      "step2943 | loss: 0.0023735917638987303 | dt: 321.02ms | tok/sec:  51037.00\n",
      "step2944 | loss: 0.002287402283400297 | dt: 320.77ms | tok/sec:  51076.45\n",
      "step2945 | loss: 0.0023716138675808907 | dt: 319.99ms | tok/sec:  51201.99\n",
      "step2946 | loss: 0.0018809378379955888 | dt: 319.98ms | tok/sec:  51202.57\n",
      "step2947 | loss: 0.0028779683634638786 | dt: 320.56ms | tok/sec:  51110.56\n",
      "step2948 | loss: 0.002051680814474821 | dt: 320.76ms | tok/sec:  51078.50\n",
      "step2949 | loss: 0.0028279561083763838 | dt: 320.69ms | tok/sec:  51089.55\n",
      "step2950 | loss: 0.00257495092228055 | dt: 319.80ms | tok/sec:  51232.69\n",
      "step2951 | loss: 0.0020538042299449444 | dt: 321.08ms | tok/sec:  51027.48\n",
      "step2952 | loss: 0.002993018599227071 | dt: 321.30ms | tok/sec:  50993.37\n",
      "step2953 | loss: 0.002217640168964863 | dt: 320.95ms | tok/sec:  51048.98\n",
      "step2954 | loss: 0.0017582450527697802 | dt: 320.52ms | tok/sec:  51117.37\n",
      "step2955 | loss: 0.0020842819940298796 | dt: 320.14ms | tok/sec:  51178.20\n",
      "step2956 | loss: 0.0019462623167783022 | dt: 321.20ms | tok/sec:  51007.98\n",
      "step2957 | loss: 0.002237280597910285 | dt: 320.29ms | tok/sec:  51154.31\n",
      "step2958 | loss: 0.0030771279707551003 | dt: 321.17ms | tok/sec:  51013.47\n",
      "step2959 | loss: 0.002070873510092497 | dt: 319.89ms | tok/sec:  51217.72\n",
      "step2960 | loss: 0.0018949736841022968 | dt: 320.14ms | tok/sec:  51177.86\n",
      "step2961 | loss: 0.0021236438769847155 | dt: 321.39ms | tok/sec:  50978.12\n",
      "step2962 | loss: 0.0028105531819164753 | dt: 319.84ms | tok/sec:  51225.31\n",
      "step2963 | loss: 0.0023384224623441696 | dt: 320.62ms | tok/sec:  51100.75\n",
      "step2964 | loss: 0.0023303860798478127 | dt: 321.06ms | tok/sec:  51031.16\n",
      "step2965 | loss: 0.002354661002755165 | dt: 319.92ms | tok/sec:  51212.60\n",
      "step2966 | loss: 0.0018539607990533113 | dt: 320.63ms | tok/sec:  51099.39\n",
      "step2967 | loss: 0.002874152734875679 | dt: 320.18ms | tok/sec:  51171.11\n",
      "step2968 | loss: 0.002016227226704359 | dt: 320.95ms | tok/sec:  51049.01\n",
      "step2969 | loss: 0.0028023109771311283 | dt: 321.21ms | tok/sec:  51007.22\n",
      "step2970 | loss: 0.0025616539642214775 | dt: 319.99ms | tok/sec:  51201.61\n",
      "step2971 | loss: 0.0019932370632886887 | dt: 320.64ms | tok/sec:  51097.22\n",
      "step2972 | loss: 0.0029606723692268133 | dt: 320.45ms | tok/sec:  51128.51\n",
      "step2973 | loss: 0.002258004155009985 | dt: 320.17ms | tok/sec:  51173.36\n",
      "step2974 | loss: 0.001695506856776774 | dt: 320.35ms | tok/sec:  51143.27\n",
      "step2975 | loss: 0.002062818268314004 | dt: 320.31ms | tok/sec:  51149.97\n",
      "step2976 | loss: 0.0017882660031318665 | dt: 319.90ms | tok/sec:  51216.53\n",
      "step2977 | loss: 0.0022060032933950424 | dt: 321.04ms | tok/sec:  51034.53\n",
      "step2978 | loss: 0.0031563546508550644 | dt: 320.01ms | tok/sec:  51198.75\n",
      "step2979 | loss: 0.002044015098363161 | dt: 321.01ms | tok/sec:  51039.23\n",
      "step2980 | loss: 0.0018704626709222794 | dt: 319.82ms | tok/sec:  51228.18\n",
      "step2981 | loss: 0.00214038765989244 | dt: 321.14ms | tok/sec:  51017.67\n",
      "step2982 | loss: 0.002769866958260536 | dt: 320.93ms | tok/sec:  51051.55\n",
      "step2983 | loss: 0.002334677381440997 | dt: 321.03ms | tok/sec:  51035.63\n",
      "step2984 | loss: 0.002241088543087244 | dt: 320.13ms | tok/sec:  51179.23\n",
      "step2985 | loss: 0.0023258577566593885 | dt: 320.46ms | tok/sec:  51126.99\n",
      "step2986 | loss: 0.0018256306648254395 | dt: 320.06ms | tok/sec:  51190.40\n",
      "step2987 | loss: 0.0028227658476680517 | dt: 321.19ms | tok/sec:  51010.25\n",
      "step2988 | loss: 0.001998503692448139 | dt: 320.68ms | tok/sec:  51091.83\n",
      "step2989 | loss: 0.0027862810529768467 | dt: 321.49ms | tok/sec:  50962.47\n",
      "step2990 | loss: 0.0025236401706933975 | dt: 320.61ms | tok/sec:  51102.05\n",
      "step2991 | loss: 0.002005245303735137 | dt: 321.04ms | tok/sec:  51033.70\n",
      "step2992 | loss: 0.002939708298072219 | dt: 320.78ms | tok/sec:  51075.46\n",
      "step2993 | loss: 0.0021714537870138884 | dt: 320.96ms | tok/sec:  51046.47\n",
      "step2994 | loss: 0.0016969847492873669 | dt: 319.82ms | tok/sec:  51229.10\n",
      "step2995 | loss: 0.0020302480552345514 | dt: 321.16ms | tok/sec:  51015.47\n",
      "step2996 | loss: 0.001902326475828886 | dt: 320.61ms | tok/sec:  51102.84\n",
      "step2997 | loss: 0.0021962327882647514 | dt: 320.72ms | tok/sec:  51085.56\n",
      "step2998 | loss: 0.003027840983122587 | dt: 320.90ms | tok/sec:  51055.95\n",
      "step2999 | loss: 0.002023161854594946 | dt: 320.18ms | tok/sec:  51171.42\n",
      "Prediction at step 3000: \n",
      " : This is a fixed text used for prediction. or party all God not enemies, hence.\n",
      " \n",
      "\n",
      "step3000 | loss: 0.0018451561918482184 | dt: 318.95ms | tok/sec:  51368.49\n",
      "step3001 | loss: 0.0020752705167979 | dt: 319.20ms | tok/sec:  51327.78\n",
      "step3002 | loss: 0.002762742107734084 | dt: 320.71ms | tok/sec:  51086.77\n",
      "step3003 | loss: 0.002294131089001894 | dt: 321.91ms | tok/sec:  50896.30\n",
      "step3004 | loss: 0.002279949141666293 | dt: 319.34ms | tok/sec:  51305.32\n",
      "step3005 | loss: 0.0023016235791146755 | dt: 319.70ms | tok/sec:  51248.58\n",
      "step3006 | loss: 0.001797366188839078 | dt: 321.52ms | tok/sec:  50958.39\n",
      "step3007 | loss: 0.002812054706737399 | dt: 320.01ms | tok/sec:  51198.56\n",
      "step3008 | loss: 0.0019671982154250145 | dt: 319.68ms | tok/sec:  51250.49\n",
      "step3009 | loss: 0.0027554924599826336 | dt: 321.21ms | tok/sec:  51006.88\n",
      "step3010 | loss: 0.0025088205002248287 | dt: 320.27ms | tok/sec:  51157.32\n",
      "step3011 | loss: 0.001944815507158637 | dt: 321.16ms | tok/sec:  51015.21\n",
      "step3012 | loss: 0.0029126089066267014 | dt: 320.27ms | tok/sec:  51157.17\n",
      "step3013 | loss: 0.0021970123052597046 | dt: 321.07ms | tok/sec:  51029.64\n",
      "step3014 | loss: 0.001655742758885026 | dt: 320.79ms | tok/sec:  51074.28\n",
      "step3015 | loss: 0.0020217997953295708 | dt: 321.07ms | tok/sec:  51029.42\n",
      "step3016 | loss: 0.0017394589958712459 | dt: 320.58ms | tok/sec:  51106.68\n",
      "step3017 | loss: 0.002155244117602706 | dt: 321.00ms | tok/sec:  51039.91\n",
      "step3018 | loss: 0.0030969674699008465 | dt: 321.02ms | tok/sec:  51037.45\n",
      "step3019 | loss: 0.002004951238632202 | dt: 321.17ms | tok/sec:  51013.69\n",
      "step3020 | loss: 0.0018141575856134295 | dt: 320.83ms | tok/sec:  51066.92\n",
      "step3021 | loss: 0.00208804989233613 | dt: 320.91ms | tok/sec:  51054.48\n",
      "step3022 | loss: 0.002712852554395795 | dt: 320.78ms | tok/sec:  51075.57\n",
      "step3023 | loss: 0.0022803139872848988 | dt: 319.63ms | tok/sec:  51258.63\n",
      "step3024 | loss: 0.0021987527143210173 | dt: 320.97ms | tok/sec:  51045.98\n",
      "step3025 | loss: 0.002267810981720686 | dt: 321.26ms | tok/sec:  50998.89\n",
      "step3026 | loss: 0.0017848252318799496 | dt: 320.26ms | tok/sec:  51158.50\n",
      "step3027 | loss: 0.0027843231800943613 | dt: 321.35ms | tok/sec:  50985.35\n",
      "step3028 | loss: 0.001954717794433236 | dt: 321.00ms | tok/sec:  51040.52\n",
      "step3029 | loss: 0.002736818976700306 | dt: 320.98ms | tok/sec:  51043.25\n",
      "step3030 | loss: 0.00247940793633461 | dt: 321.13ms | tok/sec:  51020.13\n",
      "step3031 | loss: 0.0019649046007543802 | dt: 320.93ms | tok/sec:  51051.21\n",
      "step3032 | loss: 0.0028871602844446898 | dt: 320.85ms | tok/sec:  51064.04\n",
      "step3033 | loss: 0.0021174438297748566 | dt: 321.22ms | tok/sec:  51004.83\n",
      "step3034 | loss: 0.0016364632174372673 | dt: 320.21ms | tok/sec:  51166.88\n",
      "step3035 | loss: 0.0019735030364245176 | dt: 320.92ms | tok/sec:  51053.26\n",
      "step3036 | loss: 0.0018547945655882359 | dt: 320.97ms | tok/sec:  51045.34\n",
      "step3037 | loss: 0.002147975843399763 | dt: 320.91ms | tok/sec:  51055.35\n",
      "step3038 | loss: 0.0029839121270924807 | dt: 319.95ms | tok/sec:  51208.56\n",
      "step3039 | loss: 0.0019823159091174603 | dt: 320.66ms | tok/sec:  51094.64\n",
      "step3040 | loss: 0.0017942289123311639 | dt: 320.41ms | tok/sec:  51134.18\n",
      "step3041 | loss: 0.0020327712409198284 | dt: 321.50ms | tok/sec:  50961.49\n",
      "step3042 | loss: 0.0027029761113226414 | dt: 319.64ms | tok/sec:  51257.98\n",
      "step3043 | loss: 0.0022503319196403027 | dt: 320.88ms | tok/sec:  51059.52\n",
      "step3044 | loss: 0.00222472264431417 | dt: 320.06ms | tok/sec:  51191.05\n",
      "step3045 | loss: 0.0022482594940811396 | dt: 320.03ms | tok/sec:  51195.28\n",
      "step3046 | loss: 0.001747988280840218 | dt: 320.28ms | tok/sec:  51154.81\n",
      "step3047 | loss: 0.0027709980495274067 | dt: 321.21ms | tok/sec:  51007.90\n",
      "step3048 | loss: 0.0019139128271490335 | dt: 320.41ms | tok/sec:  51134.79\n",
      "step3049 | loss: 0.002702005673199892 | dt: 320.20ms | tok/sec:  51167.95\n",
      "step3050 | loss: 0.002460704417899251 | dt: 320.40ms | tok/sec:  51136.27\n",
      "step3051 | loss: 0.0018965470371767879 | dt: 321.30ms | tok/sec:  50993.56\n",
      "step3052 | loss: 0.0028742935974150896 | dt: 320.48ms | tok/sec:  51122.96\n",
      "step3053 | loss: 0.002160024596378207 | dt: 319.98ms | tok/sec:  51202.91\n",
      "step3054 | loss: 0.001604960998520255 | dt: 320.18ms | tok/sec:  51171.45\n",
      "step3055 | loss: 0.001975194551050663 | dt: 321.04ms | tok/sec:  51034.49\n",
      "step3056 | loss: 0.0016979053616523743 | dt: 321.30ms | tok/sec:  50993.29\n",
      "step3057 | loss: 0.002117885509505868 | dt: 321.14ms | tok/sec:  51017.67\n",
      "step3058 | loss: 0.003051111241802573 | dt: 320.95ms | tok/sec:  51047.95\n",
      "step3059 | loss: 0.001957426778972149 | dt: 320.59ms | tok/sec:  51106.30\n",
      "step3060 | loss: 0.0017671873793005943 | dt: 319.97ms | tok/sec:  51204.44\n",
      "step3061 | loss: 0.002038551028817892 | dt: 321.25ms | tok/sec:  51000.14\n",
      "step3062 | loss: 0.002672507893294096 | dt: 319.55ms | tok/sec:  51271.45\n",
      "step3063 | loss: 0.0022385073825716972 | dt: 320.33ms | tok/sec:  51147.19\n",
      "step3064 | loss: 0.0021674800664186478 | dt: 321.09ms | tok/sec:  51025.89\n",
      "step3065 | loss: 0.002223595045506954 | dt: 320.98ms | tok/sec:  51043.55\n",
      "step3066 | loss: 0.0017357633914798498 | dt: 320.83ms | tok/sec:  51067.00\n",
      "step3067 | loss: 0.0027312282472848892 | dt: 321.51ms | tok/sec:  50960.20\n",
      "step3068 | loss: 0.0019014535937458277 | dt: 320.07ms | tok/sec:  51188.95\n",
      "step3069 | loss: 0.002699541859328747 | dt: 321.08ms | tok/sec:  51027.07\n",
      "step3070 | loss: 0.002428862266242504 | dt: 320.11ms | tok/sec:  51181.74\n",
      "step3071 | loss: 0.0019245723960921168 | dt: 321.01ms | tok/sec:  51039.53\n",
      "step3072 | loss: 0.00284748082049191 | dt: 320.44ms | tok/sec:  51130.18\n",
      "step3073 | loss: 0.0020705147180706263 | dt: 320.30ms | tok/sec:  51151.69\n",
      "step3074 | loss: 0.0016014543361961842 | dt: 319.99ms | tok/sec:  51202.34\n",
      "step3075 | loss: 0.0019385013729333878 | dt: 321.31ms | tok/sec:  50991.74\n",
      "step3076 | loss: 0.0018108492949977517 | dt: 320.84ms | tok/sec:  51065.74\n",
      "step3077 | loss: 0.0021016914397478104 | dt: 321.19ms | tok/sec:  51011.04\n",
      "step3078 | loss: 0.002941898303106427 | dt: 320.20ms | tok/sec:  51167.95\n",
      "step3079 | loss: 0.0019467034144327044 | dt: 320.45ms | tok/sec:  51128.20\n",
      "step3080 | loss: 0.0017455843044444919 | dt: 321.09ms | tok/sec:  51026.69\n",
      "step3081 | loss: 0.001996366074308753 | dt: 320.73ms | tok/sec:  51082.82\n",
      "step3082 | loss: 0.002668334636837244 | dt: 319.72ms | tok/sec:  51244.34\n",
      "step3083 | loss: 0.0022051383275538683 | dt: 320.08ms | tok/sec:  51187.35\n",
      "step3084 | loss: 0.00218762643635273 | dt: 321.07ms | tok/sec:  51029.68\n",
      "step3085 | loss: 0.00221410789526999 | dt: 320.99ms | tok/sec:  51042.07\n",
      "step3086 | loss: 0.0017028233269229531 | dt: 320.15ms | tok/sec:  51175.42\n",
      "step3087 | loss: 0.0027332771569490433 | dt: 320.96ms | tok/sec:  51047.16\n",
      "step3088 | loss: 0.0018774932250380516 | dt: 320.42ms | tok/sec:  51133.57\n",
      "step3089 | loss: 0.0026594612281769514 | dt: 320.93ms | tok/sec:  51051.40\n",
      "step3090 | loss: 0.0024191716220229864 | dt: 320.97ms | tok/sec:  51045.18\n",
      "step3091 | loss: 0.0018547044601291418 | dt: 320.90ms | tok/sec:  51057.17\n",
      "step3092 | loss: 0.0028176160994917154 | dt: 319.82ms | tok/sec:  51228.03\n",
      "step3093 | loss: 0.002123029436916113 | dt: 321.01ms | tok/sec:  51039.50\n",
      "step3094 | loss: 0.0015580222243443131 | dt: 320.86ms | tok/sec:  51063.24\n",
      "step3095 | loss: 0.001925313612446189 | dt: 320.98ms | tok/sec:  51044.27\n",
      "step3096 | loss: 0.0016553166788071394 | dt: 320.79ms | tok/sec:  51074.40\n",
      "step3097 | loss: 0.002077004173770547 | dt: 319.68ms | tok/sec:  51250.45\n",
      "step3098 | loss: 0.003013350535184145 | dt: 320.61ms | tok/sec:  51103.07\n",
      "step3099 | loss: 0.0019215629436075687 | dt: 321.27ms | tok/sec:  50996.81\n",
      "step3100 | loss: 0.001720439177006483 | dt: 320.22ms | tok/sec:  51164.37\n",
      "step3101 | loss: 0.001997035928070545 | dt: 321.08ms | tok/sec:  51027.22\n",
      "step3102 | loss: 0.0026306265499442816 | dt: 321.18ms | tok/sec:  51012.63\n",
      "step3103 | loss: 0.002195869805291295 | dt: 321.00ms | tok/sec:  51039.88\n",
      "step3104 | loss: 0.002130154985934496 | dt: 320.31ms | tok/sec:  51150.24\n",
      "step3105 | loss: 0.0021843586582690477 | dt: 321.16ms | tok/sec:  51014.49\n",
      "step3106 | loss: 0.0016916061285883188 | dt: 320.23ms | tok/sec:  51163.95\n",
      "step3107 | loss: 0.0026929364539682865 | dt: 321.00ms | tok/sec:  51040.67\n",
      "step3108 | loss: 0.0018549017840996385 | dt: 319.95ms | tok/sec:  51208.52\n",
      "step3109 | loss: 0.0026633210945874453 | dt: 321.00ms | tok/sec:  51040.52\n",
      "step3110 | loss: 0.0024039021227508783 | dt: 319.70ms | tok/sec:  51248.69\n",
      "step3111 | loss: 0.0018823250429704785 | dt: 321.10ms | tok/sec:  51023.85\n",
      "step3112 | loss: 0.0028153369203209877 | dt: 321.10ms | tok/sec:  51024.91\n",
      "step3113 | loss: 0.0020244771149009466 | dt: 320.84ms | tok/sec:  51065.52\n",
      "step3114 | loss: 0.0015588669339194894 | dt: 320.57ms | tok/sec:  51109.72\n",
      "step3115 | loss: 0.0018834060756489635 | dt: 320.08ms | tok/sec:  51187.81\n",
      "step3116 | loss: 0.001771074254065752 | dt: 319.48ms | tok/sec:  51283.61\n",
      "step3117 | loss: 0.002064085565507412 | dt: 320.47ms | tok/sec:  51125.09\n",
      "step3118 | loss: 0.00290103442966938 | dt: 320.10ms | tok/sec:  51183.54\n",
      "step3119 | loss: 0.0019042582716792822 | dt: 321.05ms | tok/sec:  51033.21\n",
      "step3120 | loss: 0.0017083196435123682 | dt: 320.82ms | tok/sec:  51069.08\n",
      "step3121 | loss: 0.0019572838209569454 | dt: 321.07ms | tok/sec:  51029.11\n",
      "step3122 | loss: 0.002619221806526184 | dt: 319.79ms | tok/sec:  51233.18\n",
      "step3123 | loss: 0.0021750337909907103 | dt: 320.90ms | tok/sec:  51056.52\n",
      "step3124 | loss: 0.0021378479432314634 | dt: 321.15ms | tok/sec:  51016.57\n",
      "step3125 | loss: 0.002170746447518468 | dt: 321.09ms | tok/sec:  51026.61\n",
      "step3126 | loss: 0.0016645386349409819 | dt: 321.14ms | tok/sec:  51017.90\n",
      "step3127 | loss: 0.002698858268558979 | dt: 320.91ms | tok/sec:  51054.78\n",
      "step3128 | loss: 0.0018314174376428127 | dt: 319.95ms | tok/sec:  51208.52\n",
      "step3129 | loss: 0.0026292467955499887 | dt: 321.21ms | tok/sec:  51007.86\n",
      "step3130 | loss: 0.0023834630846977234 | dt: 320.22ms | tok/sec:  51165.40\n",
      "step3131 | loss: 0.0018134487327188253 | dt: 319.95ms | tok/sec:  51207.95\n",
      "step3132 | loss: 0.002777072601020336 | dt: 321.07ms | tok/sec:  51029.64\n",
      "step3133 | loss: 0.002074632328003645 | dt: 320.67ms | tok/sec:  51092.62\n",
      "step3134 | loss: 0.0015189743135124445 | dt: 320.02ms | tok/sec:  51196.43\n",
      "step3135 | loss: 0.0018932733219116926 | dt: 320.83ms | tok/sec:  51068.13\n",
      "step3136 | loss: 0.0016178444493561983 | dt: 320.45ms | tok/sec:  51127.71\n",
      "step3137 | loss: 0.0020369146950542927 | dt: 321.02ms | tok/sec:  51037.00\n",
      "step3138 | loss: 0.00297071342356503 | dt: 320.84ms | tok/sec:  51065.78\n",
      "step3139 | loss: 0.0018863006262108684 | dt: 320.99ms | tok/sec:  51042.80\n",
      "step3140 | loss: 0.0016745016910135746 | dt: 320.04ms | tok/sec:  51192.99\n",
      "step3141 | loss: 0.001968187279999256 | dt: 320.98ms | tok/sec:  51043.63\n",
      "step3142 | loss: 0.0025972938165068626 | dt: 320.35ms | tok/sec:  51143.35\n",
      "step3143 | loss: 0.002155321417376399 | dt: 320.49ms | tok/sec:  51122.00\n",
      "step3144 | loss: 0.002081210259348154 | dt: 321.06ms | tok/sec:  51031.04\n",
      "step3145 | loss: 0.0021546129137277603 | dt: 321.02ms | tok/sec:  51037.26\n",
      "step3146 | loss: 0.0016460351180285215 | dt: 319.97ms | tok/sec:  51204.89\n",
      "step3147 | loss: 0.002654253039509058 | dt: 320.25ms | tok/sec:  51160.37\n",
      "step3148 | loss: 0.0018119396409019828 | dt: 320.30ms | tok/sec:  51151.91\n",
      "step3149 | loss: 0.0026271590031683445 | dt: 320.19ms | tok/sec:  51169.47\n",
      "step3150 | loss: 0.002351529197767377 | dt: 320.62ms | tok/sec:  51100.41\n",
      "step3151 | loss: 0.0018391470657661557 | dt: 320.69ms | tok/sec:  51090.46\n",
      "step3152 | loss: 0.0027770029846578836 | dt: 320.46ms | tok/sec:  51126.04\n",
      "step3153 | loss: 0.001990176271647215 | dt: 320.96ms | tok/sec:  51046.36\n",
      "step3154 | loss: 0.0015145365614444017 | dt: 320.85ms | tok/sec:  51064.95\n",
      "step3155 | loss: 0.0018436124082654715 | dt: 321.23ms | tok/sec:  51003.81\n",
      "step3156 | loss: 0.0017351089045405388 | dt: 320.01ms | tok/sec:  51198.37\n",
      "step3157 | loss: 0.0020362967625260353 | dt: 319.80ms | tok/sec:  51232.61\n",
      "step3158 | loss: 0.002866053953766823 | dt: 320.28ms | tok/sec:  51155.76\n",
      "step3159 | loss: 0.0018664868548512459 | dt: 321.62ms | tok/sec:  50942.60\n",
      "step3160 | loss: 0.0016696113161742687 | dt: 320.36ms | tok/sec:  51141.90\n",
      "step3161 | loss: 0.0019100324716418982 | dt: 320.36ms | tok/sec:  51142.21\n",
      "step3162 | loss: 0.0025761928409337997 | dt: 320.81ms | tok/sec:  51071.06\n",
      "step3163 | loss: 0.0021498925052583218 | dt: 321.28ms | tok/sec:  50996.77\n",
      "step3164 | loss: 0.00209419266320765 | dt: 320.14ms | tok/sec:  51178.31\n",
      "step3165 | loss: 0.0021265617106109858 | dt: 321.12ms | tok/sec:  51021.91\n",
      "step3166 | loss: 0.001615692861378193 | dt: 320.47ms | tok/sec:  51124.63\n",
      "step3167 | loss: 0.002645089291036129 | dt: 321.09ms | tok/sec:  51026.88\n",
      "step3168 | loss: 0.0018007925245910883 | dt: 320.62ms | tok/sec:  51101.70\n",
      "step3169 | loss: 0.00259513221681118 | dt: 321.40ms | tok/sec:  50976.42\n",
      "step3170 | loss: 0.002348258625715971 | dt: 320.23ms | tok/sec:  51163.07\n",
      "step3171 | loss: 0.0017738919705152512 | dt: 320.67ms | tok/sec:  51092.47\n",
      "step3172 | loss: 0.0027497005648911 | dt: 320.05ms | tok/sec:  51192.69\n",
      "step3173 | loss: 0.0020349686965346336 | dt: 320.45ms | tok/sec:  51127.60\n",
      "step3174 | loss: 0.0014659836888313293 | dt: 319.77ms | tok/sec:  51237.50\n",
      "step3175 | loss: 0.001857526134699583 | dt: 320.89ms | tok/sec:  51057.21\n",
      "step3176 | loss: 0.001579892705194652 | dt: 319.82ms | tok/sec:  51229.48\n",
      "step3177 | loss: 0.0020010313019156456 | dt: 321.19ms | tok/sec:  51009.53\n",
      "step3178 | loss: 0.0029178184922784567 | dt: 320.84ms | tok/sec:  51065.67\n",
      "step3179 | loss: 0.0018468224443495274 | dt: 321.40ms | tok/sec:  50977.21\n",
      "step3180 | loss: 0.0016407016664743423 | dt: 320.24ms | tok/sec:  51161.78\n",
      "step3181 | loss: 0.0019384033512324095 | dt: 321.26ms | tok/sec:  50998.55\n",
      "step3182 | loss: 0.002547258511185646 | dt: 320.49ms | tok/sec:  51121.97\n",
      "step3183 | loss: 0.002111389534547925 | dt: 320.54ms | tok/sec:  51113.64\n",
      "step3184 | loss: 0.0020511853508651257 | dt: 319.92ms | tok/sec:  51213.29\n",
      "step3185 | loss: 0.002111170906573534 | dt: 320.03ms | tok/sec:  51194.56\n",
      "step3186 | loss: 0.0016036909073591232 | dt: 320.28ms | tok/sec:  51155.00\n",
      "step3187 | loss: 0.002618263941258192 | dt: 320.61ms | tok/sec:  51103.26\n",
      "step3188 | loss: 0.0017766030505299568 | dt: 319.95ms | tok/sec:  51207.49\n",
      "step3189 | loss: 0.002585626905784011 | dt: 321.24ms | tok/sec:  51003.02\n",
      "step3190 | loss: 0.0023193974047899246 | dt: 321.17ms | tok/sec:  51013.77\n",
      "step3191 | loss: 0.0017979149706661701 | dt: 320.82ms | tok/sec:  51069.58\n",
      "step3192 | loss: 0.002734758425503969 | dt: 320.79ms | tok/sec:  51074.62\n",
      "step3193 | loss: 0.0019505030941218138 | dt: 321.16ms | tok/sec:  51015.44\n",
      "step3194 | loss: 0.001478696591220796 | dt: 320.31ms | tok/sec:  51150.54\n",
      "step3195 | loss: 0.0018009775085374713 | dt: 321.02ms | tok/sec:  51037.00\n",
      "step3196 | loss: 0.0017005570698529482 | dt: 320.25ms | tok/sec:  51159.87\n",
      "step3197 | loss: 0.001995125086978078 | dt: 320.91ms | tok/sec:  51054.29\n",
      "step3198 | loss: 0.002829508390277624 | dt: 320.81ms | tok/sec:  51071.28\n",
      "step3199 | loss: 0.0018340195529162884 | dt: 321.07ms | tok/sec:  51029.11\n",
      "step3200 | loss: 0.001632135477848351 | dt: 320.44ms | tok/sec:  51129.61\n",
      "step3201 | loss: 0.001877401489764452 | dt: 321.11ms | tok/sec:  51022.41\n",
      "step3202 | loss: 0.002544119255617261 | dt: 320.00ms | tok/sec:  51200.43\n",
      "step3203 | loss: 0.0021163830533623695 | dt: 321.03ms | tok/sec:  51036.09\n",
      "step3204 | loss: 0.002066745888441801 | dt: 319.62ms | tok/sec:  51261.04\n",
      "step3205 | loss: 0.0020904159173369408 | dt: 320.19ms | tok/sec:  51168.90\n",
      "step3206 | loss: 0.0015845791203901172 | dt: 321.21ms | tok/sec:  51006.39\n",
      "step3207 | loss: 0.0026223016902804375 | dt: 320.83ms | tok/sec:  51067.19\n",
      "step3208 | loss: 0.0017590724164620042 | dt: 320.37ms | tok/sec:  51141.48\n",
      "step3209 | loss: 0.0025558997876942158 | dt: 321.19ms | tok/sec:  51009.64\n",
      "step3210 | loss: 0.002306397305801511 | dt: 319.64ms | tok/sec:  51257.79\n",
      "step3211 | loss: 0.0017431308515369892 | dt: 321.20ms | tok/sec:  51009.11\n",
      "step3212 | loss: 0.0026940652169287205 | dt: 321.24ms | tok/sec:  51001.81\n",
      "step3213 | loss: 0.0020005907863378525 | dt: 320.97ms | tok/sec:  51045.94\n",
      "step3214 | loss: 0.0014292511623352766 | dt: 320.85ms | tok/sec:  51064.79\n",
      "step3215 | loss: 0.0018277316121384501 | dt: 320.14ms | tok/sec:  51177.97\n",
      "step3216 | loss: 0.0015447349287569523 | dt: 319.79ms | tok/sec:  51233.33\n",
      "step3217 | loss: 0.001970076933503151 | dt: 320.92ms | tok/sec:  51053.72\n",
      "step3218 | loss: 0.002887062029913068 | dt: 319.96ms | tok/sec:  51206.53\n",
      "step3219 | loss: 0.0018186396919190884 | dt: 320.86ms | tok/sec:  51062.06\n",
      "step3220 | loss: 0.001602759468369186 | dt: 320.94ms | tok/sec:  51049.96\n",
      "step3221 | loss: 0.0018994379788637161 | dt: 320.38ms | tok/sec:  51138.74\n",
      "step3222 | loss: 0.0025117327459156513 | dt: 320.31ms | tok/sec:  51150.12\n",
      "step3223 | loss: 0.002092620823532343 | dt: 321.08ms | tok/sec:  51027.26\n",
      "step3224 | loss: 0.002016567625105381 | dt: 319.49ms | tok/sec:  51281.20\n",
      "step3225 | loss: 0.0020746251102536917 | dt: 321.00ms | tok/sec:  51039.99\n",
      "step3226 | loss: 0.0015710724983364344 | dt: 320.12ms | tok/sec:  51181.36\n",
      "step3227 | loss: 0.002577603328973055 | dt: 321.05ms | tok/sec:  51032.41\n",
      "step3228 | loss: 0.0017345179803669453 | dt: 320.28ms | tok/sec:  51155.72\n",
      "step3229 | loss: 0.0025501183699816465 | dt: 321.41ms | tok/sec:  50975.74\n",
      "step3230 | loss: 0.0022850444074720144 | dt: 320.33ms | tok/sec:  51146.70\n",
      "step3231 | loss: 0.0017650672234594822 | dt: 320.66ms | tok/sec:  51095.28\n",
      "step3232 | loss: 0.00270550767891109 | dt: 320.73ms | tok/sec:  51083.36\n",
      "step3233 | loss: 0.0019155204063281417 | dt: 321.31ms | tok/sec:  50991.40\n",
      "step3234 | loss: 0.0014384591486304998 | dt: 320.69ms | tok/sec:  51090.04\n",
      "step3235 | loss: 0.001767138484865427 | dt: 321.19ms | tok/sec:  51009.83\n",
      "step3236 | loss: 0.001657351152971387 | dt: 320.92ms | tok/sec:  51052.54\n",
      "step3237 | loss: 0.001966154668480158 | dt: 320.88ms | tok/sec:  51060.20\n",
      "step3238 | loss: 0.0027942173182964325 | dt: 320.58ms | tok/sec:  51107.63\n",
      "step3239 | loss: 0.0018046705517917871 | dt: 321.08ms | tok/sec:  51028.39\n",
      "step3240 | loss: 0.001585196005180478 | dt: 320.95ms | tok/sec:  51047.69\n",
      "step3241 | loss: 0.0018466038163751364 | dt: 321.36ms | tok/sec:  50982.77\n",
      "step3242 | loss: 0.002502609044313431 | dt: 320.89ms | tok/sec:  51058.31\n",
      "step3243 | loss: 0.0020806528627872467 | dt: 320.84ms | tok/sec:  51066.39\n",
      "step3244 | loss: 0.0020275581628084183 | dt: 319.85ms | tok/sec:  51224.13\n",
      "step3245 | loss: 0.00205618585459888 | dt: 320.29ms | tok/sec:  51153.32\n",
      "step3246 | loss: 0.0015409097541123629 | dt: 320.53ms | tok/sec:  51115.92\n",
      "step3247 | loss: 0.002580218482762575 | dt: 320.95ms | tok/sec:  51049.05\n",
      "step3248 | loss: 0.0017302078194916248 | dt: 320.11ms | tok/sec:  51181.97\n",
      "step3249 | loss: 0.002525672083720565 | dt: 321.08ms | tok/sec:  51027.79\n",
      "step3250 | loss: 0.002280589658766985 | dt: 319.81ms | tok/sec:  51229.71\n",
      "step3251 | loss: 0.0017178916605189443 | dt: 320.14ms | tok/sec:  51178.20\n",
      "step3252 | loss: 0.0026751654222607613 | dt: 320.99ms | tok/sec:  51041.81\n",
      "step3253 | loss: 0.001969762146472931 | dt: 320.97ms | tok/sec:  51045.26\n",
      "step3254 | loss: 0.0013975908514112234 | dt: 319.81ms | tok/sec:  51231.00\n",
      "step3255 | loss: 0.0017932725604623556 | dt: 321.37ms | tok/sec:  50982.21\n",
      "step3256 | loss: 0.001514534349553287 | dt: 320.16ms | tok/sec:  51174.92\n",
      "step3257 | loss: 0.0019322803709656 | dt: 321.36ms | tok/sec:  50983.91\n",
      "step3258 | loss: 0.0028498959727585316 | dt: 320.92ms | tok/sec:  51053.68\n",
      "step3259 | loss: 0.0017847878625616431 | dt: 320.22ms | tok/sec:  51165.36\n",
      "step3260 | loss: 0.0015780201647430658 | dt: 321.12ms | tok/sec:  51021.88\n",
      "step3261 | loss: 0.0018607850652188063 | dt: 319.90ms | tok/sec:  51215.27\n",
      "step3262 | loss: 0.0024817627854645252 | dt: 319.82ms | tok/sec:  51228.29\n",
      "step3263 | loss: 0.0020483722910284996 | dt: 320.88ms | tok/sec:  51059.67\n",
      "step3264 | loss: 0.0019928228575736284 | dt: 320.25ms | tok/sec:  51160.60\n",
      "step3265 | loss: 0.002046282636001706 | dt: 321.03ms | tok/sec:  51036.50\n",
      "step3266 | loss: 0.0015383039135485888 | dt: 320.43ms | tok/sec:  51131.44\n",
      "step3267 | loss: 0.002538362517952919 | dt: 321.14ms | tok/sec:  51018.35\n",
      "step3268 | loss: 0.001694017555564642 | dt: 320.90ms | tok/sec:  51056.56\n",
      "step3269 | loss: 0.002517803106456995 | dt: 321.06ms | tok/sec:  51031.23\n",
      "step3270 | loss: 0.002248245757073164 | dt: 320.82ms | tok/sec:  51069.35\n",
      "step3271 | loss: 0.0017334317089989781 | dt: 321.20ms | tok/sec:  51008.32\n",
      "step3272 | loss: 0.002670241054147482 | dt: 321.02ms | tok/sec:  51037.26\n",
      "step3273 | loss: 0.0018828627653419971 | dt: 321.03ms | tok/sec:  51035.02\n",
      "step3274 | loss: 0.001402389956638217 | dt: 321.22ms | tok/sec:  51005.25\n",
      "step3275 | loss: 0.0017291571712121367 | dt: 320.87ms | tok/sec:  51061.30\n",
      "step3276 | loss: 0.001627270132303238 | dt: 320.50ms | tok/sec:  51120.52\n",
      "step3277 | loss: 0.0019174700137227774 | dt: 321.21ms | tok/sec:  51006.39\n",
      "step3278 | loss: 0.0027554132975637913 | dt: 320.49ms | tok/sec:  51122.27\n",
      "step3279 | loss: 0.001780823920853436 | dt: 320.34ms | tok/sec:  51144.91\n",
      "step3280 | loss: 0.0015479146968573332 | dt: 320.52ms | tok/sec:  51117.21\n",
      "step3281 | loss: 0.0018138742307201028 | dt: 320.78ms | tok/sec:  51075.73\n",
      "step3282 | loss: 0.0024750125594437122 | dt: 321.02ms | tok/sec:  51037.83\n",
      "step3283 | loss: 0.0020538142416626215 | dt: 321.16ms | tok/sec:  51014.57\n",
      "step3284 | loss: 0.0019893264397978783 | dt: 320.43ms | tok/sec:  51131.21\n",
      "step3285 | loss: 0.0020152295473963022 | dt: 320.76ms | tok/sec:  51078.69\n",
      "step3286 | loss: 0.001499932142905891 | dt: 320.90ms | tok/sec:  51057.13\n",
      "step3287 | loss: 0.002550281584262848 | dt: 320.99ms | tok/sec:  51041.73\n",
      "step3288 | loss: 0.0016992620658129454 | dt: 321.05ms | tok/sec:  51033.28\n",
      "step3289 | loss: 0.0024921330623328686 | dt: 320.93ms | tok/sec:  51052.05\n",
      "step3290 | loss: 0.0022475826554000378 | dt: 320.70ms | tok/sec:  51087.84\n",
      "step3291 | loss: 0.0016765383770689368 | dt: 321.33ms | tok/sec:  50988.41\n",
      "step3292 | loss: 0.0026340000331401825 | dt: 320.44ms | tok/sec:  51129.99\n",
      "step3293 | loss: 0.0019356525735929608 | dt: 320.57ms | tok/sec:  51108.96\n",
      "step3294 | loss: 0.0013577684294432402 | dt: 320.37ms | tok/sec:  51141.45\n",
      "step3295 | loss: 0.0017667056526988745 | dt: 320.76ms | tok/sec:  51078.15\n",
      "step3296 | loss: 0.001485389773733914 | dt: 319.96ms | tok/sec:  51205.92\n",
      "step3297 | loss: 0.001900223782286048 | dt: 321.19ms | tok/sec:  51009.98\n",
      "step3298 | loss: 0.0028169197030365467 | dt: 321.06ms | tok/sec:  51030.59\n",
      "step3299 | loss: 0.0017478960799053311 | dt: 320.96ms | tok/sec:  51046.78\n",
      "step3300 | loss: 0.0015390575863420963 | dt: 321.44ms | tok/sec:  50969.95\n",
      "step3301 | loss: 0.0018307435093447566 | dt: 320.43ms | tok/sec:  51132.08\n",
      "step3302 | loss: 0.0024495371617376804 | dt: 320.19ms | tok/sec:  51169.82\n",
      "step3303 | loss: 0.0020116004161536694 | dt: 321.10ms | tok/sec:  51024.49\n",
      "step3304 | loss: 0.001967068063095212 | dt: 320.09ms | tok/sec:  51185.71\n",
      "step3305 | loss: 0.002017499879002571 | dt: 320.00ms | tok/sec:  51200.66\n",
      "step3306 | loss: 0.0015088457148522139 | dt: 320.50ms | tok/sec:  51120.86\n",
      "step3307 | loss: 0.0025117015466094017 | dt: 321.10ms | tok/sec:  51025.10\n",
      "step3308 | loss: 0.001667394069954753 | dt: 319.89ms | tok/sec:  51217.95\n",
      "step3309 | loss: 0.002482612617313862 | dt: 320.46ms | tok/sec:  51125.73\n",
      "step3310 | loss: 0.0022212881594896317 | dt: 321.05ms | tok/sec:  51032.48\n",
      "step3311 | loss: 0.00170365150552243 | dt: 321.10ms | tok/sec:  51024.57\n",
      "step3312 | loss: 0.0026329546235501766 | dt: 320.89ms | tok/sec:  51057.93\n",
      "step3313 | loss: 0.0018481530714780092 | dt: 321.04ms | tok/sec:  51034.57\n",
      "step3314 | loss: 0.0013728062622249126 | dt: 320.99ms | tok/sec:  51042.72\n",
      "step3315 | loss: 0.0016956208273768425 | dt: 321.23ms | tok/sec:  51003.66\n",
      "step3316 | loss: 0.0015942377503961325 | dt: 320.17ms | tok/sec:  51173.13\n",
      "step3317 | loss: 0.0018898432608693838 | dt: 321.07ms | tok/sec:  51029.23\n",
      "step3318 | loss: 0.002734886482357979 | dt: 319.93ms | tok/sec:  51211.23\n",
      "step3319 | loss: 0.0017415352631360292 | dt: 321.16ms | tok/sec:  51014.79\n",
      "step3320 | loss: 0.0015160224866122007 | dt: 320.57ms | tok/sec:  51109.08\n",
      "step3321 | loss: 0.0017829008866101503 | dt: 320.39ms | tok/sec:  51137.49\n",
      "step3322 | loss: 0.002444353885948658 | dt: 321.19ms | tok/sec:  51009.95\n",
      "step3323 | loss: 0.0020280261524021626 | dt: 321.07ms | tok/sec:  51029.38\n",
      "step3324 | loss: 0.0019598049111664295 | dt: 320.57ms | tok/sec:  51108.70\n",
      "step3325 | loss: 0.0019884733483195305 | dt: 320.98ms | tok/sec:  51043.63\n",
      "step3326 | loss: 0.0014709194656461477 | dt: 319.96ms | tok/sec:  51206.84\n",
      "step3327 | loss: 0.0025208708830177784 | dt: 320.46ms | tok/sec:  51126.00\n",
      "step3328 | loss: 0.001665349118411541 | dt: 321.02ms | tok/sec:  51038.06\n",
      "step3329 | loss: 0.002463191282004118 | dt: 320.54ms | tok/sec:  51114.25\n",
      "step3330 | loss: 0.002207609126344323 | dt: 319.95ms | tok/sec:  51207.83\n",
      "step3331 | loss: 0.0016543380916118622 | dt: 320.72ms | tok/sec:  51085.03\n",
      "step3332 | loss: 0.002610973548144102 | dt: 320.13ms | tok/sec:  51179.04\n",
      "step3333 | loss: 0.0019000389147549868 | dt: 320.92ms | tok/sec:  51053.03\n",
      "step3334 | loss: 0.0013203669805079699 | dt: 319.89ms | tok/sec:  51218.40\n",
      "step3335 | loss: 0.0017357539618387818 | dt: 320.22ms | tok/sec:  51164.18\n",
      "step3336 | loss: 0.0014467324363067746 | dt: 320.17ms | tok/sec:  51172.25\n",
      "step3337 | loss: 0.0018793509807437658 | dt: 321.01ms | tok/sec:  51039.08\n",
      "step3338 | loss: 0.0027712739538401365 | dt: 320.33ms | tok/sec:  51146.47\n",
      "step3339 | loss: 0.001724747708067298 | dt: 321.00ms | tok/sec:  51040.41\n",
      "step3340 | loss: 0.0015038434648886323 | dt: 320.63ms | tok/sec:  51099.46\n",
      "step3341 | loss: 0.0017991027561947703 | dt: 321.49ms | tok/sec:  50962.02\n",
      "step3342 | loss: 0.0024114325642585754 | dt: 320.99ms | tok/sec:  51042.00\n",
      "step3343 | loss: 0.0019952156580984592 | dt: 321.01ms | tok/sec:  51038.93\n",
      "step3344 | loss: 0.0019378969445824623 | dt: 320.64ms | tok/sec:  51097.64\n",
      "step3345 | loss: 0.0019930265843868256 | dt: 321.18ms | tok/sec:  51011.80\n",
      "step3346 | loss: 0.0014632993843406439 | dt: 320.19ms | tok/sec:  51169.21\n",
      "step3347 | loss: 0.002482741605490446 | dt: 321.48ms | tok/sec:  50964.93\n",
      "step3348 | loss: 0.0016347052296623588 | dt: 321.28ms | tok/sec:  50996.36\n",
      "step3349 | loss: 0.0024594678543508053 | dt: 320.89ms | tok/sec:  51057.74\n",
      "step3350 | loss: 0.002196173183619976 | dt: 321.11ms | tok/sec:  51022.75\n",
      "step3351 | loss: 0.001666930504143238 | dt: 321.18ms | tok/sec:  51012.26\n",
      "step3352 | loss: 0.0026121046394109726 | dt: 319.92ms | tok/sec:  51213.02\n",
      "step3353 | loss: 0.0018191077979281545 | dt: 320.93ms | tok/sec:  51051.97\n",
      "step3354 | loss: 0.0013399170711636543 | dt: 321.22ms | tok/sec:  51005.44\n",
      "step3355 | loss: 0.00166794890537858 | dt: 320.53ms | tok/sec:  51114.89\n",
      "step3356 | loss: 0.00155888800509274 | dt: 319.95ms | tok/sec:  51207.83\n",
      "step3357 | loss: 0.0018750284798443317 | dt: 321.16ms | tok/sec:  51014.41\n",
      "step3358 | loss: 0.0027009998448193073 | dt: 319.55ms | tok/sec:  51271.41\n",
      "step3359 | loss: 0.0017156768590211868 | dt: 320.98ms | tok/sec:  51043.86\n",
      "step3360 | loss: 0.0014906410360708833 | dt: 320.46ms | tok/sec:  51126.68\n",
      "step3361 | loss: 0.0017576736863702536 | dt: 320.73ms | tok/sec:  51083.93\n",
      "step3362 | loss: 0.0024103184696286917 | dt: 320.54ms | tok/sec:  51113.34\n",
      "step3363 | loss: 0.0019995304755866528 | dt: 321.52ms | tok/sec:  50957.78\n",
      "step3364 | loss: 0.0019324489403516054 | dt: 319.98ms | tok/sec:  51203.52\n",
      "step3365 | loss: 0.001964536728337407 | dt: 321.03ms | tok/sec:  51036.28\n",
      "step3366 | loss: 0.0014419567305594683 | dt: 321.38ms | tok/sec:  50979.97\n",
      "step3367 | loss: 0.002492522355169058 | dt: 321.05ms | tok/sec:  51032.90\n",
      "step3368 | loss: 0.0016402954934164882 | dt: 321.24ms | tok/sec:  51002.37\n",
      "step3369 | loss: 0.0024262419901788235 | dt: 320.17ms | tok/sec:  51173.05\n",
      "step3370 | loss: 0.002181856194511056 | dt: 320.91ms | tok/sec:  51054.29\n",
      "step3371 | loss: 0.001627995283342898 | dt: 320.79ms | tok/sec:  51073.22\n",
      "step3372 | loss: 0.002573687117546797 | dt: 320.33ms | tok/sec:  51147.69\n",
      "step3373 | loss: 0.0018746242858469486 | dt: 321.14ms | tok/sec:  51017.71\n",
      "step3374 | loss: 0.0012914091348648071 | dt: 320.42ms | tok/sec:  51133.68\n",
      "step3375 | loss: 0.0017043594270944595 | dt: 320.29ms | tok/sec:  51154.12\n",
      "step3376 | loss: 0.001427013659849763 | dt: 320.53ms | tok/sec:  51115.43\n",
      "step3377 | loss: 0.0018379578832536936 | dt: 321.06ms | tok/sec:  51031.31\n",
      "step3378 | loss: 0.00274325767531991 | dt: 320.34ms | tok/sec:  51145.25\n",
      "step3379 | loss: 0.0016955105820670724 | dt: 320.35ms | tok/sec:  51143.73\n",
      "step3380 | loss: 0.0014627615455538034 | dt: 319.82ms | tok/sec:  51229.21\n",
      "step3381 | loss: 0.001766066299751401 | dt: 321.09ms | tok/sec:  51026.19\n",
      "step3382 | loss: 0.002388069871813059 | dt: 319.97ms | tok/sec:  51204.67\n",
      "step3383 | loss: 0.0019520542118698359 | dt: 320.84ms | tok/sec:  51066.16\n",
      "step3384 | loss: 0.0019055622396990657 | dt: 320.91ms | tok/sec:  51055.23\n",
      "step3385 | loss: 0.0019648042507469654 | dt: 321.18ms | tok/sec:  51012.52\n",
      "step3386 | loss: 0.0014356749597936869 | dt: 320.32ms | tok/sec:  51148.49\n",
      "step3387 | loss: 0.002455576788634062 | dt: 321.07ms | tok/sec:  51029.30\n",
      "step3388 | loss: 0.001595806796103716 | dt: 320.90ms | tok/sec:  51056.83\n",
      "step3389 | loss: 0.002425533952191472 | dt: 321.01ms | tok/sec:  51038.32\n",
      "step3390 | loss: 0.002170033985748887 | dt: 321.06ms | tok/sec:  51031.12\n",
      "step3391 | loss: 0.0016368089709430933 | dt: 321.22ms | tok/sec:  51005.48\n",
      "step3392 | loss: 0.0025772596709430218 | dt: 320.26ms | tok/sec:  51158.50\n",
      "step3393 | loss: 0.0017826117109507322 | dt: 321.08ms | tok/sec:  51027.37\n",
      "step3394 | loss: 0.001311803120188415 | dt: 320.32ms | tok/sec:  51148.15\n",
      "step3395 | loss: 0.0016334439860656857 | dt: 321.32ms | tok/sec:  50989.28\n",
      "step3396 | loss: 0.001529283239506185 | dt: 319.85ms | tok/sec:  51224.67\n",
      "step3397 | loss: 0.0018378347158432007 | dt: 320.56ms | tok/sec:  51110.90\n",
      "step3398 | loss: 0.0026877140626311302 | dt: 319.97ms | tok/sec:  51205.16\n",
      "step3399 | loss: 0.0016958466731011868 | dt: 321.19ms | tok/sec:  51010.74\n",
      "step3400 | loss: 0.0014541271375492215 | dt: 320.91ms | tok/sec:  51055.58\n",
      "step3401 | loss: 0.0017310883849859238 | dt: 321.27ms | tok/sec:  50998.21\n",
      "step3402 | loss: 0.002378408797085285 | dt: 320.95ms | tok/sec:  51048.26\n",
      "step3403 | loss: 0.001962347188964486 | dt: 320.74ms | tok/sec:  51082.10\n",
      "step3404 | loss: 0.0018911792431026697 | dt: 319.98ms | tok/sec:  51203.71\n",
      "step3405 | loss: 0.0019251611083745956 | dt: 320.75ms | tok/sec:  51079.64\n",
      "step3406 | loss: 0.001411721110343933 | dt: 320.78ms | tok/sec:  51076.29\n",
      "step3407 | loss: 0.0024568778462707996 | dt: 320.91ms | tok/sec:  51054.55\n",
      "step3408 | loss: 0.0016047111712396145 | dt: 319.76ms | tok/sec:  51237.92\n",
      "step3409 | loss: 0.0024082656018435955 | dt: 320.51ms | tok/sec:  51117.78\n",
      "step3410 | loss: 0.0021605731453746557 | dt: 320.33ms | tok/sec:  51147.42\n",
      "step3411 | loss: 0.001595580717548728 | dt: 321.05ms | tok/sec:  51033.09\n",
      "step3412 | loss: 0.002552518155425787 | dt: 320.58ms | tok/sec:  51107.44\n",
      "step3413 | loss: 0.0018440107814967632 | dt: 321.28ms | tok/sec:  50995.83\n",
      "step3414 | loss: 0.0012535342248156667 | dt: 319.92ms | tok/sec:  51213.06\n",
      "step3415 | loss: 0.00168366520665586 | dt: 320.68ms | tok/sec:  51090.88\n",
      "step3416 | loss: 0.0014043133705854416 | dt: 320.92ms | tok/sec:  51052.62\n",
      "step3417 | loss: 0.0018231782596558332 | dt: 321.01ms | tok/sec:  51038.44\n",
      "step3418 | loss: 0.0027166889049112797 | dt: 319.80ms | tok/sec:  51232.69\n",
      "step3419 | loss: 0.0016724776942282915 | dt: 321.39ms | tok/sec:  50977.89\n",
      "step3420 | loss: 0.0014339315239340067 | dt: 319.74ms | tok/sec:  51241.55\n",
      "step3421 | loss: 0.0017437459900975227 | dt: 320.06ms | tok/sec:  51190.70\n",
      "step3422 | loss: 0.0023526977747678757 | dt: 321.21ms | tok/sec:  51007.22\n",
      "step3423 | loss: 0.0019202162511646748 | dt: 320.82ms | tok/sec:  51069.04\n",
      "step3424 | loss: 0.0018774461932480335 | dt: 320.39ms | tok/sec:  51137.75\n",
      "step3425 | loss: 0.0019344633910804987 | dt: 320.21ms | tok/sec:  51166.08\n",
      "step3426 | loss: 0.001417052000761032 | dt: 320.42ms | tok/sec:  51133.26\n",
      "step3427 | loss: 0.002431714441627264 | dt: 321.08ms | tok/sec:  51027.41\n",
      "step3428 | loss: 0.001574355410411954 | dt: 320.54ms | tok/sec:  51113.07\n",
      "step3429 | loss: 0.002399909310042858 | dt: 320.85ms | tok/sec:  51064.38\n",
      "step3430 | loss: 0.0021393881179392338 | dt: 319.97ms | tok/sec:  51205.35\n",
      "step3431 | loss: 0.0016079663764685392 | dt: 319.92ms | tok/sec:  51212.49\n",
      "step3432 | loss: 0.0025539707858115435 | dt: 320.33ms | tok/sec:  51147.57\n",
      "step3433 | loss: 0.0017604578752070665 | dt: 321.05ms | tok/sec:  51033.02\n",
      "step3434 | loss: 0.0012853413354605436 | dt: 320.27ms | tok/sec:  51157.32\n",
      "step3435 | loss: 0.001605995581485331 | dt: 321.23ms | tok/sec:  51003.21\n",
      "step3436 | loss: 0.0015070801600813866 | dt: 320.52ms | tok/sec:  51116.49\n",
      "step3437 | loss: 0.001813932554796338 | dt: 320.54ms | tok/sec:  51113.45\n",
      "step3438 | loss: 0.002657356671988964 | dt: 319.91ms | tok/sec:  51215.12\n",
      "step3439 | loss: 0.0016694028163328767 | dt: 321.17ms | tok/sec:  51012.82\n",
      "step3440 | loss: 0.0014252301771193743 | dt: 319.53ms | tok/sec:  51274.93\n",
      "step3441 | loss: 0.001698305830359459 | dt: 320.97ms | tok/sec:  51045.53\n",
      "step3442 | loss: 0.0023597492836415768 | dt: 321.26ms | tok/sec:  50998.66\n",
      "step3443 | loss: 0.0019381814636290073 | dt: 320.63ms | tok/sec:  51099.77\n",
      "step3444 | loss: 0.0018767034634947777 | dt: 321.18ms | tok/sec:  51011.95\n",
      "step3445 | loss: 0.0019005556823685765 | dt: 321.34ms | tok/sec:  50985.99\n",
      "step3446 | loss: 0.0013883317587897182 | dt: 320.13ms | tok/sec:  51179.99\n",
      "step3447 | loss: 0.0024357507936656475 | dt: 321.46ms | tok/sec:  50967.31\n",
      "step3448 | loss: 0.00157146283891052 | dt: 320.36ms | tok/sec:  51142.05\n",
      "step3449 | loss: 0.00238808523863554 | dt: 320.91ms | tok/sec:  51054.25\n",
      "step3450 | loss: 0.0021322215907275677 | dt: 320.20ms | tok/sec:  51168.60\n",
      "step3451 | loss: 0.001572520937770605 | dt: 321.25ms | tok/sec:  51000.44\n",
      "step3452 | loss: 0.002519757952541113 | dt: 320.02ms | tok/sec:  51196.23\n",
      "step3453 | loss: 0.0018044004682451487 | dt: 321.17ms | tok/sec:  51013.16\n",
      "step3454 | loss: 0.0012264292454347014 | dt: 320.59ms | tok/sec:  51105.47\n",
      "step3455 | loss: 0.0016496379394084215 | dt: 320.53ms | tok/sec:  51114.63\n",
      "step3456 | loss: 0.0013811063254252076 | dt: 320.55ms | tok/sec:  51111.55\n",
      "step3457 | loss: 0.0017997215036302805 | dt: 321.00ms | tok/sec:  51039.84\n",
      "step3458 | loss: 0.0026946421712636948 | dt: 320.03ms | tok/sec:  51195.85\n",
      "step3459 | loss: 0.001645243726670742 | dt: 320.85ms | tok/sec:  51064.04\n",
      "step3460 | loss: 0.00141356501262635 | dt: 320.09ms | tok/sec:  51185.44\n",
      "step3461 | loss: 0.001717470004223287 | dt: 320.90ms | tok/sec:  51056.75\n",
      "step3462 | loss: 0.00233271112665534 | dt: 320.11ms | tok/sec:  51183.19\n",
      "step3463 | loss: 0.0019107938278466463 | dt: 321.31ms | tok/sec:  50990.76\n",
      "step3464 | loss: 0.0018520045559853315 | dt: 319.96ms | tok/sec:  51206.92\n",
      "step3465 | loss: 0.0018945581978186965 | dt: 319.71ms | tok/sec:  51246.55\n",
      "step3466 | loss: 0.00138198328204453 | dt: 320.89ms | tok/sec:  51057.97\n",
      "step3467 | loss: 0.00240305089391768 | dt: 321.01ms | tok/sec:  51038.17\n",
      "step3468 | loss: 0.0015495188999921083 | dt: 319.75ms | tok/sec:  51239.49\n",
      "step3469 | loss: 0.0023749112151563168 | dt: 321.27ms | tok/sec:  50997.04\n",
      "step3470 | loss: 0.002105425111949444 | dt: 321.20ms | tok/sec:  51008.09\n",
      "step3471 | loss: 0.0015699072973802686 | dt: 319.89ms | tok/sec:  51218.33\n",
      "step3472 | loss: 0.002526977565139532 | dt: 320.36ms | tok/sec:  51141.75\n",
      "step3473 | loss: 0.0017332287970930338 | dt: 321.46ms | tok/sec:  50967.72\n",
      "step3474 | loss: 0.0012613735161721706 | dt: 319.90ms | tok/sec:  51215.27\n",
      "step3475 | loss: 0.001581856282427907 | dt: 321.42ms | tok/sec:  50974.23\n",
      "step3476 | loss: 0.0014717027079313993 | dt: 320.78ms | tok/sec:  51075.50\n",
      "step3477 | loss: 0.0017864737892523408 | dt: 320.16ms | tok/sec:  51174.16\n",
      "step3478 | loss: 0.0026266383938491344 | dt: 319.85ms | tok/sec:  51224.21\n",
      "step3479 | loss: 0.0016347041819244623 | dt: 321.18ms | tok/sec:  51011.65\n",
      "step3480 | loss: 0.0014007675927132368 | dt: 319.94ms | tok/sec:  51209.24\n",
      "step3481 | loss: 0.001679969485849142 | dt: 320.95ms | tok/sec:  51049.13\n",
      "step3482 | loss: 0.002321619773283601 | dt: 319.88ms | tok/sec:  51218.44\n",
      "step3483 | loss: 0.0019102117512375116 | dt: 320.53ms | tok/sec:  51115.39\n",
      "step3484 | loss: 0.0018551647663116455 | dt: 319.86ms | tok/sec:  51222.64\n",
      "step3485 | loss: 0.0018759372178465128 | dt: 320.96ms | tok/sec:  51047.57\n",
      "step3486 | loss: 0.0013576579513028264 | dt: 320.18ms | tok/sec:  51171.53\n",
      "step3487 | loss: 0.0024118698202073574 | dt: 320.61ms | tok/sec:  51103.07\n",
      "step3488 | loss: 0.0015521347522735596 | dt: 319.97ms | tok/sec:  51205.16\n",
      "step3489 | loss: 0.002366045955568552 | dt: 320.80ms | tok/sec:  51071.63\n",
      "step3490 | loss: 0.0021057170815765858 | dt: 320.16ms | tok/sec:  51174.43\n",
      "step3491 | loss: 0.0015467724297195673 | dt: 321.47ms | tok/sec:  50965.57\n",
      "step3492 | loss: 0.0024939673021435738 | dt: 319.76ms | tok/sec:  51239.10\n",
      "step3493 | loss: 0.0017832231242209673 | dt: 320.58ms | tok/sec:  51107.44\n",
      "step3494 | loss: 0.0011973811779171228 | dt: 320.21ms | tok/sec:  51166.08\n",
      "step3495 | loss: 0.0016174495685845613 | dt: 320.07ms | tok/sec:  51189.03\n",
      "step3496 | loss: 0.0013515889877453446 | dt: 320.81ms | tok/sec:  51071.32\n",
      "step3497 | loss: 0.001763724721968174 | dt: 320.90ms | tok/sec:  51055.99\n",
      "step3498 | loss: 0.0026569440960884094 | dt: 320.27ms | tok/sec:  51157.44\n",
      "step3499 | loss: 0.0016311313956975937 | dt: 320.94ms | tok/sec:  51050.34\n",
      "Prediction at step 3500: \n",
      " : This is a fixed text used for prediction. fortune behold your lords;\n",
      "Stand to fruitful law \n",
      "\n",
      "step3500 | loss: 0.0013753564562648535 | dt: 318.49ms | tok/sec:  51442.82\n",
      "step3501 | loss: 0.0016868250677362084 | dt: 319.92ms | tok/sec:  51212.79\n",
      "step3502 | loss: 0.0023083887062966824 | dt: 320.87ms | tok/sec:  51060.85\n",
      "step3503 | loss: 0.0018844263395294547 | dt: 321.40ms | tok/sec:  50977.40\n",
      "step3504 | loss: 0.0018236231990158558 | dt: 319.48ms | tok/sec:  51283.61\n",
      "step3505 | loss: 0.0018819684628397226 | dt: 320.74ms | tok/sec:  51081.91\n",
      "step3506 | loss: 0.0013505516108125448 | dt: 321.82ms | tok/sec:  50910.14\n",
      "step3507 | loss: 0.002378034871071577 | dt: 319.85ms | tok/sec:  51224.67\n",
      "step3508 | loss: 0.0015230280114337802 | dt: 319.84ms | tok/sec:  51226.23\n",
      "step3509 | loss: 0.002348748268559575 | dt: 321.18ms | tok/sec:  51011.61\n",
      "step3510 | loss: 0.0020896820351481438 | dt: 320.28ms | tok/sec:  51155.84\n",
      "step3511 | loss: 0.0015496634878218174 | dt: 320.61ms | tok/sec:  51103.07\n",
      "step3512 | loss: 0.0025052991695702076 | dt: 320.10ms | tok/sec:  51183.73\n",
      "step3513 | loss: 0.0017088078893721104 | dt: 321.16ms | tok/sec:  51015.32\n",
      "step3514 | loss: 0.0012262423988431692 | dt: 319.91ms | tok/sec:  51214.93\n",
      "step3515 | loss: 0.001559162512421608 | dt: 321.34ms | tok/sec:  50985.95\n",
      "step3516 | loss: 0.0014466792345046997 | dt: 321.16ms | tok/sec:  51015.21\n",
      "step3517 | loss: 0.0017646842170506716 | dt: 319.94ms | tok/sec:  51209.59\n",
      "step3518 | loss: 0.0026038805954158306 | dt: 320.54ms | tok/sec:  51114.02\n",
      "step3519 | loss: 0.0016157767968252301 | dt: 321.43ms | tok/sec:  50971.77\n",
      "step3520 | loss: 0.0013720362912863493 | dt: 319.64ms | tok/sec:  51257.91\n",
      "step3521 | loss: 0.0016527909319847822 | dt: 320.81ms | tok/sec:  51070.60\n",
      "step3522 | loss: 0.002303831744939089 | dt: 320.39ms | tok/sec:  51137.41\n",
      "step3523 | loss: 0.0018991401884704828 | dt: 320.07ms | tok/sec:  51188.15\n",
      "step3524 | loss: 0.0018230276182293892 | dt: 320.91ms | tok/sec:  51054.66\n",
      "step3525 | loss: 0.0018518194556236267 | dt: 321.59ms | tok/sec:  50946.11\n",
      "step3526 | loss: 0.0013333579991012812 | dt: 320.91ms | tok/sec:  51054.10\n",
      "step3527 | loss: 0.002374317729845643 | dt: 320.01ms | tok/sec:  51198.98\n",
      "step3528 | loss: 0.0015338339144364 | dt: 321.25ms | tok/sec:  51000.97\n",
      "step3529 | loss: 0.002330005168914795 | dt: 321.08ms | tok/sec:  51027.71\n",
      "step3530 | loss: 0.002078088466078043 | dt: 319.91ms | tok/sec:  51215.20\n",
      "step3531 | loss: 0.001523162703961134 | dt: 321.14ms | tok/sec:  51017.78\n",
      "step3532 | loss: 0.002474887063726783 | dt: 319.93ms | tok/sec:  51211.65\n",
      "step3533 | loss: 0.0017566226888448 | dt: 321.21ms | tok/sec:  51007.07\n",
      "step3534 | loss: 0.001174948993138969 | dt: 320.71ms | tok/sec:  51086.77\n",
      "step3535 | loss: 0.0015916986158117652 | dt: 321.09ms | tok/sec:  51026.31\n",
      "step3536 | loss: 0.0013321778969839215 | dt: 320.12ms | tok/sec:  51180.98\n",
      "step3537 | loss: 0.0017511744517832994 | dt: 320.08ms | tok/sec:  51187.27\n",
      "step3538 | loss: 0.002636728808283806 | dt: 320.36ms | tok/sec:  51141.79\n",
      "step3539 | loss: 0.001599400769919157 | dt: 321.00ms | tok/sec:  51040.48\n",
      "step3540 | loss: 0.0013446795055642724 | dt: 319.98ms | tok/sec:  51202.49\n",
      "step3541 | loss: 0.0016696143429726362 | dt: 321.35ms | tok/sec:  50985.42\n",
      "step3542 | loss: 0.002280316548421979 | dt: 321.14ms | tok/sec:  51018.69\n",
      "step3543 | loss: 0.0018513837130740285 | dt: 320.77ms | tok/sec:  51076.86\n",
      "step3544 | loss: 0.0018068708013743162 | dt: 320.12ms | tok/sec:  51180.41\n",
      "step3545 | loss: 0.0018540853634476662 | dt: 320.83ms | tok/sec:  51066.92\n",
      "step3546 | loss: 0.0013246359303593636 | dt: 320.09ms | tok/sec:  51185.25\n",
      "step3547 | loss: 0.0023545371368527412 | dt: 320.71ms | tok/sec:  51087.15\n",
      "step3548 | loss: 0.0014910793397575617 | dt: 319.92ms | tok/sec:  51212.45\n",
      "step3549 | loss: 0.002331930212676525 | dt: 320.53ms | tok/sec:  51115.92\n",
      "step3550 | loss: 0.0020730039104819298 | dt: 319.72ms | tok/sec:  51244.30\n",
      "step3551 | loss: 0.0015298033831641078 | dt: 321.15ms | tok/sec:  51015.93\n",
      "step3552 | loss: 0.002479280810803175 | dt: 320.10ms | tok/sec:  51183.54\n",
      "step3553 | loss: 0.001678993459790945 | dt: 320.96ms | tok/sec:  51046.55\n",
      "step3554 | loss: 0.0011937101371586323 | dt: 321.14ms | tok/sec:  51018.16\n",
      "step3555 | loss: 0.0015391124179586768 | dt: 320.74ms | tok/sec:  51082.07\n",
      "step3556 | loss: 0.0014190278016030788 | dt: 320.14ms | tok/sec:  51177.21\n",
      "step3557 | loss: 0.0017457897774875164 | dt: 320.93ms | tok/sec:  51051.21\n",
      "step3558 | loss: 0.0025855149142444134 | dt: 320.13ms | tok/sec:  51178.50\n",
      "step3559 | loss: 0.0015995309222489595 | dt: 320.85ms | tok/sec:  51064.91\n",
      "step3560 | loss: 0.0013512122677639127 | dt: 320.59ms | tok/sec:  51105.73\n",
      "step3561 | loss: 0.0016368518117815256 | dt: 320.90ms | tok/sec:  51056.56\n",
      "step3562 | loss: 0.002276406157761812 | dt: 320.53ms | tok/sec:  51115.16\n",
      "step3563 | loss: 0.0018750142771750689 | dt: 320.85ms | tok/sec:  51064.38\n",
      "step3564 | loss: 0.0017916233045980334 | dt: 319.74ms | tok/sec:  51242.04\n",
      "step3565 | loss: 0.0018206187523901463 | dt: 321.07ms | tok/sec:  51028.81\n",
      "step3566 | loss: 0.0013054246082901955 | dt: 320.91ms | tok/sec:  51055.04\n",
      "step3567 | loss: 0.002352568320930004 | dt: 321.23ms | tok/sec:  51003.51\n",
      "step3568 | loss: 0.001502835308201611 | dt: 320.96ms | tok/sec:  51046.93\n",
      "step3569 | loss: 0.002307659713551402 | dt: 321.40ms | tok/sec:  50977.06\n",
      "step3570 | loss: 0.002054505981504917 | dt: 320.07ms | tok/sec:  51188.72\n",
      "step3571 | loss: 0.0014998691622167826 | dt: 321.37ms | tok/sec:  50981.34\n",
      "step3572 | loss: 0.002455141395330429 | dt: 321.09ms | tok/sec:  51026.84\n",
      "step3573 | loss: 0.0017306800000369549 | dt: 320.12ms | tok/sec:  51180.98\n",
      "step3574 | loss: 0.0011548810871317983 | dt: 321.02ms | tok/sec:  51036.84\n",
      "step3575 | loss: 0.0015697043854743242 | dt: 321.04ms | tok/sec:  51034.49\n",
      "step3576 | loss: 0.0013137925416231155 | dt: 319.75ms | tok/sec:  51239.75\n",
      "step3577 | loss: 0.0017184079624712467 | dt: 320.15ms | tok/sec:  51176.52\n",
      "step3578 | loss: 0.002608583075925708 | dt: 320.53ms | tok/sec:  51116.00\n",
      "step3579 | loss: 0.0015790160978212953 | dt: 321.00ms | tok/sec:  51040.63\n",
      "step3580 | loss: 0.0013261756394058466 | dt: 320.11ms | tok/sec:  51182.20\n",
      "step3581 | loss: 0.001649559591896832 | dt: 321.07ms | tok/sec:  51029.45\n",
      "step3582 | loss: 0.002253280719742179 | dt: 320.47ms | tok/sec:  51125.28\n",
      "step3583 | loss: 0.0018314695917069912 | dt: 321.22ms | tok/sec:  51005.59\n",
      "step3584 | loss: 0.0017968519823625684 | dt: 320.37ms | tok/sec:  51141.26\n",
      "step3585 | loss: 0.0018287970451638103 | dt: 321.12ms | tok/sec:  51021.95\n",
      "step3586 | loss: 0.0013083037920296192 | dt: 320.43ms | tok/sec:  51131.44\n",
      "step3587 | loss: 0.0023301863111555576 | dt: 320.80ms | tok/sec:  51071.78\n",
      "step3588 | loss: 0.0014723316999152303 | dt: 320.77ms | tok/sec:  51077.09\n",
      "step3589 | loss: 0.0023089698515832424 | dt: 320.86ms | tok/sec:  51062.52\n",
      "step3590 | loss: 0.0020485226996243 | dt: 321.16ms | tok/sec:  51015.74\n",
      "step3591 | loss: 0.0015050455695018172 | dt: 320.20ms | tok/sec:  51167.76\n",
      "step3592 | loss: 0.002455045934766531 | dt: 320.13ms | tok/sec:  51179.84\n",
      "step3593 | loss: 0.0016602542018517852 | dt: 320.81ms | tok/sec:  51071.21\n",
      "step3594 | loss: 0.0011705632787197828 | dt: 320.14ms | tok/sec:  51177.02\n",
      "step3595 | loss: 0.00150787690654397 | dt: 320.91ms | tok/sec:  51054.51\n",
      "step3596 | loss: 0.001399297034367919 | dt: 321.16ms | tok/sec:  51014.64\n",
      "step3597 | loss: 0.0017220941372215748 | dt: 320.67ms | tok/sec:  51092.74\n",
      "step3598 | loss: 0.002558870241045952 | dt: 320.10ms | tok/sec:  51184.41\n",
      "step3599 | loss: 0.0015786841977387667 | dt: 321.26ms | tok/sec:  50999.69\n",
      "step3600 | loss: 0.0013243190478533506 | dt: 321.04ms | tok/sec:  51034.23\n",
      "step3601 | loss: 0.0016173378098756075 | dt: 321.09ms | tok/sec:  51026.50\n",
      "step3602 | loss: 0.0022528518456965685 | dt: 320.35ms | tok/sec:  51143.62\n",
      "step3603 | loss: 0.0018539343727752566 | dt: 321.23ms | tok/sec:  51003.62\n",
      "step3604 | loss: 0.001772725023329258 | dt: 321.06ms | tok/sec:  51031.01\n",
      "step3605 | loss: 0.0018023406155407429 | dt: 320.99ms | tok/sec:  51042.23\n",
      "step3606 | loss: 0.001281662262044847 | dt: 320.25ms | tok/sec:  51160.79\n",
      "step3607 | loss: 0.0023339278995990753 | dt: 320.68ms | tok/sec:  51091.07\n",
      "step3608 | loss: 0.001481235260143876 | dt: 320.17ms | tok/sec:  51172.18\n",
      "step3609 | loss: 0.002290064003318548 | dt: 320.18ms | tok/sec:  51170.50\n",
      "step3610 | loss: 0.0020350595004856586 | dt: 319.73ms | tok/sec:  51243.54\n",
      "step3611 | loss: 0.0014862371608614922 | dt: 320.94ms | tok/sec:  51050.80\n",
      "step3612 | loss: 0.0024318413343280554 | dt: 321.33ms | tok/sec:  50988.52\n",
      "step3613 | loss: 0.0017033341573551297 | dt: 319.98ms | tok/sec:  51202.41\n",
      "step3614 | loss: 0.0011205000337213278 | dt: 321.02ms | tok/sec:  51037.18\n",
      "step3615 | loss: 0.001547087449580431 | dt: 320.89ms | tok/sec:  51058.38\n",
      "step3616 | loss: 0.0012921578017994761 | dt: 321.03ms | tok/sec:  51035.67\n",
      "step3617 | loss: 0.0017058637458831072 | dt: 321.03ms | tok/sec:  51036.43\n",
      "step3618 | loss: 0.002588665345683694 | dt: 321.18ms | tok/sec:  51012.52\n",
      "step3619 | loss: 0.0015619163168594241 | dt: 320.10ms | tok/sec:  51183.35\n",
      "step3620 | loss: 0.001313906628638506 | dt: 320.25ms | tok/sec:  51159.80\n",
      "step3621 | loss: 0.0016139824874699116 | dt: 320.37ms | tok/sec:  51140.08\n",
      "step3622 | loss: 0.0022321785800158978 | dt: 319.95ms | tok/sec:  51208.63\n",
      "step3623 | loss: 0.0018108388176187873 | dt: 320.88ms | tok/sec:  51059.22\n",
      "step3624 | loss: 0.0017737504094839096 | dt: 321.13ms | tok/sec:  51019.07\n",
      "step3625 | loss: 0.001807006890885532 | dt: 321.17ms | tok/sec:  51014.22\n",
      "step3626 | loss: 0.001290524727664888 | dt: 319.76ms | tok/sec:  51238.07\n",
      "step3627 | loss: 0.002312697470188141 | dt: 321.20ms | tok/sec:  51008.66\n",
      "step3628 | loss: 0.0014552471693605185 | dt: 319.94ms | tok/sec:  51209.51\n",
      "step3629 | loss: 0.002285477938130498 | dt: 320.86ms | tok/sec:  51062.67\n",
      "step3630 | loss: 0.002019175561144948 | dt: 320.92ms | tok/sec:  51053.60\n",
      "step3631 | loss: 0.0014754715375602245 | dt: 320.97ms | tok/sec:  51045.41\n",
      "step3632 | loss: 0.002423894591629505 | dt: 320.28ms | tok/sec:  51155.04\n",
      "step3633 | loss: 0.0016408257652074099 | dt: 321.01ms | tok/sec:  51039.27\n",
      "step3634 | loss: 0.0011598676210269332 | dt: 320.12ms | tok/sec:  51180.87\n",
      "step3635 | loss: 0.0014894980704411864 | dt: 320.99ms | tok/sec:  51042.23\n",
      "step3636 | loss: 0.0013778519351035357 | dt: 320.48ms | tok/sec:  51123.79\n",
      "step3637 | loss: 0.0016998937353491783 | dt: 321.17ms | tok/sec:  51013.73\n",
      "step3638 | loss: 0.002541234251111746 | dt: 320.89ms | tok/sec:  51057.51\n",
      "step3639 | loss: 0.001550913555547595 | dt: 321.13ms | tok/sec:  51020.32\n",
      "step3640 | loss: 0.0012997937155887485 | dt: 319.91ms | tok/sec:  51213.63\n",
      "step3641 | loss: 0.0015961492899805307 | dt: 321.22ms | tok/sec:  51005.36\n",
      "step3642 | loss: 0.0022394689731299877 | dt: 319.85ms | tok/sec:  51223.44\n",
      "step3643 | loss: 0.001825715065933764 | dt: 320.65ms | tok/sec:  51096.92\n",
      "step3644 | loss: 0.0017617556732147932 | dt: 320.16ms | tok/sec:  51174.43\n",
      "step3645 | loss: 0.001786101027391851 | dt: 321.01ms | tok/sec:  51039.42\n",
      "step3646 | loss: 0.0012588941026479006 | dt: 320.00ms | tok/sec:  51200.20\n",
      "step3647 | loss: 0.002321008127182722 | dt: 321.47ms | tok/sec:  50965.46\n",
      "step3648 | loss: 0.001458428567275405 | dt: 320.28ms | tok/sec:  51155.49\n",
      "step3649 | loss: 0.002276170998811722 | dt: 321.00ms | tok/sec:  51040.18\n",
      "step3650 | loss: 0.0020031530875712633 | dt: 320.47ms | tok/sec:  51124.36\n",
      "step3651 | loss: 0.0014664622722193599 | dt: 321.22ms | tok/sec:  51005.59\n",
      "step3652 | loss: 0.002407890046015382 | dt: 320.99ms | tok/sec:  51041.89\n",
      "step3653 | loss: 0.0016852857079356909 | dt: 321.03ms | tok/sec:  51035.93\n",
      "step3654 | loss: 0.001090362435206771 | dt: 319.99ms | tok/sec:  51201.00\n",
      "step3655 | loss: 0.001517721451818943 | dt: 320.96ms | tok/sec:  51046.78\n",
      "step3656 | loss: 0.0012661941582337022 | dt: 320.15ms | tok/sec:  51176.18\n",
      "step3657 | loss: 0.0016891397535800934 | dt: 320.84ms | tok/sec:  51066.08\n",
      "step3658 | loss: 0.002571790013462305 | dt: 319.95ms | tok/sec:  51207.60\n",
      "step3659 | loss: 0.0015432487707585096 | dt: 320.13ms | tok/sec:  51179.42\n",
      "step3660 | loss: 0.0012859780108556151 | dt: 319.73ms | tok/sec:  51243.31\n",
      "step3661 | loss: 0.0015956638380885124 | dt: 321.52ms | tok/sec:  50958.09\n",
      "step3662 | loss: 0.002210413571447134 | dt: 320.15ms | tok/sec:  51175.61\n",
      "step3663 | loss: 0.0018044536700472236 | dt: 320.60ms | tok/sec:  51103.41\n",
      "step3664 | loss: 0.0017402386292815208 | dt: 320.10ms | tok/sec:  51184.03\n",
      "step3665 | loss: 0.0017990469932556152 | dt: 320.83ms | tok/sec:  51068.21\n",
      "step3666 | loss: 0.001256131799891591 | dt: 319.77ms | tok/sec:  51236.85\n",
      "step3667 | loss: 0.0022840644232928753 | dt: 320.99ms | tok/sec:  51042.49\n",
      "step3668 | loss: 0.0014272719854488969 | dt: 319.94ms | tok/sec:  51209.24\n",
      "step3669 | loss: 0.002266131341457367 | dt: 321.12ms | tok/sec:  51021.27\n",
      "step3670 | loss: 0.0020002503879368305 | dt: 320.85ms | tok/sec:  51064.53\n",
      "step3671 | loss: 0.0014567539328709245 | dt: 321.34ms | tok/sec:  50986.14\n",
      "step3672 | loss: 0.0024173175916075706 | dt: 320.20ms | tok/sec:  51168.10\n",
      "step3673 | loss: 0.0016165066044777632 | dt: 320.23ms | tok/sec:  51163.87\n",
      "step3674 | loss: 0.0011413752799853683 | dt: 321.36ms | tok/sec:  50983.27\n",
      "step3675 | loss: 0.0014773112488910556 | dt: 321.28ms | tok/sec:  50995.33\n",
      "step3676 | loss: 0.0013535190373659134 | dt: 319.67ms | tok/sec:  51252.36\n",
      "step3677 | loss: 0.001674492727033794 | dt: 320.29ms | tok/sec:  51153.59\n",
      "step3678 | loss: 0.002522234106436372 | dt: 320.30ms | tok/sec:  51152.03\n",
      "step3679 | loss: 0.0015385979786515236 | dt: 321.08ms | tok/sec:  51027.10\n",
      "step3680 | loss: 0.0012734138872474432 | dt: 320.63ms | tok/sec:  51099.27\n",
      "step3681 | loss: 0.0015761572867631912 | dt: 320.83ms | tok/sec:  51067.22\n",
      "step3682 | loss: 0.0022179484367370605 | dt: 320.12ms | tok/sec:  51181.21\n",
      "step3683 | loss: 0.0018128639785572886 | dt: 320.79ms | tok/sec:  51074.40\n",
      "step3684 | loss: 0.0017404698301106691 | dt: 320.04ms | tok/sec:  51193.68\n",
      "step3685 | loss: 0.0017607894260436296 | dt: 321.25ms | tok/sec:  51001.09\n",
      "step3686 | loss: 0.0012408667244017124 | dt: 320.94ms | tok/sec:  51049.43\n",
      "step3687 | loss: 0.002290012314915657 | dt: 321.12ms | tok/sec:  51021.46\n",
      "step3688 | loss: 0.0014375534374266863 | dt: 320.68ms | tok/sec:  51091.18\n",
      "step3689 | loss: 0.0022513887379318476 | dt: 321.17ms | tok/sec:  51013.32\n",
      "step3690 | loss: 0.002000143751502037 | dt: 320.31ms | tok/sec:  51150.70\n",
      "step3691 | loss: 0.0014496471267193556 | dt: 321.39ms | tok/sec:  50978.95\n",
      "step3692 | loss: 0.002390511566773057 | dt: 320.72ms | tok/sec:  51085.14\n",
      "step3693 | loss: 0.0016623262781649828 | dt: 321.21ms | tok/sec:  51006.42\n",
      "step3694 | loss: 0.0010712426155805588 | dt: 321.31ms | tok/sec:  50990.98\n",
      "step3695 | loss: 0.0014861752279102802 | dt: 321.52ms | tok/sec:  50957.44\n",
      "step3696 | loss: 0.0012539173476397991 | dt: 320.80ms | tok/sec:  51072.31\n",
      "step3697 | loss: 0.001663053990341723 | dt: 321.15ms | tok/sec:  51016.65\n",
      "step3698 | loss: 0.0025481493212282658 | dt: 320.90ms | tok/sec:  51056.94\n",
      "step3699 | loss: 0.0015250742435455322 | dt: 321.09ms | tok/sec:  51026.57\n",
      "step3700 | loss: 0.001257273368537426 | dt: 319.96ms | tok/sec:  51207.18\n",
      "step3701 | loss: 0.0015839707339182496 | dt: 321.17ms | tok/sec:  51012.94\n",
      "step3702 | loss: 0.0021921717561781406 | dt: 320.62ms | tok/sec:  51100.64\n",
      "step3703 | loss: 0.0017698481678962708 | dt: 320.73ms | tok/sec:  51083.85\n",
      "step3704 | loss: 0.0017267349176108837 | dt: 320.24ms | tok/sec:  51161.13\n",
      "step3705 | loss: 0.0017721671611070633 | dt: 321.02ms | tok/sec:  51037.79\n",
      "step3706 | loss: 0.0012359307147562504 | dt: 320.45ms | tok/sec:  51128.17\n",
      "step3707 | loss: 0.002269725315272808 | dt: 320.69ms | tok/sec:  51090.04\n",
      "step3708 | loss: 0.0014072086196392775 | dt: 320.76ms | tok/sec:  51078.50\n",
      "step3709 | loss: 0.0022430061362683773 | dt: 321.29ms | tok/sec:  50993.78\n",
      "step3710 | loss: 0.001986999996006489 | dt: 320.64ms | tok/sec:  51097.90\n",
      "step3711 | loss: 0.0014422156382352114 | dt: 320.68ms | tok/sec:  51090.76\n",
      "step3712 | loss: 0.0023895613849163055 | dt: 321.12ms | tok/sec:  51020.97\n",
      "step3713 | loss: 0.0016018885653465986 | dt: 320.47ms | tok/sec:  51124.48\n",
      "step3714 | loss: 0.0011174874380230904 | dt: 319.90ms | tok/sec:  51215.24\n",
      "step3715 | loss: 0.0014561464777216315 | dt: 320.36ms | tok/sec:  51142.21\n",
      "step3716 | loss: 0.0013303315499797463 | dt: 319.98ms | tok/sec:  51202.60\n",
      "step3717 | loss: 0.0016577445203438401 | dt: 321.25ms | tok/sec:  51000.71\n",
      "step3718 | loss: 0.002506465883925557 | dt: 319.90ms | tok/sec:  51216.57\n",
      "step3719 | loss: 0.0015267041744664311 | dt: 321.13ms | tok/sec:  51020.51\n",
      "step3720 | loss: 0.0012656236067414284 | dt: 320.80ms | tok/sec:  51072.73\n",
      "step3721 | loss: 0.0015589580871164799 | dt: 320.14ms | tok/sec:  51177.89\n",
      "step3722 | loss: 0.002191869542002678 | dt: 320.11ms | tok/sec:  51182.43\n",
      "step3723 | loss: 0.001795340795069933 | dt: 321.30ms | tok/sec:  50992.38\n",
      "step3724 | loss: 0.0017167814075946808 | dt: 320.76ms | tok/sec:  51079.26\n",
      "step3725 | loss: 0.0017310422845184803 | dt: 319.92ms | tok/sec:  51212.26\n",
      "step3726 | loss: 0.001222853665240109 | dt: 320.73ms | tok/sec:  51083.81\n",
      "step3727 | loss: 0.0022750860080122948 | dt: 320.18ms | tok/sec:  51171.19\n",
      "step3728 | loss: 0.0014107213355600834 | dt: 320.29ms | tok/sec:  51153.21\n",
      "step3729 | loss: 0.0022345511242747307 | dt: 320.90ms | tok/sec:  51057.13\n",
      "step3730 | loss: 0.0019748276099562645 | dt: 320.36ms | tok/sec:  51142.21\n",
      "step3731 | loss: 0.0014368777628988028 | dt: 321.30ms | tok/sec:  50993.48\n",
      "step3732 | loss: 0.0023701880127191544 | dt: 320.01ms | tok/sec:  51198.45\n",
      "step3733 | loss: 0.0016448688693344593 | dt: 320.06ms | tok/sec:  51190.06\n",
      "step3734 | loss: 0.001049839542247355 | dt: 320.02ms | tok/sec:  51196.50\n",
      "step3735 | loss: 0.0014662407338619232 | dt: 320.82ms | tok/sec:  51068.40\n",
      "step3736 | loss: 0.0012347387382760644 | dt: 320.07ms | tok/sec:  51189.06\n",
      "step3737 | loss: 0.0016456273151561618 | dt: 320.99ms | tok/sec:  51042.80\n",
      "step3738 | loss: 0.0025372563395649195 | dt: 319.99ms | tok/sec:  51200.93\n",
      "step3739 | loss: 0.0015007647452875972 | dt: 320.58ms | tok/sec:  51107.82\n",
      "step3740 | loss: 0.0012328483862802386 | dt: 319.92ms | tok/sec:  51213.40\n",
      "step3741 | loss: 0.001559888245537877 | dt: 321.22ms | tok/sec:  51005.63\n",
      "step3742 | loss: 0.0021804950665682554 | dt: 321.17ms | tok/sec:  51013.05\n",
      "step3743 | loss: 0.0017528641037642956 | dt: 321.22ms | tok/sec:  51005.67\n",
      "step3744 | loss: 0.0017123911529779434 | dt: 321.46ms | tok/sec:  50967.76\n",
      "step3745 | loss: 0.0017596533289179206 | dt: 321.38ms | tok/sec:  50979.94\n",
      "step3746 | loss: 0.0012169552501291037 | dt: 319.86ms | tok/sec:  51221.69\n",
      "step3747 | loss: 0.0022518159821629524 | dt: 321.24ms | tok/sec:  51003.09\n",
      "step3748 | loss: 0.001392987323924899 | dt: 321.09ms | tok/sec:  51025.59\n",
      "step3749 | loss: 0.0022301950957626104 | dt: 320.02ms | tok/sec:  51197.57\n",
      "step3750 | loss: 0.0019688066095113754 | dt: 320.24ms | tok/sec:  51161.55\n",
      "step3751 | loss: 0.0014198839198797941 | dt: 321.22ms | tok/sec:  51005.97\n",
      "step3752 | loss: 0.0023784609511494637 | dt: 319.91ms | tok/sec:  51213.98\n",
      "step3753 | loss: 0.0015855440869927406 | dt: 320.43ms | tok/sec:  51131.36\n",
      "step3754 | loss: 0.0010932011064141989 | dt: 320.23ms | tok/sec:  51163.87\n",
      "step3755 | loss: 0.0014342502690851688 | dt: 320.18ms | tok/sec:  51171.84\n",
      "step3756 | loss: 0.0013186503201723099 | dt: 320.37ms | tok/sec:  51140.80\n",
      "step3757 | loss: 0.0016454656142741442 | dt: 321.08ms | tok/sec:  51027.98\n",
      "step3758 | loss: 0.0024803192354738712 | dt: 320.00ms | tok/sec:  51200.32\n",
      "step3759 | loss: 0.0015048796776682138 | dt: 320.66ms | tok/sec:  51093.88\n",
      "step3760 | loss: 0.0012433433439582586 | dt: 320.02ms | tok/sec:  51197.04\n",
      "step3761 | loss: 0.0015475681284442544 | dt: 320.76ms | tok/sec:  51078.46\n",
      "step3762 | loss: 0.002171159256249666 | dt: 320.85ms | tok/sec:  51065.02\n",
      "step3763 | loss: 0.0017789597623050213 | dt: 321.46ms | tok/sec:  50967.91\n",
      "step3764 | loss: 0.0016955608734861016 | dt: 320.84ms | tok/sec:  51065.33\n",
      "step3765 | loss: 0.0017213867977261543 | dt: 320.18ms | tok/sec:  51171.95\n",
      "step3766 | loss: 0.0011913187336176634 | dt: 319.83ms | tok/sec:  51227.72\n",
      "step3767 | loss: 0.0022483558859676123 | dt: 321.52ms | tok/sec:  50958.65\n",
      "step3768 | loss: 0.0013947014231234789 | dt: 320.00ms | tok/sec:  51200.43\n",
      "step3769 | loss: 0.0022215046919882298 | dt: 320.61ms | tok/sec:  51102.24\n",
      "step3770 | loss: 0.00195224373601377 | dt: 320.03ms | tok/sec:  51195.89\n",
      "step3771 | loss: 0.0014089811593294144 | dt: 321.18ms | tok/sec:  51012.60\n",
      "step3772 | loss: 0.0023483126424252987 | dt: 321.34ms | tok/sec:  50985.80\n",
      "step3773 | loss: 0.0016237040981650352 | dt: 321.06ms | tok/sec:  51030.36\n",
      "step3774 | loss: 0.0010327424388378859 | dt: 319.78ms | tok/sec:  51234.48\n",
      "step3775 | loss: 0.001457015983760357 | dt: 321.15ms | tok/sec:  51016.19\n",
      "step3776 | loss: 0.001214446034282446 | dt: 320.36ms | tok/sec:  51142.70\n",
      "step3777 | loss: 0.001629839651286602 | dt: 319.88ms | tok/sec:  51219.28\n",
      "step3778 | loss: 0.0025152028538286686 | dt: 321.01ms | tok/sec:  51038.59\n",
      "step3779 | loss: 0.001486041583120823 | dt: 320.65ms | tok/sec:  51096.38\n",
      "step3780 | loss: 0.0012194699374958873 | dt: 319.74ms | tok/sec:  51241.78\n",
      "step3781 | loss: 0.0015402983408421278 | dt: 321.23ms | tok/sec:  51004.12\n",
      "step3782 | loss: 0.0021538776345551014 | dt: 320.45ms | tok/sec:  51127.56\n",
      "step3783 | loss: 0.0017300066538155079 | dt: 321.15ms | tok/sec:  51016.57\n",
      "step3784 | loss: 0.0016962226945906878 | dt: 320.15ms | tok/sec:  51176.29\n",
      "step3785 | loss: 0.0017313010757789016 | dt: 320.83ms | tok/sec:  51067.56\n",
      "step3786 | loss: 0.0012002645526081324 | dt: 320.27ms | tok/sec:  51156.48\n",
      "step3787 | loss: 0.002224611584097147 | dt: 321.39ms | tok/sec:  50978.08\n",
      "step3788 | loss: 0.001373309176415205 | dt: 320.36ms | tok/sec:  51143.23\n",
      "step3789 | loss: 0.002211698330938816 | dt: 321.06ms | tok/sec:  51030.59\n",
      "step3790 | loss: 0.0019479359034448862 | dt: 320.19ms | tok/sec:  51170.12\n",
      "step3791 | loss: 0.001400020788423717 | dt: 320.84ms | tok/sec:  51066.73\n",
      "step3792 | loss: 0.002356800716370344 | dt: 321.03ms | tok/sec:  51035.78\n",
      "step3793 | loss: 0.001561189303174615 | dt: 321.25ms | tok/sec:  51001.47\n",
      "step3794 | loss: 0.00107565859798342 | dt: 321.16ms | tok/sec:  51014.53\n",
      "step3795 | loss: 0.0014148035552352667 | dt: 321.16ms | tok/sec:  51014.41\n",
      "step3796 | loss: 0.001310398569330573 | dt: 320.10ms | tok/sec:  51184.64\n",
      "step3797 | loss: 0.0016268441686406732 | dt: 321.24ms | tok/sec:  51002.26\n",
      "step3798 | loss: 0.00246604485437274 | dt: 320.89ms | tok/sec:  51057.93\n",
      "step3799 | loss: 0.0014911938924342394 | dt: 320.70ms | tok/sec:  51088.18\n",
      "step3800 | loss: 0.0012192216236144304 | dt: 320.34ms | tok/sec:  51145.71\n",
      "step3801 | loss: 0.0015293408650904894 | dt: 320.12ms | tok/sec:  51180.56\n",
      "step3802 | loss: 0.0021497136913239956 | dt: 319.95ms | tok/sec:  51208.79\n",
      "step3803 | loss: 0.0017603413434699178 | dt: 321.14ms | tok/sec:  51018.01\n",
      "step3804 | loss: 0.0016848179511725903 | dt: 320.60ms | tok/sec:  51104.06\n",
      "step3805 | loss: 0.0017119771800935268 | dt: 320.86ms | tok/sec:  51063.20\n",
      "step3806 | loss: 0.0011792350560426712 | dt: 320.91ms | tok/sec:  51054.06\n",
      "step3807 | loss: 0.002237513428553939 | dt: 321.24ms | tok/sec:  51002.07\n",
      "step3808 | loss: 0.0013771929079666734 | dt: 319.99ms | tok/sec:  51201.46\n",
      "step3809 | loss: 0.002204625401645899 | dt: 321.27ms | tok/sec:  50998.36\n",
      "step3810 | loss: 0.001935848267748952 | dt: 320.33ms | tok/sec:  51146.47\n",
      "step3811 | loss: 0.0013917845208197832 | dt: 320.03ms | tok/sec:  51194.75\n",
      "step3812 | loss: 0.0023305541835725307 | dt: 319.82ms | tok/sec:  51228.87\n",
      "step3813 | loss: 0.0016074306331574917 | dt: 320.88ms | tok/sec:  51059.18\n",
      "step3814 | loss: 0.001017782837152481 | dt: 320.20ms | tok/sec:  51167.83\n",
      "step3815 | loss: 0.0014466699212789536 | dt: 321.12ms | tok/sec:  51020.85\n",
      "step3816 | loss: 0.00118903792463243 | dt: 320.80ms | tok/sec:  51072.88\n",
      "step3817 | loss: 0.001621748204343021 | dt: 321.43ms | tok/sec:  50971.47\n",
      "step3818 | loss: 0.0024884003214538097 | dt: 320.08ms | tok/sec:  51186.66\n",
      "step3819 | loss: 0.0014694365672767162 | dt: 320.17ms | tok/sec:  51172.64\n",
      "step3820 | loss: 0.0012084608897566795 | dt: 320.04ms | tok/sec:  51193.64\n",
      "step3821 | loss: 0.0015151329571381211 | dt: 320.79ms | tok/sec:  51074.62\n",
      "step3822 | loss: 0.002134658396244049 | dt: 321.08ms | tok/sec:  51027.86\n",
      "step3823 | loss: 0.001728094881400466 | dt: 321.45ms | tok/sec:  50969.54\n",
      "step3824 | loss: 0.0016697035171091557 | dt: 320.42ms | tok/sec:  51132.12\n",
      "step3825 | loss: 0.0017240073066204786 | dt: 320.52ms | tok/sec:  51116.64\n",
      "step3826 | loss: 0.0011761136120185256 | dt: 320.29ms | tok/sec:  51152.94\n",
      "step3827 | loss: 0.0022176913917064667 | dt: 320.73ms | tok/sec:  51082.82\n",
      "step3828 | loss: 0.0013575396733358502 | dt: 320.64ms | tok/sec:  51097.71\n",
      "step3829 | loss: 0.0021968772634863853 | dt: 320.32ms | tok/sec:  51148.64\n",
      "step3830 | loss: 0.0019328857306391 | dt: 320.06ms | tok/sec:  51189.94\n",
      "step3831 | loss: 0.0013801343739032745 | dt: 321.07ms | tok/sec:  51028.66\n",
      "step3832 | loss: 0.0023390341084450483 | dt: 320.00ms | tok/sec:  51199.93\n",
      "step3833 | loss: 0.001546395244076848 | dt: 320.03ms | tok/sec:  51194.86\n",
      "step3834 | loss: 0.0010494876187294722 | dt: 321.06ms | tok/sec:  51030.63\n",
      "step3835 | loss: 0.0013894705334678292 | dt: 321.26ms | tok/sec:  50999.69\n",
      "step3836 | loss: 0.0012930084485560656 | dt: 320.43ms | tok/sec:  51131.86\n",
      "step3837 | loss: 0.0016012882115319371 | dt: 321.02ms | tok/sec:  51037.98\n",
      "step3838 | loss: 0.0024475909303873777 | dt: 321.69ms | tok/sec:  50930.97\n",
      "step3839 | loss: 0.0014671134995296597 | dt: 320.94ms | tok/sec:  51049.85\n",
      "step3840 | loss: 0.0011989400954917073 | dt: 320.63ms | tok/sec:  51099.42\n",
      "step3841 | loss: 0.0015092830872163177 | dt: 321.11ms | tok/sec:  51023.77\n",
      "step3842 | loss: 0.0021316532511264086 | dt: 320.30ms | tok/sec:  51152.49\n",
      "step3843 | loss: 0.0017397513147443533 | dt: 320.72ms | tok/sec:  51085.03\n",
      "step3844 | loss: 0.0016569430008530617 | dt: 320.45ms | tok/sec:  51127.86\n",
      "step3845 | loss: 0.0016874294960871339 | dt: 321.12ms | tok/sec:  51021.61\n",
      "step3846 | loss: 0.0011583874002099037 | dt: 319.93ms | tok/sec:  51211.61\n",
      "step3847 | loss: 0.0022234967909753323 | dt: 320.93ms | tok/sec:  51052.12\n",
      "step3848 | loss: 0.001357420813292265 | dt: 320.01ms | tok/sec:  51198.75\n",
      "step3849 | loss: 0.002185909543186426 | dt: 321.08ms | tok/sec:  51027.98\n",
      "step3850 | loss: 0.0019229393219575286 | dt: 320.49ms | tok/sec:  51122.12\n",
      "step3851 | loss: 0.0013716812245547771 | dt: 321.32ms | tok/sec:  50989.81\n",
      "step3852 | loss: 0.002318405080586672 | dt: 319.87ms | tok/sec:  51221.57\n",
      "step3853 | loss: 0.0015819031978026032 | dt: 320.91ms | tok/sec:  51054.74\n",
      "step3854 | loss: 0.0009984346106648445 | dt: 320.38ms | tok/sec:  51139.73\n",
      "step3855 | loss: 0.0014384412206709385 | dt: 320.35ms | tok/sec:  51143.54\n",
      "step3856 | loss: 0.0011788541451096535 | dt: 320.56ms | tok/sec:  51110.56\n",
      "step3857 | loss: 0.001602458767592907 | dt: 320.99ms | tok/sec:  51042.80\n",
      "step3858 | loss: 0.002473552944138646 | dt: 321.11ms | tok/sec:  51022.37\n",
      "step3859 | loss: 0.001455493620596826 | dt: 320.78ms | tok/sec:  51075.27\n",
      "step3860 | loss: 0.0011911065084859729 | dt: 320.78ms | tok/sec:  51074.85\n",
      "step3861 | loss: 0.0015028947964310646 | dt: 320.82ms | tok/sec:  51069.58\n",
      "step3862 | loss: 0.0021172952838242054 | dt: 320.60ms | tok/sec:  51104.86\n",
      "step3863 | loss: 0.0017111242050305009 | dt: 321.14ms | tok/sec:  51018.73\n",
      "step3864 | loss: 0.0016529152635484934 | dt: 320.35ms | tok/sec:  51144.22\n",
      "step3865 | loss: 0.0016902233473956585 | dt: 321.32ms | tok/sec:  50990.00\n",
      "step3866 | loss: 0.0011610061628744006 | dt: 319.73ms | tok/sec:  51243.99\n",
      "step3867 | loss: 0.0021937929559499025 | dt: 321.17ms | tok/sec:  51014.00\n",
      "step3868 | loss: 0.0013361836317926645 | dt: 320.17ms | tok/sec:  51172.18\n",
      "step3869 | loss: 0.0021699753124266863 | dt: 320.66ms | tok/sec:  51094.33\n",
      "step3870 | loss: 0.0019101202487945557 | dt: 320.02ms | tok/sec:  51197.53\n",
      "step3871 | loss: 0.0013728999765589833 | dt: 321.63ms | tok/sec:  50939.99\n",
      "step3872 | loss: 0.0023157470859587193 | dt: 319.98ms | tok/sec:  51203.22\n",
      "step3873 | loss: 0.001521912170574069 | dt: 320.26ms | tok/sec:  51157.70\n",
      "step3874 | loss: 0.001029327278956771 | dt: 321.26ms | tok/sec:  50999.91\n",
      "step3875 | loss: 0.0013721619034186006 | dt: 320.44ms | tok/sec:  51129.69\n",
      "step3876 | loss: 0.001268675783649087 | dt: 320.02ms | tok/sec:  51196.46\n",
      "step3877 | loss: 0.0015932718524709344 | dt: 321.28ms | tok/sec:  50995.30\n",
      "step3878 | loss: 0.002431353321298957 | dt: 320.78ms | tok/sec:  51075.73\n",
      "step3879 | loss: 0.0014487664448097348 | dt: 321.05ms | tok/sec:  51032.90\n",
      "step3880 | loss: 0.0011808479903265834 | dt: 320.49ms | tok/sec:  51122.12\n",
      "step3881 | loss: 0.001502805040217936 | dt: 321.00ms | tok/sec:  51040.26\n",
      "step3882 | loss: 0.0021198769100010395 | dt: 320.62ms | tok/sec:  51100.41\n",
      "step3883 | loss: 0.001723271794617176 | dt: 320.92ms | tok/sec:  51053.30\n",
      "step3884 | loss: 0.0016576310154050589 | dt: 320.07ms | tok/sec:  51189.60\n",
      "step3885 | loss: 0.0016766316257417202 | dt: 321.03ms | tok/sec:  51035.18\n",
      "step3886 | loss: 0.001143943052738905 | dt: 321.18ms | tok/sec:  51011.76\n",
      "step3887 | loss: 0.002200707793235779 | dt: 321.22ms | tok/sec:  51006.24\n",
      "step3888 | loss: 0.001348460791632533 | dt: 319.83ms | tok/sec:  51227.68\n",
      "step3889 | loss: 0.0021695976611226797 | dt: 320.88ms | tok/sec:  51060.32\n",
      "step3890 | loss: 0.001911284402012825 | dt: 321.22ms | tok/sec:  51005.78\n",
      "step3891 | loss: 0.0013543006498366594 | dt: 321.33ms | tok/sec:  50987.31\n",
      "step3892 | loss: 0.0023038233630359173 | dt: 321.26ms | tok/sec:  50999.46\n",
      "step3893 | loss: 0.0015747826546430588 | dt: 321.29ms | tok/sec:  50994.77\n",
      "step3894 | loss: 0.0009838133119046688 | dt: 320.00ms | tok/sec:  51200.77\n",
      "step3895 | loss: 0.0014206980122253299 | dt: 321.07ms | tok/sec:  51029.49\n",
      "step3896 | loss: 0.0011599776335060596 | dt: 320.27ms | tok/sec:  51156.52\n",
      "step3897 | loss: 0.001575238537043333 | dt: 321.17ms | tok/sec:  51013.96\n",
      "step3898 | loss: 0.0024572997353971004 | dt: 320.33ms | tok/sec:  51146.77\n",
      "step3899 | loss: 0.001434221863746643 | dt: 321.02ms | tok/sec:  51036.92\n",
      "step3900 | loss: 0.0011803335510194302 | dt: 320.72ms | tok/sec:  51085.33\n",
      "step3901 | loss: 0.001493068179115653 | dt: 321.02ms | tok/sec:  51036.96\n",
      "step3902 | loss: 0.0021049906499683857 | dt: 320.03ms | tok/sec:  51195.36\n",
      "step3903 | loss: 0.001700456952676177 | dt: 321.07ms | tok/sec:  51029.87\n",
      "step3904 | loss: 0.0016399716259911656 | dt: 320.01ms | tok/sec:  51197.99\n",
      "step3905 | loss: 0.0016762613086029887 | dt: 321.24ms | tok/sec:  51001.73\n",
      "step3906 | loss: 0.001145672402344644 | dt: 320.12ms | tok/sec:  51181.40\n",
      "step3907 | loss: 0.00217997282743454 | dt: 321.01ms | tok/sec:  51038.44\n",
      "step3908 | loss: 0.0013157795183360577 | dt: 320.19ms | tok/sec:  51170.24\n",
      "step3909 | loss: 0.002165465848520398 | dt: 321.35ms | tok/sec:  50985.69\n",
      "step3910 | loss: 0.001903191558085382 | dt: 320.28ms | tok/sec:  51154.77\n",
      "step3911 | loss: 0.0013590939342975616 | dt: 320.99ms | tok/sec:  51042.07\n",
      "step3912 | loss: 0.002300499239936471 | dt: 321.25ms | tok/sec:  51000.25\n",
      "step3913 | loss: 0.0015027124900370836 | dt: 321.49ms | tok/sec:  50962.96\n",
      "step3914 | loss: 0.0010164356790482998 | dt: 319.91ms | tok/sec:  51214.78\n",
      "step3915 | loss: 0.001349342754110694 | dt: 321.34ms | tok/sec:  50987.24\n",
      "step3916 | loss: 0.0012619525659829378 | dt: 320.50ms | tok/sec:  51120.71\n",
      "step3917 | loss: 0.0015843982109799981 | dt: 321.11ms | tok/sec:  51023.58\n",
      "step3918 | loss: 0.00241275317966938 | dt: 321.08ms | tok/sec:  51028.05\n",
      "step3919 | loss: 0.001444043591618538 | dt: 321.19ms | tok/sec:  51010.02\n",
      "step3920 | loss: 0.0011589988134801388 | dt: 320.63ms | tok/sec:  51099.80\n",
      "step3921 | loss: 0.0014799116179347038 | dt: 321.10ms | tok/sec:  51024.11\n",
      "step3922 | loss: 0.002096651354804635 | dt: 319.72ms | tok/sec:  51244.30\n",
      "step3923 | loss: 0.0016993648605421185 | dt: 321.17ms | tok/sec:  51013.66\n",
      "step3924 | loss: 0.0016232759226113558 | dt: 320.14ms | tok/sec:  51178.24\n",
      "step3925 | loss: 0.0016592873726040125 | dt: 320.59ms | tok/sec:  51106.26\n",
      "step3926 | loss: 0.0011254118289798498 | dt: 320.34ms | tok/sec:  51145.21\n",
      "step3927 | loss: 0.0021873204968869686 | dt: 321.24ms | tok/sec:  51002.94\n",
      "step3928 | loss: 0.001325185177847743 | dt: 319.95ms | tok/sec:  51208.10\n",
      "step3929 | loss: 0.002150984015315771 | dt: 321.13ms | tok/sec:  51019.45\n",
      "step3930 | loss: 0.0018958811415359378 | dt: 320.99ms | tok/sec:  51041.96\n",
      "step3931 | loss: 0.0013427690137177706 | dt: 321.15ms | tok/sec:  51016.04\n",
      "step3932 | loss: 0.0022858232259750366 | dt: 320.61ms | tok/sec:  51102.88\n",
      "step3933 | loss: 0.0015491050435230136 | dt: 321.40ms | tok/sec:  50976.34\n",
      "step3934 | loss: 0.0009669885039329529 | dt: 321.20ms | tok/sec:  51008.54\n",
      "step3935 | loss: 0.0014070677570998669 | dt: 321.43ms | tok/sec:  50972.64\n",
      "step3936 | loss: 0.0011398624628782272 | dt: 320.72ms | tok/sec:  51084.84\n",
      "step3937 | loss: 0.0015595736913383007 | dt: 321.43ms | tok/sec:  50972.75\n",
      "step3938 | loss: 0.0024484265595674515 | dt: 320.08ms | tok/sec:  51187.88\n",
      "step3939 | loss: 0.0014236089773476124 | dt: 320.90ms | tok/sec:  51056.68\n",
      "step3940 | loss: 0.0011575516546145082 | dt: 320.70ms | tok/sec:  51088.33\n",
      "step3941 | loss: 0.0014741886407136917 | dt: 321.33ms | tok/sec:  50987.58\n",
      "step3942 | loss: 0.002086003078147769 | dt: 320.68ms | tok/sec:  51091.48\n",
      "step3943 | loss: 0.0016860526520758867 | dt: 320.94ms | tok/sec:  51049.58\n",
      "step3944 | loss: 0.0016317488625645638 | dt: 321.09ms | tok/sec:  51025.97\n",
      "step3945 | loss: 0.001664837822318077 | dt: 321.02ms | tok/sec:  51037.34\n",
      "step3946 | loss: 0.001128464238718152 | dt: 319.92ms | tok/sec:  51213.56\n",
      "step3947 | loss: 0.0021683003287762403 | dt: 320.85ms | tok/sec:  51064.49\n",
      "step3948 | loss: 0.001301273237913847 | dt: 320.30ms | tok/sec:  51152.26\n",
      "step3949 | loss: 0.002147095277905464 | dt: 321.41ms | tok/sec:  50974.76\n",
      "step3950 | loss: 0.0018804898718371987 | dt: 320.64ms | tok/sec:  51097.49\n",
      "step3951 | loss: 0.0013404421042650938 | dt: 321.08ms | tok/sec:  51028.17\n",
      "step3952 | loss: 0.0022928998805582523 | dt: 320.09ms | tok/sec:  51185.25\n",
      "step3953 | loss: 0.0014931811019778252 | dt: 321.34ms | tok/sec:  50986.10\n",
      "step3954 | loss: 0.0009966237703338265 | dt: 321.26ms | tok/sec:  50999.76\n",
      "step3955 | loss: 0.001335114473477006 | dt: 321.37ms | tok/sec:  50982.47\n",
      "step3956 | loss: 0.0012502355966717005 | dt: 320.60ms | tok/sec:  51104.10\n",
      "step3957 | loss: 0.0015711057931184769 | dt: 321.52ms | tok/sec:  50958.69\n",
      "step3958 | loss: 0.0023982359562069178 | dt: 320.35ms | tok/sec:  51144.19\n",
      "step3959 | loss: 0.0014265321660786867 | dt: 320.25ms | tok/sec:  51160.33\n",
      "step3960 | loss: 0.0011458012741059065 | dt: 321.20ms | tok/sec:  51008.58\n",
      "step3961 | loss: 0.0014688230585306883 | dt: 321.15ms | tok/sec:  51017.29\n",
      "step3962 | loss: 0.0020779892802238464 | dt: 320.89ms | tok/sec:  51058.69\n",
      "step3963 | loss: 0.0016798642463982105 | dt: 321.31ms | tok/sec:  50991.47\n",
      "step3964 | loss: 0.0016146067064255476 | dt: 320.20ms | tok/sec:  51167.30\n",
      "step3965 | loss: 0.0016422461485490203 | dt: 321.17ms | tok/sec:  51012.98\n",
      "step3966 | loss: 0.0011118940310552716 | dt: 320.80ms | tok/sec:  51072.04\n",
      "step3967 | loss: 0.0021725762635469437 | dt: 321.03ms | tok/sec:  51035.10\n",
      "step3968 | loss: 0.0013110220897942781 | dt: 320.51ms | tok/sec:  51118.54\n",
      "step3969 | loss: 0.002140425844117999 | dt: 320.11ms | tok/sec:  51182.35\n",
      "step3970 | loss: 0.0018741084495559335 | dt: 320.31ms | tok/sec:  51150.54\n",
      "step3971 | loss: 0.0013268104521557689 | dt: 321.27ms | tok/sec:  50997.53\n",
      "step3972 | loss: 0.0022699558176100254 | dt: 320.40ms | tok/sec:  51135.62\n",
      "step3973 | loss: 0.0015389027539640665 | dt: 320.76ms | tok/sec:  51079.48\n",
      "step3974 | loss: 0.0009511218522675335 | dt: 321.50ms | tok/sec:  50961.45\n",
      "step3975 | loss: 0.0013898538891226053 | dt: 321.20ms | tok/sec:  51008.89\n",
      "step3976 | loss: 0.0011278880992904305 | dt: 320.06ms | tok/sec:  51190.21\n",
      "step3977 | loss: 0.0015512042446061969 | dt: 321.51ms | tok/sec:  50958.96\n",
      "step3978 | loss: 0.0024319652002304792 | dt: 320.31ms | tok/sec:  51150.09\n",
      "step3979 | loss: 0.0014105017762631178 | dt: 321.00ms | tok/sec:  51040.82\n",
      "step3980 | loss: 0.001138114370405674 | dt: 320.30ms | tok/sec:  51152.07\n",
      "step3981 | loss: 0.001456399797461927 | dt: 320.93ms | tok/sec:  51052.16\n",
      "step3982 | loss: 0.0020695968996733427 | dt: 320.47ms | tok/sec:  51124.78\n",
      "step3983 | loss: 0.0016694231890141964 | dt: 321.17ms | tok/sec:  51013.69\n",
      "step3984 | loss: 0.0016101114451885223 | dt: 319.91ms | tok/sec:  51214.05\n",
      "step3985 | loss: 0.0016506242100149393 | dt: 321.08ms | tok/sec:  51027.14\n",
      "step3986 | loss: 0.001111622666940093 | dt: 320.92ms | tok/sec:  51053.75\n",
      "step3987 | loss: 0.002148809377104044 | dt: 320.70ms | tok/sec:  51088.98\n",
      "step3988 | loss: 0.0012890008511021733 | dt: 320.72ms | tok/sec:  51084.84\n",
      "step3989 | loss: 0.002131066285073757 | dt: 320.93ms | tok/sec:  51051.97\n",
      "step3990 | loss: 0.001867847517132759 | dt: 320.02ms | tok/sec:  51197.07\n",
      "step3991 | loss: 0.0013242693385109305 | dt: 321.48ms | tok/sec:  50964.74\n",
      "step3992 | loss: 0.002273293910548091 | dt: 320.27ms | tok/sec:  51156.48\n",
      "step3993 | loss: 0.0014833722962066531 | dt: 321.27ms | tok/sec:  50997.23\n",
      "step3994 | loss: 0.0009847682667896152 | dt: 321.40ms | tok/sec:  50976.61\n",
      "step3995 | loss: 0.0013274691300466657 | dt: 320.97ms | tok/sec:  51045.90\n",
      "step3996 | loss: 0.0012370710028335452 | dt: 320.26ms | tok/sec:  51158.96\n",
      "step3997 | loss: 0.0015383200952783227 | dt: 321.30ms | tok/sec:  50992.46\n",
      "step3998 | loss: 0.0023820344358682632 | dt: 320.60ms | tok/sec:  51104.17\n",
      "step3999 | loss: 0.0014093340141698718 | dt: 321.34ms | tok/sec:  50986.71\n",
      "Prediction at step 4000: \n",
      " : This is a fixed text used for prediction. that only king, ha\n",
      "That, but work \n",
      "\n",
      "step4000 | loss: 0.0011305066291242838 | dt: 318.55ms | tok/sec:  51433.73\n",
      "step4001 | loss: 0.0014561733696609735 | dt: 319.19ms | tok/sec:  51330.42\n",
      "step4002 | loss: 0.0020732248667627573 | dt: 321.64ms | tok/sec:  50939.50\n",
      "step4003 | loss: 0.0016717581311240792 | dt: 321.09ms | tok/sec:  51026.01\n",
      "step4004 | loss: 0.0016021702904254198 | dt: 320.03ms | tok/sec:  51195.24\n",
      "step4005 | loss: 0.001630741055123508 | dt: 321.36ms | tok/sec:  50982.89\n",
      "step4006 | loss: 0.0010915860766544938 | dt: 321.95ms | tok/sec:  50889.90\n",
      "step4007 | loss: 0.0021546606440097094 | dt: 320.90ms | tok/sec:  51057.13\n",
      "step4008 | loss: 0.0012998923193663359 | dt: 319.60ms | tok/sec:  51263.76\n",
      "step4009 | loss: 0.0021119597367942333 | dt: 321.33ms | tok/sec:  50987.92\n",
      "step4010 | loss: 0.0018598114838823676 | dt: 320.93ms | tok/sec:  51052.09\n",
      "step4011 | loss: 0.0013138526119291782 | dt: 319.80ms | tok/sec:  51231.81\n",
      "step4012 | loss: 0.00225993525236845 | dt: 320.87ms | tok/sec:  51060.81\n",
      "step4013 | loss: 0.0015255308244377375 | dt: 320.92ms | tok/sec:  51053.07\n",
      "step4014 | loss: 0.0009324495331384242 | dt: 319.91ms | tok/sec:  51213.86\n",
      "step4015 | loss: 0.0013746970798820257 | dt: 321.14ms | tok/sec:  51018.16\n",
      "step4016 | loss: 0.0011102596763521433 | dt: 321.53ms | tok/sec:  50956.50\n",
      "step4017 | loss: 0.0015382792335003614 | dt: 320.76ms | tok/sec:  51079.26\n",
      "step4018 | loss: 0.0024146398063749075 | dt: 321.18ms | tok/sec:  51012.67\n",
      "step4019 | loss: 0.0014053704217076302 | dt: 321.49ms | tok/sec:  50962.24\n",
      "step4020 | loss: 0.0011185591574758291 | dt: 320.33ms | tok/sec:  51147.12\n",
      "step4021 | loss: 0.0014368999982252717 | dt: 320.55ms | tok/sec:  51112.27\n",
      "step4022 | loss: 0.002060500904917717 | dt: 321.45ms | tok/sec:  50969.54\n",
      "step4023 | loss: 0.0016589232254773378 | dt: 320.59ms | tok/sec:  51105.62\n",
      "step4024 | loss: 0.0015867678448557854 | dt: 320.97ms | tok/sec:  51045.41\n",
      "step4025 | loss: 0.001637689652852714 | dt: 321.42ms | tok/sec:  50973.81\n",
      "step4026 | loss: 0.0010990959126502275 | dt: 319.79ms | tok/sec:  51233.45\n",
      "step4027 | loss: 0.0021325754933059216 | dt: 320.38ms | tok/sec:  51138.67\n",
      "step4028 | loss: 0.0012709039729088545 | dt: 321.41ms | tok/sec:  50974.95\n",
      "step4029 | loss: 0.002115245210006833 | dt: 320.92ms | tok/sec:  51052.92\n",
      "step4030 | loss: 0.001856131013482809 | dt: 320.50ms | tok/sec:  51120.52\n",
      "step4031 | loss: 0.001307734870351851 | dt: 321.54ms | tok/sec:  50954.69\n",
      "step4032 | loss: 0.0022591943852603436 | dt: 320.91ms | tok/sec:  51054.66\n",
      "step4033 | loss: 0.0014667203649878502 | dt: 321.20ms | tok/sec:  51009.11\n",
      "step4034 | loss: 0.0009619030170142651 | dt: 320.99ms | tok/sec:  51042.26\n",
      "step4035 | loss: 0.001312735490500927 | dt: 321.02ms | tok/sec:  51037.79\n",
      "step4036 | loss: 0.0012262138770893216 | dt: 321.00ms | tok/sec:  51040.75\n",
      "step4037 | loss: 0.0015333453193306923 | dt: 321.19ms | tok/sec:  51010.59\n",
      "step4038 | loss: 0.0023732951376587152 | dt: 320.82ms | tok/sec:  51069.92\n",
      "step4039 | loss: 0.0013990579172968864 | dt: 321.23ms | tok/sec:  51003.85\n",
      "step4040 | loss: 0.0011175335384905338 | dt: 321.31ms | tok/sec:  50991.17\n",
      "step4041 | loss: 0.0014466397697106004 | dt: 321.50ms | tok/sec:  50961.03\n",
      "step4042 | loss: 0.0020575709640979767 | dt: 320.78ms | tok/sec:  51075.57\n",
      "step4043 | loss: 0.001649690791964531 | dt: 320.89ms | tok/sec:  51057.43\n",
      "step4044 | loss: 0.0015959645388647914 | dt: 321.22ms | tok/sec:  51004.91\n",
      "step4045 | loss: 0.0016161489766091108 | dt: 321.37ms | tok/sec:  50982.28\n",
      "step4046 | loss: 0.0010766780469566584 | dt: 320.51ms | tok/sec:  51119.19\n",
      "step4047 | loss: 0.002135692862793803 | dt: 320.94ms | tok/sec:  51050.30\n",
      "step4048 | loss: 0.0012710700975731015 | dt: 320.70ms | tok/sec:  51087.69\n",
      "step4049 | loss: 0.0021073524840176105 | dt: 321.14ms | tok/sec:  51019.00\n",
      "step4050 | loss: 0.001844483893364668 | dt: 320.73ms | tok/sec:  51083.55\n",
      "step4051 | loss: 0.0012951235985383391 | dt: 321.12ms | tok/sec:  51022.03\n",
      "step4052 | loss: 0.0022437686566263437 | dt: 320.33ms | tok/sec:  51146.93\n",
      "step4053 | loss: 0.0015110457316040993 | dt: 321.21ms | tok/sec:  51007.52\n",
      "step4054 | loss: 0.0009302868274971843 | dt: 320.95ms | tok/sec:  51048.18\n",
      "step4055 | loss: 0.0013499383348971605 | dt: 321.22ms | tok/sec:  51005.78\n",
      "step4056 | loss: 0.0011009827721863985 | dt: 320.97ms | tok/sec:  51045.79\n",
      "step4057 | loss: 0.0015220087952911854 | dt: 321.02ms | tok/sec:  51037.94\n",
      "step4058 | loss: 0.00239916262216866 | dt: 320.37ms | tok/sec:  51141.18\n",
      "step4059 | loss: 0.0013856417499482632 | dt: 320.07ms | tok/sec:  51189.48\n",
      "step4060 | loss: 0.0011040570680052042 | dt: 320.36ms | tok/sec:  51143.23\n",
      "step4061 | loss: 0.0014313110150396824 | dt: 321.44ms | tok/sec:  50969.88\n",
      "step4062 | loss: 0.002042253501713276 | dt: 319.98ms | tok/sec:  51203.18\n",
      "step4063 | loss: 0.0016601324314251542 | dt: 320.87ms | tok/sec:  51061.38\n",
      "step4064 | loss: 0.001572243869304657 | dt: 321.13ms | tok/sec:  51020.63\n",
      "step4065 | loss: 0.0016122283414006233 | dt: 321.38ms | tok/sec:  50980.54\n",
      "step4066 | loss: 0.0010803667828440666 | dt: 320.06ms | tok/sec:  51189.67\n",
      "step4067 | loss: 0.002128206891939044 | dt: 321.24ms | tok/sec:  51002.49\n",
      "step4068 | loss: 0.0012611811980605125 | dt: 320.67ms | tok/sec:  51092.89\n",
      "step4069 | loss: 0.0021078267600387335 | dt: 321.01ms | tok/sec:  51039.69\n",
      "step4070 | loss: 0.001842291560024023 | dt: 320.45ms | tok/sec:  51128.62\n",
      "step4071 | loss: 0.0013006748631596565 | dt: 321.11ms | tok/sec:  51022.90\n",
      "step4072 | loss: 0.0022460760083049536 | dt: 320.34ms | tok/sec:  51145.71\n",
      "step4073 | loss: 0.0014582572039216757 | dt: 320.27ms | tok/sec:  51157.44\n",
      "step4074 | loss: 0.0009462439920753241 | dt: 321.20ms | tok/sec:  51009.11\n",
      "step4075 | loss: 0.0012948527000844479 | dt: 320.24ms | tok/sec:  51161.59\n",
      "step4076 | loss: 0.0012047865893691778 | dt: 320.26ms | tok/sec:  51158.73\n",
      "step4077 | loss: 0.0015202288050204515 | dt: 320.64ms | tok/sec:  51097.11\n",
      "step4078 | loss: 0.0023543252609670162 | dt: 320.60ms | tok/sec:  51103.95\n",
      "step4079 | loss: 0.0013882247731089592 | dt: 320.84ms | tok/sec:  51066.65\n",
      "step4080 | loss: 0.0010979354847222567 | dt: 320.19ms | tok/sec:  51169.55\n",
      "step4081 | loss: 0.001422604196704924 | dt: 320.95ms | tok/sec:  51048.79\n",
      "step4082 | loss: 0.002041257219389081 | dt: 320.00ms | tok/sec:  51199.48\n",
      "step4083 | loss: 0.0016271285712718964 | dt: 321.44ms | tok/sec:  50970.48\n",
      "step4084 | loss: 0.00159126752987504 | dt: 321.20ms | tok/sec:  51008.54\n",
      "step4085 | loss: 0.0016092539299279451 | dt: 321.04ms | tok/sec:  51033.81\n",
      "step4086 | loss: 0.0010677522514015436 | dt: 320.82ms | tok/sec:  51069.73\n",
      "step4087 | loss: 0.0021309154108166695 | dt: 320.38ms | tok/sec:  51139.96\n",
      "step4088 | loss: 0.00126274349167943 | dt: 320.02ms | tok/sec:  51196.65\n",
      "step4089 | loss: 0.002094462513923645 | dt: 321.20ms | tok/sec:  51009.15\n",
      "step4090 | loss: 0.001837689196690917 | dt: 319.88ms | tok/sec:  51219.43\n",
      "step4091 | loss: 0.0012824658770114183 | dt: 321.09ms | tok/sec:  51026.73\n",
      "step4092 | loss: 0.0022320887073874474 | dt: 320.03ms | tok/sec:  51195.40\n",
      "step4093 | loss: 0.001493733492679894 | dt: 321.28ms | tok/sec:  50995.26\n",
      "step4094 | loss: 0.0009165374212898314 | dt: 321.41ms | tok/sec:  50975.55\n",
      "step4095 | loss: 0.0013390867970883846 | dt: 320.21ms | tok/sec:  51166.39\n",
      "step4096 | loss: 0.0010885586962103844 | dt: 320.37ms | tok/sec:  51141.03\n",
      "step4097 | loss: 0.0015133280539885163 | dt: 320.86ms | tok/sec:  51063.01\n",
      "step4098 | loss: 0.00239203660748899 | dt: 320.63ms | tok/sec:  51098.82\n",
      "step4099 | loss: 0.0013777241110801697 | dt: 321.16ms | tok/sec:  51015.55\n",
      "step4100 | loss: 0.0010945061221718788 | dt: 320.85ms | tok/sec:  51064.79\n",
      "step4101 | loss: 0.0014226847561076283 | dt: 320.37ms | tok/sec:  51140.15\n",
      "step4102 | loss: 0.002026143716648221 | dt: 320.38ms | tok/sec:  51139.73\n",
      "step4103 | loss: 0.0016421430045738816 | dt: 321.10ms | tok/sec:  51024.41\n",
      "step4104 | loss: 0.0015541953034698963 | dt: 320.96ms | tok/sec:  51046.66\n",
      "step4105 | loss: 0.0016042515635490417 | dt: 321.27ms | tok/sec:  50996.81\n",
      "step4106 | loss: 0.0010688977781683207 | dt: 320.76ms | tok/sec:  51078.72\n",
      "step4107 | loss: 0.002117111347615719 | dt: 321.01ms | tok/sec:  51038.17\n",
      "step4108 | loss: 0.001246006926521659 | dt: 321.04ms | tok/sec:  51034.04\n",
      "step4109 | loss: 0.002095917472615838 | dt: 321.39ms | tok/sec:  50978.58\n",
      "step4110 | loss: 0.001825611456297338 | dt: 321.27ms | tok/sec:  50997.83\n",
      "step4111 | loss: 0.0012913907412439585 | dt: 321.41ms | tok/sec:  50975.40\n",
      "step4112 | loss: 0.0022380524314939976 | dt: 321.21ms | tok/sec:  51006.84\n",
      "step4113 | loss: 0.0014381411019712687 | dt: 321.24ms | tok/sec:  51003.13\n",
      "step4114 | loss: 0.0009305637795478106 | dt: 320.93ms | tok/sec:  51051.86\n",
      "step4115 | loss: 0.0012912079691886902 | dt: 321.01ms | tok/sec:  51038.36\n",
      "step4116 | loss: 0.0011918321251869202 | dt: 320.46ms | tok/sec:  51125.92\n",
      "step4117 | loss: 0.001511288108304143 | dt: 320.78ms | tok/sec:  51075.50\n",
      "step4118 | loss: 0.00233721942640841 | dt: 320.41ms | tok/sec:  51134.25\n",
      "step4119 | loss: 0.001377686159685254 | dt: 321.08ms | tok/sec:  51028.24\n",
      "step4120 | loss: 0.0010782985482364893 | dt: 320.80ms | tok/sec:  51071.82\n",
      "step4121 | loss: 0.0014140346320345998 | dt: 320.21ms | tok/sec:  51166.31\n",
      "step4122 | loss: 0.0020250172819942236 | dt: 320.39ms | tok/sec:  51137.03\n",
      "step4123 | loss: 0.0016299928538501263 | dt: 320.58ms | tok/sec:  51106.61\n",
      "step4124 | loss: 0.001570841995999217 | dt: 320.18ms | tok/sec:  51171.19\n",
      "step4125 | loss: 0.001596615882590413 | dt: 320.18ms | tok/sec:  51171.15\n",
      "step4126 | loss: 0.001049768179655075 | dt: 320.28ms | tok/sec:  51155.80\n",
      "step4127 | loss: 0.0021161497570574284 | dt: 321.26ms | tok/sec:  50998.44\n",
      "step4128 | loss: 0.0012533336412161589 | dt: 320.67ms | tok/sec:  51093.80\n",
      "step4129 | loss: 0.0020891393069177866 | dt: 321.01ms | tok/sec:  51038.59\n",
      "step4130 | loss: 0.0018235171446576715 | dt: 320.82ms | tok/sec:  51069.50\n",
      "step4131 | loss: 0.001270242384634912 | dt: 321.37ms | tok/sec:  50982.24\n",
      "step4132 | loss: 0.002217060187831521 | dt: 321.15ms | tok/sec:  51016.23\n",
      "step4133 | loss: 0.0014776657335460186 | dt: 321.26ms | tok/sec:  50998.59\n",
      "step4134 | loss: 0.0009007913176901639 | dt: 320.12ms | tok/sec:  51180.14\n",
      "step4135 | loss: 0.0013297441182658076 | dt: 321.43ms | tok/sec:  50972.79\n",
      "step4136 | loss: 0.0010752021335065365 | dt: 320.96ms | tok/sec:  51046.78\n",
      "step4137 | loss: 0.0014993611257523298 | dt: 320.92ms | tok/sec:  51053.94\n",
      "step4138 | loss: 0.002377459779381752 | dt: 319.91ms | tok/sec:  51214.66\n",
      "step4139 | loss: 0.001365955569781363 | dt: 321.14ms | tok/sec:  51017.67\n",
      "step4140 | loss: 0.001082761911675334 | dt: 320.19ms | tok/sec:  51170.04\n",
      "step4141 | loss: 0.0014061226975172758 | dt: 320.65ms | tok/sec:  51096.57\n",
      "step4142 | loss: 0.002016992773860693 | dt: 320.25ms | tok/sec:  51160.44\n",
      "step4143 | loss: 0.0016236109659075737 | dt: 321.11ms | tok/sec:  51022.79\n",
      "step4144 | loss: 0.0015569415409117937 | dt: 319.98ms | tok/sec:  51202.53\n",
      "step4145 | loss: 0.0015919455327093601 | dt: 321.00ms | tok/sec:  51040.37\n",
      "step4146 | loss: 0.0010577982757240534 | dt: 320.56ms | tok/sec:  51110.94\n",
      "step4147 | loss: 0.0021005000453442335 | dt: 320.33ms | tok/sec:  51146.74\n",
      "step4148 | loss: 0.0012331886682659388 | dt: 320.82ms | tok/sec:  51068.78\n",
      "step4149 | loss: 0.0020873863250017166 | dt: 320.89ms | tok/sec:  51058.04\n",
      "step4150 | loss: 0.0018100648885592818 | dt: 321.53ms | tok/sec:  50956.84\n",
      "step4151 | loss: 0.0012774926144629717 | dt: 320.45ms | tok/sec:  51128.39\n",
      "step4152 | loss: 0.0022317979019135237 | dt: 320.72ms | tok/sec:  51085.37\n",
      "step4153 | loss: 0.0014238706789910793 | dt: 321.14ms | tok/sec:  51019.00\n",
      "step4154 | loss: 0.0009158221073448658 | dt: 319.65ms | tok/sec:  51255.27\n",
      "step4155 | loss: 0.001269060536287725 | dt: 321.21ms | tok/sec:  51007.52\n",
      "step4156 | loss: 0.0011786548420786858 | dt: 320.25ms | tok/sec:  51160.79\n",
      "step4157 | loss: 0.0015069956425577402 | dt: 320.01ms | tok/sec:  51198.83\n",
      "step4158 | loss: 0.002323322929441929 | dt: 320.24ms | tok/sec:  51162.04\n",
      "step4159 | loss: 0.001360165188089013 | dt: 321.56ms | tok/sec:  50951.06\n",
      "step4160 | loss: 0.0010674099903553724 | dt: 319.87ms | tok/sec:  51220.24\n",
      "step4161 | loss: 0.00140263547655195 | dt: 320.25ms | tok/sec:  51160.83\n",
      "step4162 | loss: 0.00201984029263258 | dt: 320.43ms | tok/sec:  51131.86\n",
      "step4163 | loss: 0.0016238139942288399 | dt: 321.15ms | tok/sec:  51016.38\n",
      "step4164 | loss: 0.0015520082088187337 | dt: 320.64ms | tok/sec:  51097.56\n",
      "step4165 | loss: 0.0015726989367976785 | dt: 321.14ms | tok/sec:  51017.52\n",
      "step4166 | loss: 0.0010358127765357494 | dt: 319.94ms | tok/sec:  51209.93\n",
      "step4167 | loss: 0.002107564127072692 | dt: 321.03ms | tok/sec:  51035.86\n",
      "step4168 | loss: 0.0012429205235093832 | dt: 320.04ms | tok/sec:  51192.92\n",
      "step4169 | loss: 0.0020731778349727392 | dt: 321.05ms | tok/sec:  51032.30\n",
      "step4170 | loss: 0.0018115772400051355 | dt: 320.19ms | tok/sec:  51170.20\n",
      "step4171 | loss: 0.001253975322470069 | dt: 321.21ms | tok/sec:  51007.11\n",
      "step4172 | loss: 0.002209032652899623 | dt: 320.26ms | tok/sec:  51158.35\n",
      "step4173 | loss: 0.0014701285399496555 | dt: 321.08ms | tok/sec:  51028.17\n",
      "step4174 | loss: 0.0008787208353169262 | dt: 321.28ms | tok/sec:  50996.43\n",
      "step4175 | loss: 0.001313167391344905 | dt: 319.89ms | tok/sec:  51217.22\n",
      "step4176 | loss: 0.0010717534460127354 | dt: 320.32ms | tok/sec:  51149.21\n",
      "step4177 | loss: 0.0014866889687255025 | dt: 321.17ms | tok/sec:  51013.73\n",
      "step4178 | loss: 0.002366209402680397 | dt: 320.02ms | tok/sec:  51197.49\n",
      "step4179 | loss: 0.0013467599637806416 | dt: 320.98ms | tok/sec:  51042.91\n",
      "step4180 | loss: 0.0010663135908544064 | dt: 320.47ms | tok/sec:  51124.86\n",
      "step4181 | loss: 0.001392640289850533 | dt: 321.27ms | tok/sec:  50997.30\n",
      "step4182 | loss: 0.0019992399029433727 | dt: 320.21ms | tok/sec:  51166.01\n",
      "step4183 | loss: 0.0016008905367925763 | dt: 321.36ms | tok/sec:  50982.58\n",
      "step4184 | loss: 0.0015501584857702255 | dt: 320.65ms | tok/sec:  51095.51\n",
      "step4185 | loss: 0.0015795245999470353 | dt: 321.33ms | tok/sec:  50988.30\n",
      "step4186 | loss: 0.0010404970962554216 | dt: 320.44ms | tok/sec:  51129.76\n",
      "step4187 | loss: 0.0020796952303498983 | dt: 321.12ms | tok/sec:  51021.35\n",
      "step4188 | loss: 0.001216244651004672 | dt: 320.02ms | tok/sec:  51197.30\n",
      "step4189 | loss: 0.0020689836237579584 | dt: 320.78ms | tok/sec:  51075.99\n",
      "step4190 | loss: 0.0018045941833406687 | dt: 319.90ms | tok/sec:  51215.39\n",
      "step4191 | loss: 0.0012607977259904146 | dt: 320.27ms | tok/sec:  51157.06\n",
      "step4192 | loss: 0.0022153062745928764 | dt: 320.65ms | tok/sec:  51096.42\n",
      "step4193 | loss: 0.0014078833628445864 | dt: 321.21ms | tok/sec:  51006.88\n",
      "step4194 | loss: 0.0009106446523219347 | dt: 320.81ms | tok/sec:  51070.87\n",
      "step4195 | loss: 0.0012626959942281246 | dt: 321.42ms | tok/sec:  50973.51\n",
      "step4196 | loss: 0.0011691756080836058 | dt: 320.06ms | tok/sec:  51191.09\n",
      "step4197 | loss: 0.0014852996682748199 | dt: 321.13ms | tok/sec:  51019.22\n",
      "step4198 | loss: 0.0023147836327552795 | dt: 320.24ms | tok/sec:  51161.28\n",
      "step4199 | loss: 0.0013524850364774466 | dt: 321.52ms | tok/sec:  50957.37\n",
      "step4200 | loss: 0.0010559725342318416 | dt: 320.07ms | tok/sec:  51188.15\n",
      "step4201 | loss: 0.0013906973181292415 | dt: 321.07ms | tok/sec:  51030.06\n",
      "step4202 | loss: 0.0020111771300435066 | dt: 320.42ms | tok/sec:  51133.64\n",
      "step4203 | loss: 0.0016187322326004505 | dt: 320.48ms | tok/sec:  51123.91\n",
      "step4204 | loss: 0.0015297539066523314 | dt: 321.37ms | tok/sec:  50981.22\n",
      "step4205 | loss: 0.001571608823724091 | dt: 320.92ms | tok/sec:  51053.91\n",
      "step4206 | loss: 0.0010230927728116512 | dt: 320.54ms | tok/sec:  51114.48\n",
      "step4207 | loss: 0.0020832251757383347 | dt: 321.49ms | tok/sec:  50962.43\n",
      "step4208 | loss: 0.0012279623188078403 | dt: 320.48ms | tok/sec:  51123.98\n",
      "step4209 | loss: 0.002057898323982954 | dt: 321.13ms | tok/sec:  51019.72\n",
      "step4210 | loss: 0.0018002677243202925 | dt: 320.72ms | tok/sec:  51084.34\n",
      "step4211 | loss: 0.0012502113822847605 | dt: 321.10ms | tok/sec:  51024.53\n",
      "step4212 | loss: 0.002200801856815815 | dt: 321.25ms | tok/sec:  51001.31\n",
      "step4213 | loss: 0.0014630653895437717 | dt: 321.21ms | tok/sec:  51007.79\n",
      "step4214 | loss: 0.0008647379581816494 | dt: 321.02ms | tok/sec:  51037.68\n",
      "step4215 | loss: 0.0013032869901508093 | dt: 320.98ms | tok/sec:  51043.48\n",
      "step4216 | loss: 0.0010507421102374792 | dt: 321.12ms | tok/sec:  51021.80\n",
      "step4217 | loss: 0.001482694991864264 | dt: 320.94ms | tok/sec:  51050.53\n",
      "step4218 | loss: 0.0023535490036010742 | dt: 320.56ms | tok/sec:  51111.28\n",
      "step4219 | loss: 0.0013378995936363935 | dt: 321.19ms | tok/sec:  51010.10\n",
      "step4220 | loss: 0.0010551107116043568 | dt: 320.14ms | tok/sec:  51177.44\n",
      "step4221 | loss: 0.0013710350031033158 | dt: 321.41ms | tok/sec:  50974.72\n",
      "step4222 | loss: 0.0019868386443704367 | dt: 320.61ms | tok/sec:  51101.82\n",
      "step4223 | loss: 0.001590649364516139 | dt: 321.11ms | tok/sec:  51022.71\n",
      "step4224 | loss: 0.0015464494936168194 | dt: 319.99ms | tok/sec:  51202.38\n",
      "step4225 | loss: 0.0015653370646759868 | dt: 321.38ms | tok/sec:  50980.77\n",
      "step4226 | loss: 0.0010304031893610954 | dt: 320.32ms | tok/sec:  51148.34\n",
      "step4227 | loss: 0.002070230897516012 | dt: 321.47ms | tok/sec:  50965.68\n",
      "step4228 | loss: 0.0012098206207156181 | dt: 320.02ms | tok/sec:  51197.49\n",
      "step4229 | loss: 0.002063922816887498 | dt: 321.44ms | tok/sec:  50970.79\n",
      "step4230 | loss: 0.0017936767544597387 | dt: 320.56ms | tok/sec:  51111.17\n",
      "step4231 | loss: 0.0012498139403760433 | dt: 320.40ms | tok/sec:  51135.32\n",
      "step4232 | loss: 0.0021944218315184116 | dt: 320.49ms | tok/sec:  51122.50\n",
      "step4233 | loss: 0.0013952945591881871 | dt: 321.02ms | tok/sec:  51037.03\n",
      "step4234 | loss: 0.0008908940944820642 | dt: 320.30ms | tok/sec:  51151.57\n",
      "step4235 | loss: 0.0012495690025389194 | dt: 320.94ms | tok/sec:  51050.61\n",
      "step4236 | loss: 0.0011551945935934782 | dt: 320.49ms | tok/sec:  51122.31\n",
      "step4237 | loss: 0.0014698283048346639 | dt: 320.21ms | tok/sec:  51166.88\n",
      "step4238 | loss: 0.002304943511262536 | dt: 320.36ms | tok/sec:  51143.01\n",
      "step4239 | loss: 0.0013374821282923222 | dt: 320.43ms | tok/sec:  51131.86\n",
      "step4240 | loss: 0.0010377397993579507 | dt: 320.58ms | tok/sec:  51107.29\n",
      "step4241 | loss: 0.0013893481809645891 | dt: 320.30ms | tok/sec:  51152.79\n",
      "step4242 | loss: 0.0019930978305637836 | dt: 320.74ms | tok/sec:  51082.18\n",
      "step4243 | loss: 0.0016092306468635798 | dt: 320.62ms | tok/sec:  51101.48\n",
      "step4244 | loss: 0.0015180669724941254 | dt: 320.79ms | tok/sec:  51074.24\n",
      "step4245 | loss: 0.0015566506190225482 | dt: 320.98ms | tok/sec:  51043.82\n",
      "step4246 | loss: 0.0010070691350847483 | dt: 320.91ms | tok/sec:  51054.66\n",
      "step4247 | loss: 0.002071299124509096 | dt: 321.55ms | tok/sec:  50952.49\n",
      "step4248 | loss: 0.0012205366510897875 | dt: 320.98ms | tok/sec:  51043.29\n",
      "step4249 | loss: 0.0020452472381293774 | dt: 320.63ms | tok/sec:  51098.97\n",
      "step4250 | loss: 0.0017913526389747858 | dt: 321.21ms | tok/sec:  51007.18\n",
      "step4251 | loss: 0.001237834570929408 | dt: 321.17ms | tok/sec:  51013.16\n",
      "step4252 | loss: 0.002181223826482892 | dt: 321.09ms | tok/sec:  51025.44\n",
      "step4253 | loss: 0.0014515201328322291 | dt: 321.06ms | tok/sec:  51031.69\n",
      "step4254 | loss: 0.0008528202888555825 | dt: 320.57ms | tok/sec:  51109.57\n",
      "step4255 | loss: 0.0012902106391265988 | dt: 320.70ms | tok/sec:  51088.48\n",
      "step4256 | loss: 0.0010395431891083717 | dt: 320.36ms | tok/sec:  51142.74\n",
      "step4257 | loss: 0.0014700167812407017 | dt: 320.98ms | tok/sec:  51043.52\n",
      "step4258 | loss: 0.0023322333581745625 | dt: 321.20ms | tok/sec:  51008.09\n",
      "step4259 | loss: 0.001328438171185553 | dt: 321.26ms | tok/sec:  50998.40\n",
      "step4260 | loss: 0.0010474736336618662 | dt: 320.55ms | tok/sec:  51112.84\n",
      "step4261 | loss: 0.0013690118212252855 | dt: 321.17ms | tok/sec:  51014.11\n",
      "step4262 | loss: 0.001973877428099513 | dt: 319.98ms | tok/sec:  51203.06\n",
      "step4263 | loss: 0.0015755519270896912 | dt: 320.04ms | tok/sec:  51194.21\n",
      "step4264 | loss: 0.001537530217319727 | dt: 321.33ms | tok/sec:  50988.07\n",
      "step4265 | loss: 0.001553829642944038 | dt: 320.61ms | tok/sec:  51102.50\n",
      "step4266 | loss: 0.0010178827214986086 | dt: 319.99ms | tok/sec:  51202.22\n",
      "step4267 | loss: 0.0020592580549418926 | dt: 321.53ms | tok/sec:  50956.80\n",
      "step4268 | loss: 0.0011986787430942059 | dt: 320.52ms | tok/sec:  51117.40\n",
      "step4269 | loss: 0.0020507043227553368 | dt: 320.98ms | tok/sec:  51043.55\n",
      "step4270 | loss: 0.001785935484804213 | dt: 320.72ms | tok/sec:  51085.03\n",
      "step4271 | loss: 0.0012362946290522814 | dt: 321.34ms | tok/sec:  50985.84\n",
      "step4272 | loss: 0.0021833020728081465 | dt: 320.22ms | tok/sec:  51164.25\n",
      "step4273 | loss: 0.0013876772718504071 | dt: 321.07ms | tok/sec:  51030.06\n",
      "step4274 | loss: 0.0008863088442012668 | dt: 319.99ms | tok/sec:  51201.73\n",
      "step4275 | loss: 0.0012327816803008318 | dt: 320.94ms | tok/sec:  51050.64\n",
      "step4276 | loss: 0.001143091474659741 | dt: 320.38ms | tok/sec:  51139.81\n",
      "step4277 | loss: 0.0014687865041196346 | dt: 321.14ms | tok/sec:  51017.60\n",
      "step4278 | loss: 0.00228757387958467 | dt: 320.33ms | tok/sec:  51146.93\n",
      "step4279 | loss: 0.001329605933278799 | dt: 321.17ms | tok/sec:  51014.00\n",
      "step4280 | loss: 0.001019506948068738 | dt: 320.72ms | tok/sec:  51084.91\n",
      "step4281 | loss: 0.0013645929284393787 | dt: 320.94ms | tok/sec:  51050.80\n",
      "step4282 | loss: 0.001990030985325575 | dt: 320.54ms | tok/sec:  51114.29\n",
      "step4283 | loss: 0.0015970906242728233 | dt: 320.24ms | tok/sec:  51161.02\n",
      "step4284 | loss: 0.0015197277534753084 | dt: 320.01ms | tok/sec:  51198.14\n",
      "step4285 | loss: 0.0015503906179219484 | dt: 321.31ms | tok/sec:  50990.72\n",
      "step4286 | loss: 0.0009923751931637526 | dt: 320.24ms | tok/sec:  51161.24\n",
      "step4287 | loss: 0.0020634615793824196 | dt: 320.18ms | tok/sec:  51171.87\n",
      "step4288 | loss: 0.0012052343226969242 | dt: 321.18ms | tok/sec:  51012.14\n",
      "step4289 | loss: 0.002034451114013791 | dt: 320.91ms | tok/sec:  51055.46\n",
      "step4290 | loss: 0.0017748004756867886 | dt: 321.20ms | tok/sec:  51008.20\n",
      "step4291 | loss: 0.0012322162510827184 | dt: 320.86ms | tok/sec:  51062.78\n",
      "step4292 | loss: 0.0021643752697855234 | dt: 321.33ms | tok/sec:  50987.46\n",
      "step4293 | loss: 0.0014370286371558905 | dt: 321.22ms | tok/sec:  51004.91\n",
      "step4294 | loss: 0.0008377167396247387 | dt: 321.12ms | tok/sec:  51020.74\n",
      "step4295 | loss: 0.0012798041570931673 | dt: 320.15ms | tok/sec:  51175.61\n",
      "step4296 | loss: 0.001034190529026091 | dt: 319.91ms | tok/sec:  51214.13\n",
      "step4297 | loss: 0.0014582739677280188 | dt: 321.21ms | tok/sec:  51007.41\n",
      "step4298 | loss: 0.002339602680876851 | dt: 319.90ms | tok/sec:  51216.23\n",
      "step4299 | loss: 0.0013174397172406316 | dt: 321.22ms | tok/sec:  51005.33\n",
      "step4300 | loss: 0.001036882633343339 | dt: 320.22ms | tok/sec:  51165.17\n",
      "step4301 | loss: 0.0013680497650057077 | dt: 320.81ms | tok/sec:  51071.09\n",
      "step4302 | loss: 0.0019621688406914473 | dt: 320.40ms | tok/sec:  51136.46\n",
      "step4303 | loss: 0.001575944828800857 | dt: 320.49ms | tok/sec:  51121.05\n",
      "step4304 | loss: 0.0015230621211230755 | dt: 320.42ms | tok/sec:  51133.11\n",
      "step4305 | loss: 0.0015440843999385834 | dt: 320.20ms | tok/sec:  51167.99\n",
      "step4306 | loss: 0.0010134413605555892 | dt: 320.43ms | tok/sec:  51131.59\n",
      "step4307 | loss: 0.002055781427770853 | dt: 321.41ms | tok/sec:  50975.13\n",
      "step4308 | loss: 0.001184732187539339 | dt: 320.68ms | tok/sec:  51090.69\n",
      "step4309 | loss: 0.0020333570428192616 | dt: 321.35ms | tok/sec:  50984.29\n",
      "step4310 | loss: 0.0017617999110370874 | dt: 320.42ms | tok/sec:  51132.85\n",
      "step4311 | loss: 0.0012268524151295424 | dt: 320.99ms | tok/sec:  51041.70\n",
      "step4312 | loss: 0.0021744088735431433 | dt: 320.85ms | tok/sec:  51064.30\n",
      "step4313 | loss: 0.0013769613578915596 | dt: 321.03ms | tok/sec:  51036.46\n",
      "step4314 | loss: 0.0008716989541426301 | dt: 321.29ms | tok/sec:  50994.39\n",
      "step4315 | loss: 0.0012206730898469687 | dt: 321.07ms | tok/sec:  51028.92\n",
      "step4316 | loss: 0.0011319757904857397 | dt: 320.97ms | tok/sec:  51044.80\n",
      "step4317 | loss: 0.001453968696296215 | dt: 320.84ms | tok/sec:  51065.36\n",
      "step4318 | loss: 0.0022786096669733524 | dt: 320.57ms | tok/sec:  51108.74\n",
      "step4319 | loss: 0.0013197960797697306 | dt: 320.06ms | tok/sec:  51190.40\n",
      "step4320 | loss: 0.0010109348222613335 | dt: 319.91ms | tok/sec:  51214.47\n",
      "step4321 | loss: 0.0013558149803429842 | dt: 320.93ms | tok/sec:  51052.12\n",
      "step4322 | loss: 0.0019796525593847036 | dt: 320.19ms | tok/sec:  51169.82\n",
      "step4323 | loss: 0.0015805286820977926 | dt: 321.13ms | tok/sec:  51019.15\n",
      "step4324 | loss: 0.0015060713049024343 | dt: 321.01ms | tok/sec:  51039.08\n",
      "step4325 | loss: 0.0015283511020243168 | dt: 321.00ms | tok/sec:  51039.99\n",
      "step4326 | loss: 0.00098373310174793 | dt: 320.27ms | tok/sec:  51156.64\n",
      "step4327 | loss: 0.0020546475425362587 | dt: 320.84ms | tok/sec:  51066.27\n",
      "step4328 | loss: 0.00119355961214751 | dt: 320.34ms | tok/sec:  51146.36\n",
      "step4329 | loss: 0.0020217825658619404 | dt: 320.65ms | tok/sec:  51095.93\n",
      "step4330 | loss: 0.0017699082382023335 | dt: 319.95ms | tok/sec:  51208.79\n",
      "step4331 | loss: 0.001217008102685213 | dt: 320.45ms | tok/sec:  51128.20\n",
      "step4332 | loss: 0.002165380399674177 | dt: 321.02ms | tok/sec:  51036.65\n",
      "step4333 | loss: 0.0014312195125967264 | dt: 320.55ms | tok/sec:  51111.81\n",
      "step4334 | loss: 0.0008263123454526067 | dt: 319.60ms | tok/sec:  51263.34\n",
      "step4335 | loss: 0.0012637104373425245 | dt: 321.42ms | tok/sec:  50973.89\n",
      "step4336 | loss: 0.0010273540392518044 | dt: 320.30ms | tok/sec:  51152.45\n",
      "step4337 | loss: 0.0014446824789047241 | dt: 321.02ms | tok/sec:  51037.26\n",
      "step4338 | loss: 0.0023174500092864037 | dt: 321.35ms | tok/sec:  50984.85\n",
      "step4339 | loss: 0.0013138290960341692 | dt: 320.82ms | tok/sec:  51068.74\n",
      "step4340 | loss: 0.0010275400709360838 | dt: 321.31ms | tok/sec:  50991.06\n",
      "step4341 | loss: 0.0013540649088099599 | dt: 321.38ms | tok/sec:  50980.43\n",
      "step4342 | loss: 0.0019524544477462769 | dt: 321.46ms | tok/sec:  50967.91\n",
      "step4343 | loss: 0.001571072731167078 | dt: 320.24ms | tok/sec:  51161.44\n",
      "step4344 | loss: 0.0015091215027496219 | dt: 320.80ms | tok/sec:  51072.38\n",
      "step4345 | loss: 0.0015327617293223739 | dt: 319.91ms | tok/sec:  51213.79\n",
      "step4346 | loss: 0.001003701938316226 | dt: 320.97ms | tok/sec:  51044.73\n",
      "step4347 | loss: 0.002038783859461546 | dt: 321.06ms | tok/sec:  51031.46\n",
      "step4348 | loss: 0.0011646377388387918 | dt: 320.83ms | tok/sec:  51067.00\n",
      "step4349 | loss: 0.002027431968599558 | dt: 321.28ms | tok/sec:  50995.83\n",
      "step4350 | loss: 0.0017572237411513925 | dt: 320.47ms | tok/sec:  51124.21\n",
      "step4351 | loss: 0.0012174791190773249 | dt: 320.87ms | tok/sec:  51060.58\n",
      "step4352 | loss: 0.002161972224712372 | dt: 321.14ms | tok/sec:  51018.54\n",
      "step4353 | loss: 0.001365245203487575 | dt: 321.25ms | tok/sec:  51000.78\n",
      "step4354 | loss: 0.0008573277154937387 | dt: 319.75ms | tok/sec:  51240.21\n",
      "step4355 | loss: 0.001215615775436163 | dt: 321.12ms | tok/sec:  51022.14\n",
      "step4356 | loss: 0.0011166955810040236 | dt: 320.30ms | tok/sec:  51152.49\n",
      "step4357 | loss: 0.0014361429493874311 | dt: 321.00ms | tok/sec:  51040.37\n",
      "step4358 | loss: 0.0022745151072740555 | dt: 321.23ms | tok/sec:  51004.49\n",
      "step4359 | loss: 0.0013141762465238571 | dt: 321.19ms | tok/sec:  51010.93\n",
      "step4360 | loss: 0.0009987738449126482 | dt: 319.88ms | tok/sec:  51219.21\n",
      "step4361 | loss: 0.0013490940909832716 | dt: 320.35ms | tok/sec:  51143.88\n",
      "step4362 | loss: 0.0019668168388307095 | dt: 320.01ms | tok/sec:  51198.87\n",
      "step4363 | loss: 0.0015674014575779438 | dt: 320.20ms | tok/sec:  51167.26\n",
      "step4364 | loss: 0.0014998699771240354 | dt: 320.85ms | tok/sec:  51063.92\n",
      "step4365 | loss: 0.001521417056210339 | dt: 321.05ms | tok/sec:  51033.02\n",
      "step4366 | loss: 0.0009721638634800911 | dt: 321.17ms | tok/sec:  51014.04\n",
      "step4367 | loss: 0.0020476102363318205 | dt: 320.80ms | tok/sec:  51071.97\n",
      "step4368 | loss: 0.0011831012088805437 | dt: 321.02ms | tok/sec:  51037.18\n",
      "step4369 | loss: 0.0020221425220370293 | dt: 321.13ms | tok/sec:  51019.94\n",
      "step4370 | loss: 0.0017617384437471628 | dt: 320.95ms | tok/sec:  51047.95\n",
      "step4371 | loss: 0.0012028353521600366 | dt: 320.98ms | tok/sec:  51043.06\n",
      "step4372 | loss: 0.0021556431893259287 | dt: 320.93ms | tok/sec:  51051.40\n",
      "step4373 | loss: 0.0014122198335826397 | dt: 321.07ms | tok/sec:  51029.60\n",
      "step4374 | loss: 0.0008188727078959346 | dt: 320.44ms | tok/sec:  51129.38\n",
      "step4375 | loss: 0.0012557159643620253 | dt: 320.59ms | tok/sec:  51105.12\n",
      "step4376 | loss: 0.0010193991474807262 | dt: 320.13ms | tok/sec:  51179.31\n",
      "step4377 | loss: 0.0014385689282789826 | dt: 320.96ms | tok/sec:  51046.85\n",
      "step4378 | loss: 0.0022999485954642296 | dt: 321.06ms | tok/sec:  51030.32\n",
      "step4379 | loss: 0.0012963840272277594 | dt: 320.89ms | tok/sec:  51058.23\n",
      "step4380 | loss: 0.001006274251267314 | dt: 320.47ms | tok/sec:  51124.71\n",
      "step4381 | loss: 0.0013436370063573122 | dt: 321.44ms | tok/sec:  50971.05\n",
      "step4382 | loss: 0.0019400669261813164 | dt: 319.69ms | tok/sec:  51250.38\n",
      "step4383 | loss: 0.0015558598097413778 | dt: 320.33ms | tok/sec:  51147.12\n",
      "step4384 | loss: 0.001489411573857069 | dt: 321.59ms | tok/sec:  50946.94\n",
      "step4385 | loss: 0.0015252727316692472 | dt: 320.75ms | tok/sec:  51080.77\n",
      "step4386 | loss: 0.000990370288491249 | dt: 320.96ms | tok/sec:  51046.97\n",
      "step4387 | loss: 0.0020287255756556988 | dt: 320.65ms | tok/sec:  51095.97\n",
      "step4388 | loss: 0.0011582435108721256 | dt: 320.36ms | tok/sec:  51141.90\n",
      "step4389 | loss: 0.0020133370999246836 | dt: 321.14ms | tok/sec:  51018.62\n",
      "step4390 | loss: 0.0017503498820587993 | dt: 320.27ms | tok/sec:  51157.47\n",
      "step4391 | loss: 0.0012086123460903764 | dt: 320.41ms | tok/sec:  51134.14\n",
      "step4392 | loss: 0.0021569353993982077 | dt: 320.27ms | tok/sec:  51156.67\n",
      "step4393 | loss: 0.0013537660706788301 | dt: 320.95ms | tok/sec:  51047.76\n",
      "step4394 | loss: 0.000855209247674793 | dt: 320.50ms | tok/sec:  51120.10\n",
      "step4395 | loss: 0.0012062243185937405 | dt: 320.98ms | tok/sec:  51043.48\n",
      "step4396 | loss: 0.001098828506655991 | dt: 320.45ms | tok/sec:  51128.13\n",
      "step4397 | loss: 0.0014295990113168955 | dt: 321.12ms | tok/sec:  51020.74\n",
      "step4398 | loss: 0.002268737182021141 | dt: 320.02ms | tok/sec:  51197.42\n",
      "step4399 | loss: 0.0013036576565355062 | dt: 320.77ms | tok/sec:  51076.71\n",
      "step4400 | loss: 0.000991154694929719 | dt: 321.02ms | tok/sec:  51037.79\n",
      "step4401 | loss: 0.0013348208740353584 | dt: 321.27ms | tok/sec:  50998.10\n",
      "step4402 | loss: 0.0019562782254070044 | dt: 320.50ms | tok/sec:  51120.60\n",
      "step4403 | loss: 0.0015520529123023152 | dt: 320.96ms | tok/sec:  51046.81\n",
      "step4404 | loss: 0.0014956991653889418 | dt: 320.33ms | tok/sec:  51146.97\n",
      "step4405 | loss: 0.0015111500397324562 | dt: 320.64ms | tok/sec:  51098.40\n",
      "step4406 | loss: 0.0009633684530854225 | dt: 320.35ms | tok/sec:  51143.50\n",
      "step4407 | loss: 0.0020296964794397354 | dt: 321.24ms | tok/sec:  51002.75\n",
      "step4408 | loss: 0.001180333667434752 | dt: 320.33ms | tok/sec:  51147.50\n",
      "step4409 | loss: 0.002009174320846796 | dt: 321.33ms | tok/sec:  50988.11\n",
      "step4410 | loss: 0.0017418573843315244 | dt: 321.00ms | tok/sec:  51040.22\n",
      "step4411 | loss: 0.0011931066401302814 | dt: 320.06ms | tok/sec:  51190.40\n",
      "step4412 | loss: 0.002141126897186041 | dt: 319.94ms | tok/sec:  51210.12\n",
      "step4413 | loss: 0.0014032421167939901 | dt: 321.25ms | tok/sec:  51000.67\n",
      "step4414 | loss: 0.0008049001917243004 | dt: 319.91ms | tok/sec:  51214.09\n",
      "step4415 | loss: 0.0012407067697495222 | dt: 321.10ms | tok/sec:  51024.53\n",
      "step4416 | loss: 0.0010120130609720945 | dt: 320.69ms | tok/sec:  51089.32\n",
      "step4417 | loss: 0.001428426941856742 | dt: 320.35ms | tok/sec:  51144.64\n",
      "step4418 | loss: 0.0022947369143366814 | dt: 321.13ms | tok/sec:  51020.59\n",
      "step4419 | loss: 0.0012877134140580893 | dt: 321.46ms | tok/sec:  50967.38\n",
      "step4420 | loss: 0.0009993993444368243 | dt: 320.44ms | tok/sec:  51129.88\n",
      "step4421 | loss: 0.001338906236924231 | dt: 320.13ms | tok/sec:  51179.08\n",
      "step4422 | loss: 0.0019326083129271865 | dt: 320.87ms | tok/sec:  51061.00\n",
      "step4423 | loss: 0.0015485381009057164 | dt: 321.21ms | tok/sec:  51007.48\n",
      "step4424 | loss: 0.0014812625013291836 | dt: 320.07ms | tok/sec:  51189.33\n",
      "step4425 | loss: 0.0015120137250050902 | dt: 320.87ms | tok/sec:  51060.66\n",
      "step4426 | loss: 0.000967701431363821 | dt: 320.88ms | tok/sec:  51059.67\n",
      "step4427 | loss: 0.0020204000174999237 | dt: 321.33ms | tok/sec:  50988.11\n",
      "step4428 | loss: 0.001149379531852901 | dt: 320.08ms | tok/sec:  51186.62\n",
      "step4429 | loss: 0.0020060199312865734 | dt: 321.32ms | tok/sec:  50989.96\n",
      "step4430 | loss: 0.0017472525360062718 | dt: 321.22ms | tok/sec:  51005.97\n",
      "step4431 | loss: 0.0011972622014582157 | dt: 321.28ms | tok/sec:  50996.20\n",
      "step4432 | loss: 0.002150612184777856 | dt: 320.28ms | tok/sec:  51155.46\n",
      "step4433 | loss: 0.0013494029408320785 | dt: 321.07ms | tok/sec:  51028.81\n",
      "step4434 | loss: 0.0008408036082983017 | dt: 320.21ms | tok/sec:  51166.73\n",
      "step4435 | loss: 0.001195811666548252 | dt: 321.10ms | tok/sec:  51024.41\n",
      "step4436 | loss: 0.00109380972571671 | dt: 319.83ms | tok/sec:  51227.80\n",
      "step4437 | loss: 0.0014261798933148384 | dt: 321.06ms | tok/sec:  51031.65\n",
      "step4438 | loss: 0.002258380874991417 | dt: 320.15ms | tok/sec:  51175.34\n",
      "step4439 | loss: 0.0012945239432156086 | dt: 321.18ms | tok/sec:  51011.76\n",
      "step4440 | loss: 0.0009902137098833919 | dt: 321.19ms | tok/sec:  51010.85\n",
      "step4441 | loss: 0.001326833851635456 | dt: 321.41ms | tok/sec:  50974.87\n",
      "step4442 | loss: 0.0019374017138034105 | dt: 319.97ms | tok/sec:  51205.24\n",
      "step4443 | loss: 0.0015527894720435143 | dt: 321.30ms | tok/sec:  50993.25\n",
      "step4444 | loss: 0.0014766479143872857 | dt: 320.34ms | tok/sec:  51146.28\n",
      "step4445 | loss: 0.0015030473005026579 | dt: 321.08ms | tok/sec:  51027.52\n",
      "step4446 | loss: 0.0009583901264704764 | dt: 320.06ms | tok/sec:  51190.82\n",
      "step4447 | loss: 0.0020276985596865416 | dt: 321.32ms | tok/sec:  50990.19\n",
      "step4448 | loss: 0.0011665660422295332 | dt: 320.13ms | tok/sec:  51179.31\n",
      "step4449 | loss: 0.001998737920075655 | dt: 321.30ms | tok/sec:  50992.95\n",
      "step4450 | loss: 0.001737360842525959 | dt: 321.30ms | tok/sec:  50993.48\n",
      "step4451 | loss: 0.0011842597741633654 | dt: 321.31ms | tok/sec:  50991.44\n",
      "step4452 | loss: 0.002128797583281994 | dt: 320.37ms | tok/sec:  51140.80\n",
      "step4453 | loss: 0.0013889236142858863 | dt: 321.48ms | tok/sec:  50963.64\n",
      "step4454 | loss: 0.0007958966889418662 | dt: 320.15ms | tok/sec:  51176.26\n",
      "step4455 | loss: 0.0012243186356499791 | dt: 321.11ms | tok/sec:  51023.81\n",
      "step4456 | loss: 0.0010042156791314483 | dt: 321.11ms | tok/sec:  51022.63\n",
      "step4457 | loss: 0.0014163879677653313 | dt: 321.04ms | tok/sec:  51034.91\n",
      "step4458 | loss: 0.0022972221486270428 | dt: 320.21ms | tok/sec:  51166.92\n",
      "step4459 | loss: 0.0012806893792003393 | dt: 320.96ms | tok/sec:  51046.51\n",
      "step4460 | loss: 0.0009878977434709668 | dt: 320.63ms | tok/sec:  51099.92\n",
      "step4461 | loss: 0.0013359044678509235 | dt: 320.28ms | tok/sec:  51155.95\n",
      "step4462 | loss: 0.001933388994075358 | dt: 321.61ms | tok/sec:  50943.39\n",
      "step4463 | loss: 0.001529030967503786 | dt: 321.67ms | tok/sec:  50934.90\n",
      "step4464 | loss: 0.0014699858147650957 | dt: 320.53ms | tok/sec:  51114.89\n",
      "step4465 | loss: 0.0015059270663186908 | dt: 321.18ms | tok/sec:  51011.61\n",
      "step4466 | loss: 0.0009584079962223768 | dt: 320.44ms | tok/sec:  51129.80\n",
      "step4467 | loss: 0.0020140372216701508 | dt: 321.05ms | tok/sec:  51031.84\n",
      "step4468 | loss: 0.001144698355346918 | dt: 321.10ms | tok/sec:  51024.60\n",
      "step4469 | loss: 0.00200243410654366 | dt: 321.69ms | tok/sec:  50930.37\n",
      "step4470 | loss: 0.001732709351927042 | dt: 321.17ms | tok/sec:  51012.75\n",
      "step4471 | loss: 0.0011878320947289467 | dt: 321.42ms | tok/sec:  50974.26\n",
      "step4472 | loss: 0.0021287163253873587 | dt: 320.48ms | tok/sec:  51123.98\n",
      "step4473 | loss: 0.001339366426691413 | dt: 320.33ms | tok/sec:  51147.42\n",
      "step4474 | loss: 0.000832679565064609 | dt: 320.31ms | tok/sec:  51151.00\n",
      "step4475 | loss: 0.001190003240481019 | dt: 321.18ms | tok/sec:  51011.31\n",
      "step4476 | loss: 0.0010874699801206589 | dt: 320.40ms | tok/sec:  51135.70\n",
      "step4477 | loss: 0.0014166373293846846 | dt: 321.13ms | tok/sec:  51019.72\n",
      "step4478 | loss: 0.0022357823327183723 | dt: 321.09ms | tok/sec:  51026.31\n",
      "step4479 | loss: 0.0012831039493903518 | dt: 321.39ms | tok/sec:  50978.58\n",
      "step4480 | loss: 0.0009781743865460157 | dt: 320.95ms | tok/sec:  51048.14\n",
      "step4481 | loss: 0.0013101242948323488 | dt: 321.14ms | tok/sec:  51018.62\n",
      "step4482 | loss: 0.0019228027667850256 | dt: 321.47ms | tok/sec:  50966.29\n",
      "step4483 | loss: 0.0015500412555411458 | dt: 321.26ms | tok/sec:  50999.35\n",
      "step4484 | loss: 0.001477264566347003 | dt: 321.03ms | tok/sec:  51035.86\n",
      "step4485 | loss: 0.001489587128162384 | dt: 321.32ms | tok/sec:  50988.94\n",
      "step4486 | loss: 0.0009518935112282634 | dt: 321.41ms | tok/sec:  50974.95\n",
      "step4487 | loss: 0.0020199655555188656 | dt: 320.71ms | tok/sec:  51086.43\n",
      "step4488 | loss: 0.0011544376611709595 | dt: 320.48ms | tok/sec:  51123.72\n",
      "step4489 | loss: 0.0019883618224412203 | dt: 321.23ms | tok/sec:  51004.19\n",
      "step4490 | loss: 0.0017284994246438146 | dt: 320.25ms | tok/sec:  51159.84\n",
      "step4491 | loss: 0.0011748941615223885 | dt: 320.95ms | tok/sec:  51049.17\n",
      "step4492 | loss: 0.002121144672855735 | dt: 320.11ms | tok/sec:  51182.89\n",
      "step4493 | loss: 0.0013842700282111764 | dt: 320.10ms | tok/sec:  51184.41\n",
      "step4494 | loss: 0.0007830939721316099 | dt: 320.86ms | tok/sec:  51062.40\n",
      "step4495 | loss: 0.0012231040745973587 | dt: 321.16ms | tok/sec:  51014.38\n",
      "step4496 | loss: 0.0009911071974784136 | dt: 319.87ms | tok/sec:  51221.23\n",
      "step4497 | loss: 0.0014081897679716349 | dt: 321.18ms | tok/sec:  51012.56\n",
      "step4498 | loss: 0.0022829845547676086 | dt: 320.09ms | tok/sec:  51186.05\n",
      "step4499 | loss: 0.0012721582315862179 | dt: 320.85ms | tok/sec:  51064.57\n",
      "Prediction at step 4500: \n",
      " : This is a fixed text used for prediction. uncle profity, leave\n",
      "Your Capitol, help \n",
      "\n",
      "step4500 | loss: 0.0009785769507288933 | dt: 318.90ms | tok/sec:  51376.40\n",
      "step4501 | loss: 0.0013266089372336864 | dt: 319.37ms | tok/sec:  51300.73\n",
      "step4502 | loss: 0.0019192062318325043 | dt: 321.27ms | tok/sec:  50998.17\n",
      "step4503 | loss: 0.0015229489654302597 | dt: 321.31ms | tok/sec:  50991.29\n",
      "step4504 | loss: 0.0014630330260843039 | dt: 320.85ms | tok/sec:  51064.83\n",
      "step4505 | loss: 0.001504264771938324 | dt: 319.86ms | tok/sec:  51221.76\n",
      "step4506 | loss: 0.0009524580673314631 | dt: 321.16ms | tok/sec:  51015.29\n",
      "step4507 | loss: 0.0020016469061374664 | dt: 321.27ms | tok/sec:  50997.34\n",
      "step4508 | loss: 0.0011318610049784184 | dt: 321.11ms | tok/sec:  51023.24\n",
      "step4509 | loss: 0.0019871823024004698 | dt: 321.17ms | tok/sec:  51014.15\n",
      "step4510 | loss: 0.0017225835472345352 | dt: 320.33ms | tok/sec:  51146.97\n",
      "step4511 | loss: 0.0011803526431322098 | dt: 321.08ms | tok/sec:  51028.13\n",
      "step4512 | loss: 0.002128660213202238 | dt: 321.23ms | tok/sec:  51003.93\n",
      "step4513 | loss: 0.0013285911409184337 | dt: 321.42ms | tok/sec:  50973.43\n",
      "step4514 | loss: 0.0008202997269108891 | dt: 320.25ms | tok/sec:  51159.57\n",
      "step4515 | loss: 0.0011684347409754992 | dt: 321.28ms | tok/sec:  50995.67\n",
      "step4516 | loss: 0.0010783758480101824 | dt: 320.62ms | tok/sec:  51101.21\n",
      "step4517 | loss: 0.0014171460643410683 | dt: 320.82ms | tok/sec:  51069.04\n",
      "step4518 | loss: 0.002231290563941002 | dt: 319.86ms | tok/sec:  51221.80\n",
      "step4519 | loss: 0.0012718485668301582 | dt: 321.45ms | tok/sec:  50968.93\n",
      "step4520 | loss: 0.0009676931658759713 | dt: 320.16ms | tok/sec:  51174.43\n",
      "step4521 | loss: 0.0013047871179878712 | dt: 321.05ms | tok/sec:  51032.71\n",
      "step4522 | loss: 0.0019171542953699827 | dt: 320.13ms | tok/sec:  51178.47\n",
      "step4523 | loss: 0.0015423779841512442 | dt: 321.19ms | tok/sec:  51010.93\n",
      "step4524 | loss: 0.0014640409499406815 | dt: 321.25ms | tok/sec:  51000.44\n",
      "step4525 | loss: 0.0014829227002337575 | dt: 321.21ms | tok/sec:  51006.35\n",
      "step4526 | loss: 0.0009367423481307924 | dt: 319.97ms | tok/sec:  51205.35\n",
      "step4527 | loss: 0.002010567346587777 | dt: 321.03ms | tok/sec:  51035.21\n",
      "step4528 | loss: 0.0011429113801568747 | dt: 319.85ms | tok/sec:  51223.83\n",
      "step4529 | loss: 0.0019773771055042744 | dt: 321.07ms | tok/sec:  51029.95\n",
      "step4530 | loss: 0.0017203211318701506 | dt: 320.00ms | tok/sec:  51199.25\n",
      "step4531 | loss: 0.0011664016637951136 | dt: 320.30ms | tok/sec:  51151.61\n",
      "step4532 | loss: 0.002107850043103099 | dt: 321.11ms | tok/sec:  51023.47\n",
      "step4533 | loss: 0.0013776689302176237 | dt: 320.78ms | tok/sec:  51074.78\n",
      "step4534 | loss: 0.0007758825668133795 | dt: 320.49ms | tok/sec:  51122.42\n",
      "step4535 | loss: 0.001213249284774065 | dt: 320.23ms | tok/sec:  51162.69\n",
      "step4536 | loss: 0.0009809561306610703 | dt: 320.93ms | tok/sec:  51051.93\n",
      "step4537 | loss: 0.0013965221587568521 | dt: 321.43ms | tok/sec:  50972.87\n",
      "step4538 | loss: 0.0022720126435160637 | dt: 321.47ms | tok/sec:  50965.38\n",
      "step4539 | loss: 0.001265128143131733 | dt: 321.22ms | tok/sec:  51005.25\n",
      "step4540 | loss: 0.0009758284431882203 | dt: 320.29ms | tok/sec:  51153.51\n",
      "step4541 | loss: 0.0013161443639546633 | dt: 321.33ms | tok/sec:  50988.41\n",
      "step4542 | loss: 0.0019021922489628196 | dt: 321.10ms | tok/sec:  51024.60\n",
      "step4543 | loss: 0.0015195328742265701 | dt: 321.17ms | tok/sec:  51013.05\n",
      "step4544 | loss: 0.0014554987428709865 | dt: 320.37ms | tok/sec:  51140.87\n",
      "step4545 | loss: 0.001494104857556522 | dt: 321.37ms | tok/sec:  50982.47\n",
      "step4546 | loss: 0.0009395782835781574 | dt: 321.43ms | tok/sec:  50972.90\n",
      "step4547 | loss: 0.001995739061385393 | dt: 321.10ms | tok/sec:  51024.38\n",
      "step4548 | loss: 0.0011243748012930155 | dt: 320.00ms | tok/sec:  51200.77\n",
      "step4549 | loss: 0.0019782776944339275 | dt: 321.20ms | tok/sec:  51009.11\n",
      "step4550 | loss: 0.0017195269465446472 | dt: 320.09ms | tok/sec:  51185.98\n",
      "step4551 | loss: 0.0011722794733941555 | dt: 320.10ms | tok/sec:  51183.77\n",
      "step4552 | loss: 0.002124588005244732 | dt: 320.80ms | tok/sec:  51072.38\n",
      "step4553 | loss: 0.0013229972682893276 | dt: 320.43ms | tok/sec:  51131.89\n",
      "step4554 | loss: 0.0008010214660316706 | dt: 320.06ms | tok/sec:  51190.78\n",
      "step4555 | loss: 0.0011627597268670797 | dt: 321.25ms | tok/sec:  51000.90\n",
      "step4556 | loss: 0.001064235344529152 | dt: 320.12ms | tok/sec:  51180.87\n",
      "step4557 | loss: 0.0014026244170963764 | dt: 321.17ms | tok/sec:  51013.96\n",
      "step4558 | loss: 0.00222798902541399 | dt: 320.12ms | tok/sec:  51180.91\n",
      "step4559 | loss: 0.0012628366239368916 | dt: 321.38ms | tok/sec:  50980.32\n",
      "step4560 | loss: 0.0009530029492452741 | dt: 319.78ms | tok/sec:  51235.02\n",
      "step4561 | loss: 0.0012918519787490368 | dt: 321.37ms | tok/sec:  50982.17\n",
      "step4562 | loss: 0.0019183310214430094 | dt: 320.73ms | tok/sec:  51082.67\n",
      "step4563 | loss: 0.0015264867106452584 | dt: 321.13ms | tok/sec:  51019.30\n",
      "step4564 | loss: 0.0014539978001266718 | dt: 321.20ms | tok/sec:  51009.30\n",
      "step4565 | loss: 0.0014703780179843307 | dt: 320.23ms | tok/sec:  51163.57\n",
      "step4566 | loss: 0.000928042340092361 | dt: 320.17ms | tok/sec:  51172.67\n",
      "step4567 | loss: 0.0019939050544053316 | dt: 321.26ms | tok/sec:  50999.69\n",
      "step4568 | loss: 0.0011350142303854227 | dt: 321.11ms | tok/sec:  51022.86\n",
      "step4569 | loss: 0.001974205020815134 | dt: 321.54ms | tok/sec:  50955.14\n",
      "step4570 | loss: 0.0017141606658697128 | dt: 320.57ms | tok/sec:  51108.51\n",
      "step4571 | loss: 0.0011556781828403473 | dt: 321.09ms | tok/sec:  51026.08\n",
      "step4572 | loss: 0.0020977247040718794 | dt: 320.59ms | tok/sec:  51105.12\n",
      "step4573 | loss: 0.0013638663804158568 | dt: 321.21ms | tok/sec:  51007.52\n",
      "step4574 | loss: 0.0007709850906394422 | dt: 319.87ms | tok/sec:  51221.27\n",
      "step4575 | loss: 0.00119822530541569 | dt: 321.25ms | tok/sec:  51000.25\n",
      "step4576 | loss: 0.0009710111189633608 | dt: 321.13ms | tok/sec:  51019.91\n",
      "step4577 | loss: 0.0013830892276018858 | dt: 320.81ms | tok/sec:  51071.17\n",
      "step4578 | loss: 0.002257097978144884 | dt: 319.98ms | tok/sec:  51203.06\n",
      "step4579 | loss: 0.001255139708518982 | dt: 321.28ms | tok/sec:  50996.51\n",
      "step4580 | loss: 0.0009616570314392447 | dt: 320.44ms | tok/sec:  51130.37\n",
      "step4581 | loss: 0.0013127113925293088 | dt: 321.38ms | tok/sec:  50980.69\n",
      "step4582 | loss: 0.0019001358887180686 | dt: 320.05ms | tok/sec:  51191.51\n",
      "step4583 | loss: 0.0015035760588943958 | dt: 321.32ms | tok/sec:  50989.92\n",
      "step4584 | loss: 0.0014393720775842667 | dt: 320.70ms | tok/sec:  51088.29\n",
      "step4585 | loss: 0.001477915095165372 | dt: 321.44ms | tok/sec:  50970.26\n",
      "step4586 | loss: 0.0009356006630696356 | dt: 321.43ms | tok/sec:  50972.68\n",
      "step4587 | loss: 0.001988759031519294 | dt: 321.47ms | tok/sec:  50966.48\n",
      "step4588 | loss: 0.0011089150793850422 | dt: 321.45ms | tok/sec:  50969.50\n",
      "step4589 | loss: 0.0019739146810024977 | dt: 321.19ms | tok/sec:  51009.57\n",
      "step4590 | loss: 0.0017099101096391678 | dt: 320.91ms | tok/sec:  51054.32\n",
      "step4591 | loss: 0.0011646291241049767 | dt: 320.70ms | tok/sec:  51087.99\n",
      "step4592 | loss: 0.002107648178935051 | dt: 321.07ms | tok/sec:  51029.45\n",
      "step4593 | loss: 0.0013141435338184237 | dt: 320.50ms | tok/sec:  51120.45\n",
      "step4594 | loss: 0.0007918826886452734 | dt: 321.42ms | tok/sec:  50973.43\n",
      "step4595 | loss: 0.001159464824013412 | dt: 321.40ms | tok/sec:  50976.72\n",
      "step4596 | loss: 0.0010586633579805493 | dt: 320.66ms | tok/sec:  51094.68\n",
      "step4597 | loss: 0.0013960867654532194 | dt: 321.74ms | tok/sec:  50922.89\n",
      "step4598 | loss: 0.00222032330930233 | dt: 320.08ms | tok/sec:  51186.59\n",
      "step4599 | loss: 0.001264526741579175 | dt: 321.21ms | tok/sec:  51007.86\n",
      "step4600 | loss: 0.0009510640520602465 | dt: 320.08ms | tok/sec:  51186.59\n",
      "step4601 | loss: 0.0012754187919199467 | dt: 321.38ms | tok/sec:  50979.45\n",
      "step4602 | loss: 0.0019057183526456356 | dt: 321.43ms | tok/sec:  50971.77\n",
      "step4603 | loss: 0.0015145993093028665 | dt: 321.20ms | tok/sec:  51009.00\n",
      "step4604 | loss: 0.001449566101655364 | dt: 321.36ms | tok/sec:  50983.15\n",
      "step4605 | loss: 0.0014662824105471373 | dt: 320.19ms | tok/sec:  51169.93\n",
      "step4606 | loss: 0.0009197650942951441 | dt: 321.22ms | tok/sec:  51006.12\n",
      "step4607 | loss: 0.0019919881597161293 | dt: 321.28ms | tok/sec:  50996.70\n",
      "step4608 | loss: 0.0011318258475512266 | dt: 320.19ms | tok/sec:  51169.63\n",
      "step4609 | loss: 0.0019640736281871796 | dt: 320.08ms | tok/sec:  51186.43\n",
      "step4610 | loss: 0.0017064039129763842 | dt: 320.15ms | tok/sec:  51176.22\n",
      "step4611 | loss: 0.001148212468251586 | dt: 321.21ms | tok/sec:  51006.77\n",
      "step4612 | loss: 0.002104528248310089 | dt: 320.75ms | tok/sec:  51080.77\n",
      "step4613 | loss: 0.0013560408260673285 | dt: 321.29ms | tok/sec:  50993.67\n",
      "step4614 | loss: 0.0007602803525514901 | dt: 320.18ms | tok/sec:  51170.88\n",
      "step4615 | loss: 0.0011963373981416225 | dt: 320.96ms | tok/sec:  51046.55\n",
      "step4616 | loss: 0.0009633433655835688 | dt: 321.29ms | tok/sec:  50994.80\n",
      "step4617 | loss: 0.0013890012633055449 | dt: 321.44ms | tok/sec:  50970.45\n",
      "step4618 | loss: 0.002252360340207815 | dt: 321.22ms | tok/sec:  51005.78\n",
      "step4619 | loss: 0.0012467065826058388 | dt: 321.30ms | tok/sec:  50993.29\n",
      "step4620 | loss: 0.0009452130761928856 | dt: 320.90ms | tok/sec:  51056.52\n",
      "step4621 | loss: 0.0013063224032521248 | dt: 321.37ms | tok/sec:  50981.41\n",
      "step4622 | loss: 0.0018946467898786068 | dt: 320.61ms | tok/sec:  51101.89\n",
      "step4623 | loss: 0.001503985607996583 | dt: 321.38ms | tok/sec:  50980.28\n",
      "step4624 | loss: 0.0014345655217766762 | dt: 320.65ms | tok/sec:  51096.99\n",
      "step4625 | loss: 0.0014782588696107268 | dt: 320.90ms | tok/sec:  51056.79\n",
      "step4626 | loss: 0.0009275396005250514 | dt: 320.33ms | tok/sec:  51147.27\n",
      "step4627 | loss: 0.0019839650485664606 | dt: 321.20ms | tok/sec:  51008.85\n",
      "step4628 | loss: 0.001110939891077578 | dt: 321.14ms | tok/sec:  51018.24\n",
      "step4629 | loss: 0.001975548453629017 | dt: 320.28ms | tok/sec:  51154.88\n",
      "step4630 | loss: 0.0016968360869213939 | dt: 321.36ms | tok/sec:  50982.58\n",
      "step4631 | loss: 0.0011579261627048254 | dt: 320.59ms | tok/sec:  51106.15\n",
      "step4632 | loss: 0.002099732868373394 | dt: 320.63ms | tok/sec:  51099.54\n",
      "step4633 | loss: 0.0013044996885582805 | dt: 321.20ms | tok/sec:  51008.70\n",
      "step4634 | loss: 0.0007860370678827167 | dt: 319.92ms | tok/sec:  51212.95\n",
      "step4635 | loss: 0.0011541616404429078 | dt: 321.26ms | tok/sec:  50998.74\n",
      "step4636 | loss: 0.0010514874011278152 | dt: 321.30ms | tok/sec:  50993.33\n",
      "step4637 | loss: 0.001384009956382215 | dt: 321.15ms | tok/sec:  51015.93\n",
      "step4638 | loss: 0.0022135600447654724 | dt: 320.93ms | tok/sec:  51050.99\n",
      "step4639 | loss: 0.0012527854414656758 | dt: 321.05ms | tok/sec:  51032.60\n",
      "step4640 | loss: 0.0009455738472752273 | dt: 321.38ms | tok/sec:  50979.48\n",
      "step4641 | loss: 0.0012717595091089606 | dt: 321.51ms | tok/sec:  50960.01\n",
      "step4642 | loss: 0.0018964618211612105 | dt: 320.79ms | tok/sec:  51073.86\n",
      "step4643 | loss: 0.0015152906998991966 | dt: 321.07ms | tok/sec:  51028.62\n",
      "step4644 | loss: 0.0014384894166141748 | dt: 320.50ms | tok/sec:  51120.71\n",
      "step4645 | loss: 0.001454717479646206 | dt: 321.14ms | tok/sec:  51018.47\n",
      "step4646 | loss: 0.0009092438849620521 | dt: 320.78ms | tok/sec:  51075.00\n",
      "step4647 | loss: 0.0019823038019239902 | dt: 321.27ms | tok/sec:  50997.11\n",
      "step4648 | loss: 0.0011201768647879362 | dt: 321.12ms | tok/sec:  51021.80\n",
      "step4649 | loss: 0.0019448173698037863 | dt: 321.73ms | tok/sec:  50924.59\n",
      "step4650 | loss: 0.0016944925300776958 | dt: 321.41ms | tok/sec:  50974.72\n",
      "step4651 | loss: 0.001140531268902123 | dt: 320.88ms | tok/sec:  51058.80\n",
      "step4652 | loss: 0.002089745830744505 | dt: 321.31ms | tok/sec:  50991.93\n",
      "step4653 | loss: 0.0013427964877337217 | dt: 320.85ms | tok/sec:  51064.64\n",
      "step4654 | loss: 0.0007548723369836807 | dt: 320.31ms | tok/sec:  51149.74\n",
      "step4655 | loss: 0.0011886247666552663 | dt: 320.93ms | tok/sec:  51051.10\n",
      "step4656 | loss: 0.0009550871327519417 | dt: 321.30ms | tok/sec:  50992.19\n",
      "step4657 | loss: 0.0013757047709077597 | dt: 321.44ms | tok/sec:  50970.60\n",
      "step4658 | loss: 0.0022455034777522087 | dt: 320.65ms | tok/sec:  51096.61\n",
      "step4659 | loss: 0.0012434368254616857 | dt: 320.14ms | tok/sec:  51178.09\n",
      "step4660 | loss: 0.0009378435206599534 | dt: 320.47ms | tok/sec:  51125.35\n",
      "step4661 | loss: 0.0013049509143456817 | dt: 321.21ms | tok/sec:  51007.03\n",
      "step4662 | loss: 0.0018887731712311506 | dt: 321.01ms | tok/sec:  51039.23\n",
      "step4663 | loss: 0.001491455128416419 | dt: 321.12ms | tok/sec:  51021.91\n",
      "step4664 | loss: 0.001432022312656045 | dt: 321.26ms | tok/sec:  50999.42\n",
      "step4665 | loss: 0.0014629828510805964 | dt: 321.01ms | tok/sec:  51039.61\n",
      "step4666 | loss: 0.000916928518563509 | dt: 320.85ms | tok/sec:  51064.60\n",
      "step4667 | loss: 0.001973602920770645 | dt: 320.99ms | tok/sec:  51041.73\n",
      "step4668 | loss: 0.001102876616641879 | dt: 320.64ms | tok/sec:  51098.21\n",
      "step4669 | loss: 0.001956075895577669 | dt: 320.95ms | tok/sec:  51047.76\n",
      "step4670 | loss: 0.0016923639923334122 | dt: 321.06ms | tok/sec:  51031.12\n",
      "step4671 | loss: 0.001147157046943903 | dt: 321.11ms | tok/sec:  51023.20\n",
      "step4672 | loss: 0.002087724395096302 | dt: 320.97ms | tok/sec:  51044.62\n",
      "step4673 | loss: 0.0013034793082624674 | dt: 321.27ms | tok/sec:  50997.04\n",
      "step4674 | loss: 0.0007763650501146913 | dt: 320.04ms | tok/sec:  51192.95\n",
      "step4675 | loss: 0.0011423892574384809 | dt: 321.28ms | tok/sec:  50995.33\n",
      "step4676 | loss: 0.0010471527930349112 | dt: 321.33ms | tok/sec:  50988.22\n",
      "step4677 | loss: 0.0013687186874449253 | dt: 320.12ms | tok/sec:  51180.94\n",
      "step4678 | loss: 0.0022026195656508207 | dt: 320.23ms | tok/sec:  51162.88\n",
      "step4679 | loss: 0.001244029146619141 | dt: 321.30ms | tok/sec:  50993.37\n",
      "step4680 | loss: 0.0009277776116505265 | dt: 320.74ms | tok/sec:  51082.29\n",
      "step4681 | loss: 0.0012650348944589496 | dt: 320.09ms | tok/sec:  51184.99\n",
      "step4682 | loss: 0.001881631906144321 | dt: 319.96ms | tok/sec:  51206.38\n",
      "step4683 | loss: 0.001507078530266881 | dt: 321.01ms | tok/sec:  51039.65\n",
      "step4684 | loss: 0.0014327173121273518 | dt: 320.24ms | tok/sec:  51161.55\n",
      "step4685 | loss: 0.0014433527830988169 | dt: 320.37ms | tok/sec:  51140.95\n",
      "step4686 | loss: 0.0009039657888934016 | dt: 320.78ms | tok/sec:  51076.03\n",
      "step4687 | loss: 0.0019791575614362955 | dt: 321.18ms | tok/sec:  51011.35\n",
      "step4688 | loss: 0.0011103349970653653 | dt: 320.35ms | tok/sec:  51143.50\n",
      "step4689 | loss: 0.0019402089528739452 | dt: 320.88ms | tok/sec:  51059.18\n",
      "step4690 | loss: 0.0016867552185431123 | dt: 321.11ms | tok/sec:  51023.01\n",
      "step4691 | loss: 0.001132352277636528 | dt: 321.49ms | tok/sec:  50963.23\n",
      "step4692 | loss: 0.002084291074424982 | dt: 320.74ms | tok/sec:  51082.26\n",
      "step4693 | loss: 0.0013284068554639816 | dt: 320.22ms | tok/sec:  51165.36\n",
      "step4694 | loss: 0.0007485850946977735 | dt: 320.65ms | tok/sec:  51095.70\n",
      "step4695 | loss: 0.0011882353574037552 | dt: 321.09ms | tok/sec:  51026.65\n",
      "step4696 | loss: 0.000949501758441329 | dt: 321.33ms | tok/sec:  50987.46\n",
      "step4697 | loss: 0.0013673007488250732 | dt: 321.16ms | tok/sec:  51015.13\n",
      "step4698 | loss: 0.0022370563820004463 | dt: 320.83ms | tok/sec:  51068.10\n",
      "step4699 | loss: 0.00123661570250988 | dt: 321.21ms | tok/sec:  51007.33\n",
      "step4700 | loss: 0.000928711611777544 | dt: 321.35ms | tok/sec:  50984.89\n",
      "step4701 | loss: 0.001303830649703741 | dt: 320.80ms | tok/sec:  51072.73\n",
      "step4702 | loss: 0.001870425883680582 | dt: 321.15ms | tok/sec:  51017.44\n",
      "step4703 | loss: 0.001482266467064619 | dt: 321.01ms | tok/sec:  51038.28\n",
      "step4704 | loss: 0.001431307871825993 | dt: 321.05ms | tok/sec:  51033.17\n",
      "step4705 | loss: 0.0014626700431108475 | dt: 321.27ms | tok/sec:  50997.38\n",
      "step4706 | loss: 0.0009069850784726441 | dt: 320.88ms | tok/sec:  51059.86\n",
      "step4707 | loss: 0.0019619115628302097 | dt: 321.19ms | tok/sec:  51010.29\n",
      "step4708 | loss: 0.0010915155289694667 | dt: 319.91ms | tok/sec:  51214.63\n",
      "step4709 | loss: 0.001946822740137577 | dt: 321.13ms | tok/sec:  51020.40\n",
      "step4710 | loss: 0.001682901754975319 | dt: 320.89ms | tok/sec:  51058.46\n",
      "step4711 | loss: 0.0011396754998713732 | dt: 321.48ms | tok/sec:  50964.13\n",
      "step4712 | loss: 0.002085648709908128 | dt: 319.99ms | tok/sec:  51201.54\n",
      "step4713 | loss: 0.0012925126357004046 | dt: 321.05ms | tok/sec:  51032.94\n",
      "step4714 | loss: 0.0007663338910788298 | dt: 320.08ms | tok/sec:  51186.55\n",
      "step4715 | loss: 0.0011290258262306452 | dt: 321.02ms | tok/sec:  51037.26\n",
      "step4716 | loss: 0.0010372777469456196 | dt: 320.47ms | tok/sec:  51124.86\n",
      "step4717 | loss: 0.0013678196119144559 | dt: 321.14ms | tok/sec:  51017.60\n",
      "step4718 | loss: 0.002194893779233098 | dt: 321.37ms | tok/sec:  50981.07\n",
      "step4719 | loss: 0.0012439851416274905 | dt: 321.18ms | tok/sec:  51011.84\n",
      "step4720 | loss: 0.0009283974068239331 | dt: 320.31ms | tok/sec:  51151.04\n",
      "step4721 | loss: 0.0012532337568700314 | dt: 320.82ms | tok/sec:  51069.73\n",
      "step4722 | loss: 0.00188338418956846 | dt: 320.43ms | tok/sec:  51131.17\n",
      "step4723 | loss: 0.0015034270472824574 | dt: 320.63ms | tok/sec:  51099.27\n",
      "step4724 | loss: 0.0014293647836893797 | dt: 320.27ms | tok/sec:  51156.06\n",
      "step4725 | loss: 0.0014336849562823772 | dt: 321.26ms | tok/sec:  50999.84\n",
      "step4726 | loss: 0.0008982157451100647 | dt: 320.04ms | tok/sec:  51194.14\n",
      "step4727 | loss: 0.001972061349079013 | dt: 321.02ms | tok/sec:  51038.09\n",
      "step4728 | loss: 0.001101270318031311 | dt: 320.48ms | tok/sec:  51124.02\n",
      "step4729 | loss: 0.0019440758042037487 | dt: 320.16ms | tok/sec:  51175.11\n",
      "step4730 | loss: 0.0016799786826595664 | dt: 320.01ms | tok/sec:  51198.68\n",
      "step4731 | loss: 0.0011304966174066067 | dt: 321.27ms | tok/sec:  50997.87\n",
      "step4732 | loss: 0.0020740688778460026 | dt: 321.07ms | tok/sec:  51030.10\n",
      "step4733 | loss: 0.0013284964952617884 | dt: 321.35ms | tok/sec:  50984.66\n",
      "step4734 | loss: 0.0007421161280944943 | dt: 320.55ms | tok/sec:  51111.55\n",
      "step4735 | loss: 0.0011816381011158228 | dt: 320.00ms | tok/sec:  51200.32\n",
      "step4736 | loss: 0.0009380884002894163 | dt: 320.78ms | tok/sec:  51075.80\n",
      "step4737 | loss: 0.0013585174456238747 | dt: 320.96ms | tok/sec:  51046.62\n",
      "step4738 | loss: 0.0022202390246093273 | dt: 320.94ms | tok/sec:  51050.08\n",
      "step4739 | loss: 0.0012260705698281527 | dt: 321.00ms | tok/sec:  51039.91\n",
      "step4740 | loss: 0.0009142583003267646 | dt: 320.30ms | tok/sec:  51151.42\n",
      "step4741 | loss: 0.0012929708464071155 | dt: 321.30ms | tok/sec:  50992.42\n",
      "step4742 | loss: 0.0018724545370787382 | dt: 320.48ms | tok/sec:  51122.69\n",
      "step4743 | loss: 0.0014691995456814766 | dt: 321.43ms | tok/sec:  50971.47\n",
      "step4744 | loss: 0.0014145848108455539 | dt: 320.85ms | tok/sec:  51064.38\n",
      "step4745 | loss: 0.0014542089775204659 | dt: 321.12ms | tok/sec:  51021.46\n",
      "step4746 | loss: 0.0008961882558651268 | dt: 320.23ms | tok/sec:  51162.77\n",
      "step4747 | loss: 0.0019493252038955688 | dt: 321.32ms | tok/sec:  50990.30\n",
      "step4748 | loss: 0.0010802396573126316 | dt: 321.17ms | tok/sec:  51013.69\n",
      "step4749 | loss: 0.0019345695618540049 | dt: 320.96ms | tok/sec:  51046.09\n",
      "step4750 | loss: 0.0016799126751720905 | dt: 320.49ms | tok/sec:  51122.12\n",
      "step4751 | loss: 0.0011314512230455875 | dt: 321.25ms | tok/sec:  51001.09\n",
      "step4752 | loss: 0.0020792202558368444 | dt: 319.69ms | tok/sec:  51249.11\n",
      "step4753 | loss: 0.0012830166378989816 | dt: 321.34ms | tok/sec:  50986.44\n",
      "step4754 | loss: 0.0007594833732582629 | dt: 320.50ms | tok/sec:  51120.64\n",
      "step4755 | loss: 0.0011264001950621605 | dt: 321.05ms | tok/sec:  51032.14\n",
      "step4756 | loss: 0.0010260463459417224 | dt: 321.29ms | tok/sec:  50995.15\n",
      "step4757 | loss: 0.001352294348180294 | dt: 321.37ms | tok/sec:  50981.87\n",
      "step4758 | loss: 0.002192846965044737 | dt: 320.06ms | tok/sec:  51189.79\n",
      "step4759 | loss: 0.0012333537451922894 | dt: 321.37ms | tok/sec:  50981.98\n",
      "step4760 | loss: 0.0009215424070134759 | dt: 321.44ms | tok/sec:  50969.95\n",
      "step4761 | loss: 0.0012443438172340393 | dt: 321.38ms | tok/sec:  50979.97\n",
      "step4762 | loss: 0.0018681975780054927 | dt: 321.35ms | tok/sec:  50985.01\n",
      "step4763 | loss: 0.0014981701970100403 | dt: 321.53ms | tok/sec:  50956.73\n",
      "step4764 | loss: 0.001418794272467494 | dt: 320.39ms | tok/sec:  51137.83\n",
      "step4765 | loss: 0.0014277928275987506 | dt: 321.11ms | tok/sec:  51023.09\n",
      "step4766 | loss: 0.0008933983626775444 | dt: 321.36ms | tok/sec:  50983.57\n",
      "step4767 | loss: 0.0019614440388977528 | dt: 320.72ms | tok/sec:  51085.71\n",
      "step4768 | loss: 0.0010929052950814366 | dt: 320.49ms | tok/sec:  51122.50\n",
      "step4769 | loss: 0.0019355935510247946 | dt: 321.57ms | tok/sec:  50950.30\n",
      "step4770 | loss: 0.001678655156865716 | dt: 320.32ms | tok/sec:  51149.40\n",
      "step4771 | loss: 0.001113617210648954 | dt: 321.29ms | tok/sec:  50993.82\n",
      "step4772 | loss: 0.00207437202334404 | dt: 320.42ms | tok/sec:  51132.88\n",
      "step4773 | loss: 0.0013181581161916256 | dt: 321.45ms | tok/sec:  50968.90\n",
      "step4774 | loss: 0.0007319669821299613 | dt: 320.58ms | tok/sec:  51107.86\n",
      "step4775 | loss: 0.001174406846985221 | dt: 321.47ms | tok/sec:  50966.63\n",
      "step4776 | loss: 0.0009372503263875842 | dt: 321.02ms | tok/sec:  51038.02\n",
      "step4777 | loss: 0.0013592676259577274 | dt: 321.26ms | tok/sec:  50999.95\n",
      "step4778 | loss: 0.002213954459875822 | dt: 321.13ms | tok/sec:  51019.41\n",
      "step4779 | loss: 0.0012143740896135569 | dt: 321.44ms | tok/sec:  50970.56\n",
      "step4780 | loss: 0.0009035791736096144 | dt: 320.21ms | tok/sec:  51166.35\n",
      "step4781 | loss: 0.0012894461397081614 | dt: 321.19ms | tok/sec:  51010.29\n",
      "step4782 | loss: 0.0018573172856122255 | dt: 321.17ms | tok/sec:  51013.73\n",
      "step4783 | loss: 0.0014558781404048204 | dt: 320.41ms | tok/sec:  51134.98\n",
      "step4784 | loss: 0.0014044083654880524 | dt: 320.37ms | tok/sec:  51140.95\n",
      "step4785 | loss: 0.0014497432857751846 | dt: 320.34ms | tok/sec:  51146.09\n",
      "step4786 | loss: 0.0008861677488312125 | dt: 320.71ms | tok/sec:  51087.31\n",
      "step4787 | loss: 0.001949226250872016 | dt: 321.21ms | tok/sec:  51006.73\n",
      "step4788 | loss: 0.001081337220966816 | dt: 320.64ms | tok/sec:  51097.60\n",
      "step4789 | loss: 0.0019389913650229573 | dt: 321.31ms | tok/sec:  50991.70\n",
      "step4790 | loss: 0.0016664178110659122 | dt: 320.66ms | tok/sec:  51094.64\n",
      "step4791 | loss: 0.0011320471530780196 | dt: 321.45ms | tok/sec:  50969.46\n",
      "step4792 | loss: 0.002067171037197113 | dt: 321.07ms | tok/sec:  51029.64\n",
      "step4793 | loss: 0.001284001860767603 | dt: 321.29ms | tok/sec:  50993.86\n",
      "step4794 | loss: 0.0007505194516852498 | dt: 320.52ms | tok/sec:  51116.45\n",
      "step4795 | loss: 0.0011152980150654912 | dt: 321.48ms | tok/sec:  50964.70\n",
      "step4796 | loss: 0.0010150903835892677 | dt: 321.16ms | tok/sec:  51015.36\n",
      "step4797 | loss: 0.0013480749912559986 | dt: 321.53ms | tok/sec:  50955.97\n",
      "step4798 | loss: 0.0021920360159128904 | dt: 321.04ms | tok/sec:  51034.72\n",
      "step4799 | loss: 0.0012282180832698941 | dt: 321.22ms | tok/sec:  51005.67\n",
      "step4800 | loss: 0.0009124753414653242 | dt: 320.64ms | tok/sec:  51098.25\n",
      "step4801 | loss: 0.0012417114339768887 | dt: 321.29ms | tok/sec:  50994.58\n",
      "step4802 | loss: 0.001868144841864705 | dt: 320.17ms | tok/sec:  51173.02\n",
      "step4803 | loss: 0.0014929866883903742 | dt: 321.15ms | tok/sec:  51017.37\n",
      "step4804 | loss: 0.001415240578353405 | dt: 320.14ms | tok/sec:  51177.89\n",
      "step4805 | loss: 0.001418777508661151 | dt: 321.11ms | tok/sec:  51023.13\n",
      "step4806 | loss: 0.0008825210970826447 | dt: 320.23ms | tok/sec:  51163.34\n",
      "step4807 | loss: 0.0019521232461556792 | dt: 321.28ms | tok/sec:  50995.71\n",
      "step4808 | loss: 0.0010828159283846617 | dt: 321.25ms | tok/sec:  51000.67\n",
      "step4809 | loss: 0.001928837038576603 | dt: 320.63ms | tok/sec:  51100.03\n",
      "step4810 | loss: 0.0016647586598992348 | dt: 320.39ms | tok/sec:  51137.91\n",
      "step4811 | loss: 0.0011096525704488158 | dt: 321.20ms | tok/sec:  51008.24\n",
      "step4812 | loss: 0.00205735070630908 | dt: 321.11ms | tok/sec:  51022.86\n",
      "step4813 | loss: 0.001304518198594451 | dt: 321.32ms | tok/sec:  50989.28\n",
      "step4814 | loss: 0.0007281886064447463 | dt: 320.99ms | tok/sec:  51042.57\n",
      "step4815 | loss: 0.0011627161875367165 | dt: 320.92ms | tok/sec:  51052.50\n",
      "step4816 | loss: 0.0009318585507571697 | dt: 320.24ms | tok/sec:  51161.21\n",
      "step4817 | loss: 0.0013515757163986564 | dt: 321.59ms | tok/sec:  50946.38\n",
      "step4818 | loss: 0.0022097057662904263 | dt: 320.99ms | tok/sec:  51041.70\n",
      "step4819 | loss: 0.0012108319206163287 | dt: 321.32ms | tok/sec:  50990.07\n",
      "step4820 | loss: 0.0008969290065579116 | dt: 319.96ms | tok/sec:  51206.69\n",
      "step4821 | loss: 0.0012785259168595076 | dt: 321.76ms | tok/sec:  50919.53\n",
      "step4822 | loss: 0.0018525240011513233 | dt: 320.88ms | tok/sec:  51059.94\n",
      "step4823 | loss: 0.0014570725616067648 | dt: 320.73ms | tok/sec:  51084.15\n",
      "step4824 | loss: 0.0014031893806532025 | dt: 320.72ms | tok/sec:  51085.26\n",
      "step4825 | loss: 0.001440884079784155 | dt: 321.40ms | tok/sec:  50977.14\n",
      "step4826 | loss: 0.0008791352156549692 | dt: 321.55ms | tok/sec:  50953.10\n",
      "step4827 | loss: 0.0019476981833577156 | dt: 321.55ms | tok/sec:  50953.82\n",
      "step4828 | loss: 0.00106908124871552 | dt: 320.05ms | tok/sec:  51191.24\n",
      "step4829 | loss: 0.0019329728092998266 | dt: 321.12ms | tok/sec:  51021.80\n",
      "step4830 | loss: 0.0016640624962747097 | dt: 320.37ms | tok/sec:  51140.91\n",
      "step4831 | loss: 0.0011294940486550331 | dt: 321.12ms | tok/sec:  51021.38\n",
      "step4832 | loss: 0.0020522410050034523 | dt: 321.30ms | tok/sec:  50992.95\n",
      "step4833 | loss: 0.0012774518691003323 | dt: 321.54ms | tok/sec:  50954.27\n",
      "step4834 | loss: 0.0007372237741947174 | dt: 320.00ms | tok/sec:  51199.97\n",
      "step4835 | loss: 0.0011087419698014855 | dt: 321.48ms | tok/sec:  50964.70\n",
      "step4836 | loss: 0.001003382494673133 | dt: 321.61ms | tok/sec:  50944.30\n",
      "step4837 | loss: 0.0013507327530533075 | dt: 321.37ms | tok/sec:  50981.56\n",
      "step4838 | loss: 0.002172379055991769 | dt: 320.61ms | tok/sec:  51102.27\n",
      "step4839 | loss: 0.0012223186204209924 | dt: 320.27ms | tok/sec:  51156.52\n",
      "step4840 | loss: 0.0009088818915188313 | dt: 320.42ms | tok/sec:  51133.42\n",
      "step4841 | loss: 0.0012310405727475882 | dt: 321.49ms | tok/sec:  50962.66\n",
      "step4842 | loss: 0.001849735388532281 | dt: 320.69ms | tok/sec:  51090.42\n",
      "step4843 | loss: 0.0014899137895554304 | dt: 321.86ms | tok/sec:  50904.79\n",
      "step4844 | loss: 0.001399018568918109 | dt: 320.68ms | tok/sec:  51091.22\n",
      "step4845 | loss: 0.0014026177814230323 | dt: 320.62ms | tok/sec:  51100.26\n",
      "step4846 | loss: 0.0008737149182707071 | dt: 320.54ms | tok/sec:  51113.41\n",
      "step4847 | loss: 0.001951113110408187 | dt: 321.45ms | tok/sec:  50969.05\n",
      "step4848 | loss: 0.0010853472631424665 | dt: 320.74ms | tok/sec:  51082.56\n",
      "step4849 | loss: 0.0019264372531324625 | dt: 321.42ms | tok/sec:  50974.19\n",
      "step4850 | loss: 0.0016610152088105679 | dt: 321.63ms | tok/sec:  50940.52\n",
      "step4851 | loss: 0.0010998493526130915 | dt: 321.45ms | tok/sec:  50969.61\n",
      "step4852 | loss: 0.002049428643658757 | dt: 320.15ms | tok/sec:  51175.84\n",
      "step4853 | loss: 0.0012943632900714874 | dt: 320.61ms | tok/sec:  51102.62\n",
      "step4854 | loss: 0.0007221914129331708 | dt: 320.03ms | tok/sec:  51195.62\n",
      "step4855 | loss: 0.0011562479194253683 | dt: 321.18ms | tok/sec:  51011.54\n",
      "step4856 | loss: 0.0009279222576878965 | dt: 320.40ms | tok/sec:  51135.93\n",
      "step4857 | loss: 0.0013454509899020195 | dt: 320.96ms | tok/sec:  51046.85\n",
      "step4858 | loss: 0.0022004100028425455 | dt: 320.81ms | tok/sec:  51070.98\n",
      "step4859 | loss: 0.0012096134014427662 | dt: 320.85ms | tok/sec:  51064.00\n",
      "step4860 | loss: 0.0008864050614647567 | dt: 320.15ms | tok/sec:  51176.07\n",
      "step4861 | loss: 0.0012717898935079575 | dt: 320.45ms | tok/sec:  51127.67\n",
      "step4862 | loss: 0.0018446501344442368 | dt: 320.59ms | tok/sec:  51105.24\n",
      "step4863 | loss: 0.0014503579586744308 | dt: 321.38ms | tok/sec:  50980.92\n",
      "step4864 | loss: 0.0013973347377032042 | dt: 320.83ms | tok/sec:  51068.25\n",
      "step4865 | loss: 0.0014380383072420955 | dt: 321.71ms | tok/sec:  50927.46\n",
      "step4866 | loss: 0.0008757476462051272 | dt: 320.16ms | tok/sec:  51174.12\n",
      "step4867 | loss: 0.001939364243298769 | dt: 321.07ms | tok/sec:  51029.76\n",
      "step4868 | loss: 0.001056315959431231 | dt: 320.27ms | tok/sec:  51157.47\n",
      "step4869 | loss: 0.0019198361551389098 | dt: 320.57ms | tok/sec:  51108.39\n",
      "step4870 | loss: 0.0016549988649785519 | dt: 321.65ms | tok/sec:  50938.10\n",
      "step4871 | loss: 0.0011202514870092273 | dt: 321.46ms | tok/sec:  50967.80\n",
      "step4872 | loss: 0.0020456919446587563 | dt: 320.28ms | tok/sec:  51155.00\n",
      "step4873 | loss: 0.0012680806685239077 | dt: 321.42ms | tok/sec:  50973.02\n",
      "step4874 | loss: 0.0007359615410678089 | dt: 321.44ms | tok/sec:  50971.20\n",
      "step4875 | loss: 0.0011008274741470814 | dt: 321.27ms | tok/sec:  50997.91\n",
      "step4876 | loss: 0.0010007102973759174 | dt: 320.26ms | tok/sec:  51158.31\n",
      "step4877 | loss: 0.0013335623079910874 | dt: 320.42ms | tok/sec:  51132.96\n",
      "step4878 | loss: 0.002162344753742218 | dt: 320.35ms | tok/sec:  51143.96\n",
      "step4879 | loss: 0.001216621370986104 | dt: 321.22ms | tok/sec:  51005.82\n",
      "step4880 | loss: 0.0008970341878011823 | dt: 320.07ms | tok/sec:  51189.06\n",
      "step4881 | loss: 0.0012258121278136969 | dt: 320.67ms | tok/sec:  51093.54\n",
      "step4882 | loss: 0.0018492109375074506 | dt: 320.73ms | tok/sec:  51083.85\n",
      "step4883 | loss: 0.001476990059018135 | dt: 320.37ms | tok/sec:  51140.84\n",
      "step4884 | loss: 0.0013973392779007554 | dt: 320.72ms | tok/sec:  51085.71\n",
      "step4885 | loss: 0.0014062232803553343 | dt: 321.60ms | tok/sec:  50944.64\n",
      "step4886 | loss: 0.0008636405691504478 | dt: 320.79ms | tok/sec:  51073.83\n",
      "step4887 | loss: 0.001946608885191381 | dt: 321.63ms | tok/sec:  50939.88\n",
      "step4888 | loss: 0.001080519170500338 | dt: 321.32ms | tok/sec:  50990.45\n",
      "step4889 | loss: 0.0019181985408067703 | dt: 320.75ms | tok/sec:  51080.39\n",
      "step4890 | loss: 0.001658181194216013 | dt: 320.66ms | tok/sec:  51094.30\n",
      "step4891 | loss: 0.001091525424271822 | dt: 321.53ms | tok/sec:  50956.58\n",
      "step4892 | loss: 0.0020465413108468056 | dt: 320.55ms | tok/sec:  51111.81\n",
      "step4893 | loss: 0.0012940769083797932 | dt: 321.21ms | tok/sec:  51006.88\n",
      "step4894 | loss: 0.0007158660446293652 | dt: 321.04ms | tok/sec:  51033.77\n",
      "step4895 | loss: 0.0011457887012511492 | dt: 321.26ms | tok/sec:  50998.59\n",
      "step4896 | loss: 0.0009217876940965652 | dt: 321.45ms | tok/sec:  50968.93\n",
      "step4897 | loss: 0.001336637418717146 | dt: 321.31ms | tok/sec:  50991.13\n",
      "step4898 | loss: 0.002199332695454359 | dt: 320.92ms | tok/sec:  51053.03\n",
      "step4899 | loss: 0.0012015968095511198 | dt: 321.62ms | tok/sec:  50942.83\n",
      "step4900 | loss: 0.0008821329101920128 | dt: 321.61ms | tok/sec:  50944.18\n",
      "step4901 | loss: 0.0012604400981217623 | dt: 321.38ms | tok/sec:  50980.13\n",
      "step4902 | loss: 0.001840690616518259 | dt: 321.71ms | tok/sec:  50928.48\n",
      "step4903 | loss: 0.0014480315148830414 | dt: 321.69ms | tok/sec:  50930.78\n",
      "step4904 | loss: 0.0013950790744274855 | dt: 320.62ms | tok/sec:  51100.34\n",
      "step4905 | loss: 0.0014296799199655652 | dt: 321.68ms | tok/sec:  50931.95\n",
      "step4906 | loss: 0.0008735168958082795 | dt: 321.56ms | tok/sec:  50950.83\n",
      "step4907 | loss: 0.0019303924636915326 | dt: 320.13ms | tok/sec:  51179.84\n",
      "step4908 | loss: 0.0010537549387663603 | dt: 320.78ms | tok/sec:  51075.04\n",
      "step4909 | loss: 0.001918902387842536 | dt: 321.39ms | tok/sec:  50979.18\n",
      "step4910 | loss: 0.0016553123714402318 | dt: 321.54ms | tok/sec:  50954.35\n",
      "step4911 | loss: 0.0011172278318554163 | dt: 321.31ms | tok/sec:  50990.60\n",
      "step4912 | loss: 0.0020419179927557707 | dt: 320.28ms | tok/sec:  51154.66\n",
      "step4913 | loss: 0.001256090821698308 | dt: 321.50ms | tok/sec:  50961.60\n",
      "step4914 | loss: 0.000719124567694962 | dt: 320.80ms | tok/sec:  51072.65\n",
      "step4915 | loss: 0.001094886101782322 | dt: 321.61ms | tok/sec:  50944.11\n",
      "step4916 | loss: 0.001000983640551567 | dt: 320.89ms | tok/sec:  51057.97\n",
      "step4917 | loss: 0.0013365847989916801 | dt: 321.24ms | tok/sec:  51002.30\n",
      "step4918 | loss: 0.002161805285140872 | dt: 321.31ms | tok/sec:  50991.59\n",
      "step4919 | loss: 0.0012064091861248016 | dt: 321.56ms | tok/sec:  50952.15\n",
      "step4920 | loss: 0.0008891976904124022 | dt: 321.66ms | tok/sec:  50936.37\n",
      "step4921 | loss: 0.0012275613844394684 | dt: 321.06ms | tok/sec:  51031.61\n",
      "step4922 | loss: 0.0018401581328362226 | dt: 321.19ms | tok/sec:  51011.01\n",
      "step4923 | loss: 0.0014679612359032035 | dt: 321.57ms | tok/sec:  50949.28\n",
      "step4924 | loss: 0.0013930617133155465 | dt: 320.10ms | tok/sec:  51183.77\n",
      "step4925 | loss: 0.0013929209671914577 | dt: 321.49ms | tok/sec:  50962.96\n",
      "step4926 | loss: 0.0008553555817343295 | dt: 320.14ms | tok/sec:  51177.59\n",
      "step4927 | loss: 0.0019274381920695305 | dt: 321.27ms | tok/sec:  50997.95\n",
      "step4928 | loss: 0.001070711761713028 | dt: 321.27ms | tok/sec:  50997.76\n",
      "step4929 | loss: 0.0019071006681770086 | dt: 321.59ms | tok/sec:  50947.62\n",
      "step4930 | loss: 0.0016509122215211391 | dt: 320.04ms | tok/sec:  51193.45\n",
      "step4931 | loss: 0.0010841736802831292 | dt: 320.88ms | tok/sec:  51059.79\n",
      "step4932 | loss: 0.0020407973788678646 | dt: 321.12ms | tok/sec:  51022.03\n",
      "step4933 | loss: 0.0012875532265752554 | dt: 321.28ms | tok/sec:  50995.45\n",
      "step4934 | loss: 0.0007054122979752719 | dt: 320.72ms | tok/sec:  51085.71\n",
      "step4935 | loss: 0.0011400111252442002 | dt: 321.27ms | tok/sec:  50998.32\n",
      "step4936 | loss: 0.0009109145030379295 | dt: 320.89ms | tok/sec:  51057.66\n",
      "step4937 | loss: 0.0013208654709160328 | dt: 321.83ms | tok/sec:  50908.37\n",
      "step4938 | loss: 0.002194807631894946 | dt: 320.66ms | tok/sec:  51094.26\n",
      "step4939 | loss: 0.0011887578293681145 | dt: 321.55ms | tok/sec:  50953.55\n",
      "step4940 | loss: 0.0008774824673309922 | dt: 320.91ms | tok/sec:  51054.82\n",
      "step4941 | loss: 0.001253993366844952 | dt: 321.03ms | tok/sec:  51035.48\n",
      "step4942 | loss: 0.0018314820481464267 | dt: 320.13ms | tok/sec:  51178.62\n",
      "step4943 | loss: 0.0014452915638685226 | dt: 321.68ms | tok/sec:  50932.78\n",
      "step4944 | loss: 0.001385582610964775 | dt: 320.13ms | tok/sec:  51178.85\n",
      "step4945 | loss: 0.0014231400564312935 | dt: 321.31ms | tok/sec:  50991.97\n",
      "step4946 | loss: 0.0008670265087857842 | dt: 320.78ms | tok/sec:  51075.54\n",
      "step4947 | loss: 0.001918494002893567 | dt: 320.53ms | tok/sec:  51115.81\n",
      "step4948 | loss: 0.0010441310005262494 | dt: 321.10ms | tok/sec:  51024.19\n",
      "step4949 | loss: 0.0019034342840313911 | dt: 321.67ms | tok/sec:  50934.03\n",
      "step4950 | loss: 0.0016472537536174059 | dt: 320.99ms | tok/sec:  51042.61\n",
      "step4951 | loss: 0.0011037832591682673 | dt: 321.20ms | tok/sec:  51008.01\n",
      "step4952 | loss: 0.002043049782514572 | dt: 320.30ms | tok/sec:  51151.95\n",
      "step4953 | loss: 0.0012562795309349895 | dt: 321.06ms | tok/sec:  51030.74\n",
      "step4954 | loss: 0.0007174437632784247 | dt: 321.72ms | tok/sec:  50925.72\n",
      "step4955 | loss: 0.0010889876866713166 | dt: 321.72ms | tok/sec:  50926.74\n",
      "step4956 | loss: 0.0010039655026048422 | dt: 320.73ms | tok/sec:  51083.66\n",
      "step4957 | loss: 0.0013251786585897207 | dt: 320.49ms | tok/sec:  51121.93\n",
      "step4958 | loss: 0.002158752642571926 | dt: 320.35ms | tok/sec:  51143.46\n",
      "step4959 | loss: 0.0012013079831376672 | dt: 320.98ms | tok/sec:  51044.43\n",
      "step4960 | loss: 0.0008768219850026071 | dt: 320.76ms | tok/sec:  51079.37\n",
      "step4961 | loss: 0.001219326164573431 | dt: 321.14ms | tok/sec:  51018.39\n",
      "step4962 | loss: 0.0018341363174840808 | dt: 321.43ms | tok/sec:  50972.22\n",
      "step4963 | loss: 0.001466394867748022 | dt: 321.29ms | tok/sec:  50995.07\n",
      "step4964 | loss: 0.0013767688069492579 | dt: 321.40ms | tok/sec:  50976.23\n",
      "step4965 | loss: 0.0013983601238578558 | dt: 322.08ms | tok/sec:  50869.29\n",
      "step4966 | loss: 0.0008548760670237243 | dt: 321.23ms | tok/sec:  51004.04\n",
      "step4967 | loss: 0.00191367301158607 | dt: 321.26ms | tok/sec:  50999.80\n",
      "step4968 | loss: 0.0010646533919498324 | dt: 321.69ms | tok/sec:  50931.76\n",
      "step4969 | loss: 0.0019012794364243746 | dt: 321.79ms | tok/sec:  50915.65\n",
      "step4970 | loss: 0.0016455084551125765 | dt: 320.21ms | tok/sec:  51165.66\n",
      "step4971 | loss: 0.001082696719095111 | dt: 321.21ms | tok/sec:  51007.86\n",
      "step4972 | loss: 0.002029336988925934 | dt: 320.48ms | tok/sec:  51124.10\n",
      "step4973 | loss: 0.0012869834899902344 | dt: 321.41ms | tok/sec:  50975.40\n",
      "step4974 | loss: 0.0006965730572119355 | dt: 320.66ms | tok/sec:  51095.24\n",
      "step4975 | loss: 0.001136296195909381 | dt: 320.84ms | tok/sec:  51066.24\n",
      "step4976 | loss: 0.0008981890860013664 | dt: 320.61ms | tok/sec:  51102.73\n",
      "step4977 | loss: 0.0013201121473684907 | dt: 321.83ms | tok/sec:  50908.11\n",
      "step4978 | loss: 0.0021846559830009937 | dt: 320.62ms | tok/sec:  51100.72\n",
      "step4979 | loss: 0.0011885648127645254 | dt: 321.74ms | tok/sec:  50923.08\n",
      "step4980 | loss: 0.0008754266891628504 | dt: 320.18ms | tok/sec:  51171.11\n",
      "step4981 | loss: 0.0012545892968773842 | dt: 322.17ms | tok/sec:  50855.51\n",
      "step4982 | loss: 0.001820719800889492 | dt: 321.25ms | tok/sec:  51000.25\n",
      "step4983 | loss: 0.001438595587387681 | dt: 321.43ms | tok/sec:  50972.41\n",
      "step4984 | loss: 0.0013775208499282598 | dt: 320.33ms | tok/sec:  51147.23\n",
      "step4985 | loss: 0.0014052358455955982 | dt: 321.83ms | tok/sec:  50909.01\n",
      "step4986 | loss: 0.0008552176877856255 | dt: 321.39ms | tok/sec:  50978.42\n",
      "step4987 | loss: 0.0019099212950095534 | dt: 321.54ms | tok/sec:  50955.40\n",
      "step4988 | loss: 0.0010363049805164337 | dt: 321.46ms | tok/sec:  50967.12\n",
      "step4989 | loss: 0.0018986264476552606 | dt: 321.18ms | tok/sec:  51012.33\n",
      "step4990 | loss: 0.0016384380869567394 | dt: 321.38ms | tok/sec:  50980.77\n",
      "step4991 | loss: 0.0010957757476717234 | dt: 320.38ms | tok/sec:  51138.67\n",
      "step4992 | loss: 0.0020430993754416704 | dt: 320.21ms | tok/sec:  51166.23\n",
      "step4993 | loss: 0.0012395738158375025 | dt: 321.26ms | tok/sec:  50998.82\n",
      "step4994 | loss: 0.0007172275800257921 | dt: 321.45ms | tok/sec:  50969.77\n",
      "step4995 | loss: 0.0010817935690283775 | dt: 320.42ms | tok/sec:  51132.62\n",
      "step4996 | loss: 0.0010054379235953093 | dt: 321.20ms | tok/sec:  51008.28\n",
      "step4997 | loss: 0.001319867791607976 | dt: 322.16ms | tok/sec:  50857.06\n",
      "step4998 | loss: 0.0021425699815154076 | dt: 320.76ms | tok/sec:  51078.04\n",
      "step4999 | loss: 0.0011943564750254154 | dt: 321.26ms | tok/sec:  50999.19\n",
      "Prediction at step 5000: \n",
      " : This is a fixed text used for prediction. mustWARD Bona, e' no power \n",
      "\n",
      "Checkpoint saved to llm_checkpoint.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53162/3629093597.py:351: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint. Resuming training for another 50 steps.\n",
      "Step 1 (After Resuming) | Loss: 0.0009 | dt: 323.67ms | tok/sec: 50619.70\n",
      "Step 2 (After Resuming) | Loss: 0.0012 | dt: 319.33ms | tok/sec: 51306.89\n",
      "Step 3 (After Resuming) | Loss: 0.0018 | dt: 319.47ms | tok/sec: 51284.15\n",
      "Step 4 (After Resuming) | Loss: 0.0015 | dt: 320.93ms | tok/sec: 51051.21\n",
      "Step 5 (After Resuming) | Loss: 0.0014 | dt: 319.73ms | tok/sec: 51242.77\n",
      "Step 6 (After Resuming) | Loss: 0.0014 | dt: 319.55ms | tok/sec: 51271.60\n",
      "Step 7 (After Resuming) | Loss: 0.0008 | dt: 321.50ms | tok/sec: 50960.54\n",
      "Step 8 (After Resuming) | Loss: 0.0019 | dt: 320.05ms | tok/sec: 51192.19\n",
      "Step 9 (After Resuming) | Loss: 0.0011 | dt: 319.64ms | tok/sec: 51257.91\n",
      "Step 10 (After Resuming) | Loss: 0.0019 | dt: 320.77ms | tok/sec: 51076.56\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<CompiledFunctionBackward>)\n"
     ]
    }
   ],
   "source": [
    "# POwer of 2\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import inspect\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANGPT_SCALE_INIT = 1\n",
    "        # regularization\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size)).view(1, 1, config.block_size, config.block_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        # nh is \"number of heads\", hs is \"head size\", and C (number of channels) = nh * hs\n",
    "        # e.g. in GPT-2 (124M), n_head=12, hs=64, so nh*hs=C=768 channels in the Transformer\n",
    "        qkv = self.c_attn(x)\n",
    "        q, k, v = qkv.split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "        # att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        # att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))\n",
    "        # att = F.softmax(att, dim=-1)\n",
    "        # y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "\n",
    "        y = F.scaled_dot_product_attention(q, k, v, is_causal = True) # Flash attention\n",
    "\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "        # output projection\n",
    "        y = self.c_proj(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd)\n",
    "        self.gelu    = nn.GELU(approximate='tanh')\n",
    "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    '''\n",
    "    block_size: int = 1024 # max sequence length\n",
    "    vocab_size: int = 50304 # number of tokens: 50,000 BPE merges + 256 bytes tokens + 1 <|endoftext|> token\n",
    "    n_layer: int = 12 # number of layers\n",
    "    n_head: int = 12 # number of heads\n",
    "    n_embd: int = 768 # embedding dimension\n",
    "\n",
    "    '''\n",
    "    block_size: int = 2048 # max sequence length\n",
    "    vocab_size: int = 49152 # number of tokens: 50,000 BPE merges + 256 bytes tokens + 1 <|endoftext|> token\n",
    "    n_layer: int = 30 # number of layers\n",
    "    n_head: int = 9 # number of heads\n",
    "    n_embd: int = 576 # embedding dimension\n",
    "    \n",
    "\n",
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = nn.LayerNorm(config.n_embd),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "        # weight sharing\n",
    "        self.transformer.wte.weight = self.lm_head.weight\n",
    "\n",
    "        # weight initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            std = 0.02\n",
    "            if hasattr(module, 'NANGPT_SCALE_INIT'):\n",
    "                std *= (2 * self.config.n_layer) ** -0.5\n",
    "            torch.nn.init.normal_(module.weight, mean = 0.0, std = std)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std = 0.02)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx is of shape (B, T)\n",
    "        B, T = idx.size()\n",
    "        assert T <= self.config.block_size, f\"Cannot forward sequence of length {T}, block size is only {self.config.block_size}\"\n",
    "        # forward the token and posisition embeddings\n",
    "        pos = torch.arange(0, T, dtype=torch.long, device=idx.device) # shape (T)\n",
    "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (T, n_embd)\n",
    "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (B, T, n_embd)\n",
    "        x = tok_emb + pos_emb\n",
    "        # forward the blocks of the transformer\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        # forward the final layernorm and the classifier\n",
    "        x = self.transformer.ln_f(x)\n",
    "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "        return logits, loss\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_type):\n",
    "        \"\"\"Loads pretrained GPT-2 model weights from huggingface\"\"\"\n",
    "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
    "\n",
    "        # n_layer, n_head and n_embd are determined from model_type\n",
    "        config_args = {\n",
    "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "        }[model_type]\n",
    "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
    "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
    "        # create a from-scratch initialized minGPT model\n",
    "        config = GPTConfig(**config_args)\n",
    "        model = GPT(config)\n",
    "        sd = model.state_dict()\n",
    "        sd_keys = sd.keys()\n",
    "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
    "\n",
    "        # init a huggingface/transformers model\n",
    "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
    "        sd_hf = model_hf.state_dict()\n",
    "\n",
    "        # copy while ensuring all of the parameters are aligned and match in names and shapes\n",
    "        sd_keys_hf = sd_hf.keys()\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
    "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "        # basically the openai checkpoints use a \"Conv1D\" module, but we only want to use a vanilla Linear\n",
    "        # this means that we have to transpose these weights when we import them\n",
    "        assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
    "        for k in sd_keys_hf:\n",
    "            if any(k.endswith(w) for w in transposed):\n",
    "                # special treatment for the Conv1D weights we need to transpose\n",
    "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k].t())\n",
    "            else:\n",
    "                # vanilla copy over the other parameters\n",
    "                assert sd_hf[k].shape == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Generate text given a starting token sequence.\n",
    "\n",
    "        Args:\n",
    "            idx (torch.Tensor): The starting sequence of shape (B, T).\n",
    "            max_new_tokens (int): The maximum number of new tokens to generate.\n",
    "            temperature (float): Sampling temperature (default 1.0).\n",
    "            top_k (int, optional): Top-k sampling for decoding (default None).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The generated token sequence of shape (B, T + max_new_tokens).\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Crop the context length to the block size\n",
    "            idx_cond = idx[:, -self.config.block_size:]\n",
    "            \n",
    "            # Get the logits and loss (ignore loss during generation)\n",
    "            logits, _ = self.forward(idx_cond)\n",
    "            \n",
    "            # Focus only on the last token's logits\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            \n",
    "            # Apply top-k sampling if specified\n",
    "            if top_k is not None:\n",
    "                values, _ = torch.topk(logits, k=top_k)\n",
    "                logits[logits < values[:, [-1]]] = -float('Inf')\n",
    "            \n",
    "            # Sample from the distribution\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            \n",
    "            # Append sampled token to the sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        \n",
    "        return idx\n",
    "\n",
    "# model = GPT.from_pretrained('gpt2')\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "# SEED\n",
    "torch.manual_seed(1337)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(1337)\n",
    "\n",
    "# STOP\n",
    "num_return_sequences = 5\n",
    "max_length = 30\n",
    "\n",
    "\n",
    "\n",
    "import tiktoken\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "\n",
    "class DataLoaderLite:\n",
    "    def __init__(self, B, T):\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "\n",
    "        # at init load tokens from disk and store them in memory\n",
    "        with open('input.txt', 'r') as f:\n",
    "            text = f.read()\n",
    "        #enc = tiktoken.get_encoding('gpt2')\n",
    "        # Load the HuggingFace tokenizer\n",
    "        enc = AutoTokenizer.from_pretrained(\"HuggingFaceTB/cosmo2-tokenizer\")\n",
    "        tokens = enc.encode(text)\n",
    "        self.tokens = torch.tensor(tokens)\n",
    "        print(f'loaded {len(self.tokens)} tokens')\n",
    "        print(f'1 epoch = {len(self.tokens) // (B * T)} batches')\n",
    "\n",
    "        # state\n",
    "        self.current_position = 0\n",
    "    \n",
    "    def next_batch(self):\n",
    "        B, T = self.B, self.T\n",
    "        buf = self.tokens[self.current_position: self.current_position + B * T + 1]\n",
    "        x = (buf[:-1]).view(B, T) # inputs\n",
    "        y = (buf[1:]).view(B, T) # targets\n",
    "        # advance the position in the tensor\n",
    "        self.current_position += B*T\n",
    "        # if loading the next batch would be out of bounds, reset\n",
    "        if self.current_position + (B * T + 1) > len(self.tokens):\n",
    "            self.current_position = 0\n",
    "        return x, y\n",
    "\n",
    "# CHANGES IN CURRENT CODE\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "model = GPT(GPTConfig())\n",
    "model.to(device)\n",
    "model = torch.compile(model)\n",
    "\n",
    "train_loader = DataLoaderLite(B = 16, T = 1024)\n",
    "\n",
    "# NEW CODE\n",
    "import time\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 3e-4)\n",
    "\n",
    "# Define the fixed text for prediction\n",
    "fixed_text = \"This is a fixed text used for prediction.\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/cosmo2-tokenizer\")\n",
    "encoded_text = tokenizer(fixed_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Training loop\n",
    "total_steps = 5000\n",
    "prediction_interval = 500\n",
    "checkpoint_path = \"llm_checkpoint.pt\"\n",
    "\n",
    "for step in range(total_steps):\n",
    "    t0 = time.time()\n",
    "    x, y = train_loader.next_batch()\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    # NEW CODE ADDED HERE\n",
    "    with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "        logits, loss = model(x, y) \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    torch.cuda.synchronize() \n",
    "    t1 = time.time()\n",
    "    dt = (t1 - t0) * 1000\n",
    "    tokens_per_sec = (train_loader.B * train_loader.T) / (t1 - t0)\n",
    "    print(f'step{step} | loss: {loss.item()} | dt: {dt:.2f}ms | tok/sec: {tokens_per_sec: .2f}')\n",
    "    \n",
    "    # Perform prediction every 500 steps\n",
    "    if (step + 1) % prediction_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            \n",
    "            max_new_tokens = 10\n",
    "            temperature = 1.0\n",
    "            top_k = 40\n",
    "            \n",
    "            prediction_logits = model.generate(encoded_text[\"input_ids\"], max_new_tokens=max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "            prediction = tokenizer.decode(prediction_logits[0], skip_special_tokens=True)\n",
    "            print(f\"Prediction at step {step+1}: \\n : {prediction} \\n\")\n",
    "            model.train()\n",
    "\n",
    "# Save checkpoint after 5000 steps\n",
    "torch.save({\"model_state_dict\": model.state_dict(), \"optimizer_state_dict\": optimizer.state_dict()}, checkpoint_path)\n",
    "print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "# Load checkpoint and train for another 50 steps\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "print(\"Loaded checkpoint. Resuming training for another 50 steps.\")\n",
    "\n",
    "for step in range(10):\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Training batch\n",
    "    x, y = train_loader.next_batch()\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "        logits, loss = model(x, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    t1 = time.time()\n",
    "    dt = (t1 - t0) * 1000  # Time in milliseconds\n",
    "    tokens_per_sec = (train_loader.B * train_loader.T) / (t1 - t0)\n",
    "\n",
    "    print(f\"Step {step+1} (After Resuming) | Loss: {loss.item():.4f} | dt: {dt:.2f}ms | tok/sec: {tokens_per_sec:.2f}\")\n",
    "    \n",
    "print(loss)\n",
    "\n",
    "# step13 | loss: 7.214234352111816 | dt: 2418.43ms | tok/sec:  3387.32\n",
    "# step13 | loss: 7.214259624481201 | dt: 1337.68ms | tok/sec:  6124.05\n",
    "# step13 | loss: 7.330005645751953 | dt: 978.19ms | tok/sec:  8374.65\n",
    "# step13 | loss: 7.012979507446289 | dt: 1032.97ms | tok/sec:  15861.12\n",
    "# step13 | loss: 6.9644927978515625 | dt: 1004.06ms | tok/sec:  16317.75\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n",
      "loaded 341094 tokens\n",
      "1 epoch = 20 batches\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import inspect\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import tiktoken\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import inspect\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANGPT_SCALE_INIT = 1\n",
    "        # regularization\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size)).view(1, 1, config.block_size, config.block_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        # nh is \"number of heads\", hs is \"head size\", and C (number of channels) = nh * hs\n",
    "        # e.g. in GPT-2 (124M), n_head=12, hs=64, so nh*hs=C=768 channels in the Transformer\n",
    "        qkv = self.c_attn(x)\n",
    "        q, k, v = qkv.split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "        # att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        # att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))\n",
    "        # att = F.softmax(att, dim=-1)\n",
    "        # y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "\n",
    "        y = F.scaled_dot_product_attention(q, k, v, is_causal = True) # Flash attention\n",
    "\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "        # output projection\n",
    "        y = self.c_proj(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd)\n",
    "        self.gelu    = nn.GELU(approximate='tanh')\n",
    "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    '''\n",
    "    block_size: int = 1024 # max sequence length\n",
    "    vocab_size: int = 50304 # number of tokens: 50,000 BPE merges + 256 bytes tokens + 1 <|endoftext|> token\n",
    "    n_layer: int = 12 # number of layers\n",
    "    n_head: int = 12 # number of heads\n",
    "    n_embd: int = 768 # embedding dimension\n",
    "\n",
    "    '''\n",
    "    block_size: int = 2048 # max sequence length\n",
    "    vocab_size: int = 49152 # number of tokens: 50,000 BPE merges + 256 bytes tokens + 1 <|endoftext|> token\n",
    "    n_layer: int = 30 # number of layers\n",
    "    n_head: int = 9 # number of heads\n",
    "    n_embd: int = 576 # embedding dimension\n",
    "    \n",
    "\n",
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = nn.LayerNorm(config.n_embd),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "        # weight sharing\n",
    "        self.transformer.wte.weight = self.lm_head.weight\n",
    "\n",
    "        # weight initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            std = 0.02\n",
    "            if hasattr(module, 'NANGPT_SCALE_INIT'):\n",
    "                std *= (2 * self.config.n_layer) ** -0.5\n",
    "            torch.nn.init.normal_(module.weight, mean = 0.0, std = std)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std = 0.02)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx is of shape (B, T)\n",
    "        B, T = idx.size()\n",
    "        assert T <= self.config.block_size, f\"Cannot forward sequence of length {T}, block size is only {self.config.block_size}\"\n",
    "        # forward the token and posisition embeddings\n",
    "        pos = torch.arange(0, T, dtype=torch.long, device=idx.device) # shape (T)\n",
    "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (T, n_embd)\n",
    "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (B, T, n_embd)\n",
    "        x = tok_emb + pos_emb\n",
    "        # forward the blocks of the transformer\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        # forward the final layernorm and the classifier\n",
    "        x = self.transformer.ln_f(x)\n",
    "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "        return logits, loss\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_type):\n",
    "        \"\"\"Loads pretrained GPT-2 model weights from huggingface\"\"\"\n",
    "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
    "\n",
    "        # n_layer, n_head and n_embd are determined from model_type\n",
    "        config_args = {\n",
    "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "        }[model_type]\n",
    "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
    "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
    "        # create a from-scratch initialized minGPT model\n",
    "        config = GPTConfig(**config_args)\n",
    "        model = GPT(config)\n",
    "        sd = model.state_dict()\n",
    "        sd_keys = sd.keys()\n",
    "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
    "\n",
    "        # init a huggingface/transformers model\n",
    "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
    "        sd_hf = model_hf.state_dict()\n",
    "\n",
    "        # copy while ensuring all of the parameters are aligned and match in names and shapes\n",
    "        sd_keys_hf = sd_hf.keys()\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
    "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "        # basically the openai checkpoints use a \"Conv1D\" module, but we only want to use a vanilla Linear\n",
    "        # this means that we have to transpose these weights when we import them\n",
    "        assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
    "        for k in sd_keys_hf:\n",
    "            if any(k.endswith(w) for w in transposed):\n",
    "                # special treatment for the Conv1D weights we need to transpose\n",
    "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k].t())\n",
    "            else:\n",
    "                # vanilla copy over the other parameters\n",
    "                assert sd_hf[k].shape == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Generate text given a starting token sequence.\n",
    "\n",
    "        Args:\n",
    "            idx (torch.Tensor): The starting sequence of shape (B, T).\n",
    "            max_new_tokens (int): The maximum number of new tokens to generate.\n",
    "            temperature (float): Sampling temperature (default 1.0).\n",
    "            top_k (int, optional): Top-k sampling for decoding (default None).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The generated token sequence of shape (B, T + max_new_tokens).\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Crop the context length to the block size\n",
    "            idx_cond = idx[:, -self.config.block_size:]\n",
    "            \n",
    "            # Get the logits and loss (ignore loss during generation)\n",
    "            logits, _ = self.forward(idx_cond)\n",
    "            \n",
    "            # Focus only on the last token's logits\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            \n",
    "            # Apply top-k sampling if specified\n",
    "            if top_k is not None:\n",
    "                values, _ = torch.topk(logits, k=top_k)\n",
    "                logits[logits < values[:, [-1]]] = -float('Inf')\n",
    "            \n",
    "            # Sample from the distribution\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            \n",
    "            # Append sampled token to the sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        \n",
    "        return idx\n",
    "    \n",
    "    \n",
    "class DataLoaderLite:\n",
    "    def __init__(self, B, T):\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "\n",
    "        # at init load tokens from disk and store them in memory\n",
    "        with open('input.txt', 'r') as f:\n",
    "            text = f.read()\n",
    "        #enc = tiktoken.get_encoding('gpt2')\n",
    "        # Load the HuggingFace tokenizer\n",
    "        enc = AutoTokenizer.from_pretrained(\"HuggingFaceTB/cosmo2-tokenizer\")\n",
    "        tokens = enc.encode(text)\n",
    "        self.tokens = torch.tensor(tokens)\n",
    "        print(f'loaded {len(self.tokens)} tokens')\n",
    "        print(f'1 epoch = {len(self.tokens) // (B * T)} batches')\n",
    "\n",
    "        # state\n",
    "        self.current_position = 0\n",
    "    \n",
    "    def next_batch(self):\n",
    "        B, T = self.B, self.T\n",
    "        buf = self.tokens[self.current_position: self.current_position + B * T + 1]\n",
    "        x = (buf[:-1]).view(B, T) # inputs\n",
    "        y = (buf[1:]).view(B, T) # targets\n",
    "        # advance the position in the tensor\n",
    "        self.current_position += B*T\n",
    "        # if loading the next batch would be out of bounds, reset\n",
    "        if self.current_position + (B * T + 1) > len(self.tokens):\n",
    "            self.current_position = 0\n",
    "        return x, y\n",
    "\n",
    "# model = GPT.from_pretrained('gpt2')\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "# SEED\n",
    "torch.manual_seed(1337)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(1337)\n",
    "\n",
    "# STOP\n",
    "num_return_sequences = 5\n",
    "max_length = 30\n",
    "\n",
    "# CHANGES IN CURRENT CODE\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "model = GPT(GPTConfig())\n",
    "model.to(device)\n",
    "model = torch.compile(model)\n",
    "\n",
    "train_loader = DataLoaderLite(B = 16, T = 1024)\n",
    "\n",
    "# NEW CODE\n",
    "import time\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 3e-4)\n",
    "\n",
    "# Define the fixed text for prediction\n",
    "fixed_text = \"This is a fixed text used for prediction.\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/cosmo2-tokenizer\")\n",
    "encoded_text = tokenizer(fixed_text, return_tensors=\"pt\").to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58979/4093890313.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint. Resuming training for another 50 steps.\n",
      "Step 1 (After Resuming) | Loss: 0.0009 | dt: 16370.94ms | tok/sec: 1000.80\n",
      "Step 2 (After Resuming) | Loss: 0.0012 | dt: 319.25ms | tok/sec: 51320.92\n",
      "Step 3 (After Resuming) | Loss: 0.0018 | dt: 319.91ms | tok/sec: 51213.98\n",
      "Step 4 (After Resuming) | Loss: 0.0015 | dt: 319.88ms | tok/sec: 51219.93\n",
      "Step 5 (After Resuming) | Loss: 0.0014 | dt: 318.59ms | tok/sec: 51426.07\n",
      "Step 6 (After Resuming) | Loss: 0.0014 | dt: 318.52ms | tok/sec: 51438.54\n",
      "Step 7 (After Resuming) | Loss: 0.0008 | dt: 319.90ms | tok/sec: 51215.92\n",
      "Step 8 (After Resuming) | Loss: 0.0019 | dt: 318.30ms | tok/sec: 51473.84\n",
      "Step 9 (After Resuming) | Loss: 0.0011 | dt: 318.59ms | tok/sec: 51426.53\n",
      "Step 10 (After Resuming) | Loss: 0.0019 | dt: 319.11ms | tok/sec: 51343.08\n",
      "Step 11 (After Resuming) | Loss: 0.0016 | dt: 319.89ms | tok/sec: 51216.95\n",
      "Step 12 (After Resuming) | Loss: 0.0011 | dt: 319.08ms | tok/sec: 51346.84\n",
      "Step 13 (After Resuming) | Loss: 0.0020 | dt: 319.76ms | tok/sec: 51237.80\n",
      "Step 14 (After Resuming) | Loss: 0.0013 | dt: 319.90ms | tok/sec: 51215.24\n",
      "Step 15 (After Resuming) | Loss: 0.0007 | dt: 318.99ms | tok/sec: 51361.35\n",
      "Step 16 (After Resuming) | Loss: 0.0011 | dt: 320.14ms | tok/sec: 51177.02\n",
      "Step 17 (After Resuming) | Loss: 0.0009 | dt: 319.92ms | tok/sec: 51212.98\n",
      "Step 18 (After Resuming) | Loss: 0.0013 | dt: 320.11ms | tok/sec: 51182.77\n",
      "Step 19 (After Resuming) | Loss: 0.0022 | dt: 320.01ms | tok/sec: 51198.87\n",
      "Step 20 (After Resuming) | Loss: 0.0012 | dt: 319.11ms | tok/sec: 51343.42\n",
      "Step 21 (After Resuming) | Loss: 0.0009 | dt: 319.58ms | tok/sec: 51268.08\n",
      "Step 22 (After Resuming) | Loss: 0.0012 | dt: 319.89ms | tok/sec: 51217.72\n",
      "Step 23 (After Resuming) | Loss: 0.0018 | dt: 320.34ms | tok/sec: 51146.05\n",
      "Step 24 (After Resuming) | Loss: 0.0014 | dt: 319.15ms | tok/sec: 51335.79\n",
      "Step 25 (After Resuming) | Loss: 0.0014 | dt: 319.59ms | tok/sec: 51265.86\n",
      "Step 26 (After Resuming) | Loss: 0.0014 | dt: 320.31ms | tok/sec: 51151.11\n",
      "Step 27 (After Resuming) | Loss: 0.0009 | dt: 319.38ms | tok/sec: 51299.58\n",
      "Step 28 (After Resuming) | Loss: 0.0019 | dt: 320.85ms | tok/sec: 51064.79\n",
      "Step 29 (After Resuming) | Loss: 0.0010 | dt: 320.49ms | tok/sec: 51121.40\n",
      "Step 30 (After Resuming) | Loss: 0.0019 | dt: 321.55ms | tok/sec: 50953.29\n",
      "Step 31 (After Resuming) | Loss: 0.0016 | dt: 320.15ms | tok/sec: 51176.07\n",
      "Step 32 (After Resuming) | Loss: 0.0011 | dt: 321.20ms | tok/sec: 51009.11\n",
      "Step 33 (After Resuming) | Loss: 0.0020 | dt: 320.50ms | tok/sec: 51120.48\n",
      "Step 34 (After Resuming) | Loss: 0.0012 | dt: 320.38ms | tok/sec: 51138.71\n",
      "Step 35 (After Resuming) | Loss: 0.0007 | dt: 320.91ms | tok/sec: 51054.63\n",
      "Step 36 (After Resuming) | Loss: 0.0011 | dt: 321.34ms | tok/sec: 50986.18\n",
      "Step 37 (After Resuming) | Loss: 0.0010 | dt: 320.37ms | tok/sec: 51140.84\n",
      "Step 38 (After Resuming) | Loss: 0.0013 | dt: 320.54ms | tok/sec: 51113.56\n",
      "Step 39 (After Resuming) | Loss: 0.0021 | dt: 320.27ms | tok/sec: 51156.06\n",
      "Step 40 (After Resuming) | Loss: 0.0012 | dt: 321.26ms | tok/sec: 50999.50\n",
      "Step 41 (After Resuming) | Loss: 0.0009 | dt: 320.24ms | tok/sec: 51162.01\n",
      "Step 42 (After Resuming) | Loss: 0.0012 | dt: 320.37ms | tok/sec: 51140.19\n",
      "Step 43 (After Resuming) | Loss: 0.0018 | dt: 320.56ms | tok/sec: 51111.28\n",
      "Step 44 (After Resuming) | Loss: 0.0015 | dt: 320.96ms | tok/sec: 51046.44\n",
      "Step 45 (After Resuming) | Loss: 0.0014 | dt: 320.31ms | tok/sec: 51150.77\n",
      "Step 46 (After Resuming) | Loss: 0.0014 | dt: 321.01ms | tok/sec: 51038.17\n",
      "Step 47 (After Resuming) | Loss: 0.0008 | dt: 321.68ms | tok/sec: 50932.10\n",
      "Step 48 (After Resuming) | Loss: 0.0019 | dt: 321.15ms | tok/sec: 51015.93\n",
      "Step 49 (After Resuming) | Loss: 0.0011 | dt: 320.73ms | tok/sec: 51083.96\n",
      "Step 50 (After Resuming) | Loss: 0.0019 | dt: 320.41ms | tok/sec: 51133.87\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    " \n",
    "checkpoint_path = \"llm_checkpoint.pt\"\n",
    "     \n",
    "# Load checkpoint and train for another 50 steps\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "print(\"Loaded checkpoint. Resuming training for another 50 steps.\")\n",
    "\n",
    "for step in range(50):\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Training batch\n",
    "    x, y = train_loader.next_batch()\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "        logits, loss = model(x, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    t1 = time.time()\n",
    "    dt = (t1 - t0) * 1000  # Time in milliseconds\n",
    "    tokens_per_sec = (train_loader.B * train_loader.T) / (t1 - t0)\n",
    "\n",
    "    print(f\"Step {step+1} (After Resuming) | Loss: {loss.item():.4f} | dt: {dt:.2f}ms | tok/sec: {tokens_per_sec:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
