{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Decoder-Only Transformer Model\n",
    "\n",
    "This notebook implements training for the transformer model defined in transformer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from pathlib import Path\n",
    "from transformer import Config, DecoderOnlyTransformer\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Widget\n",
    "Widget.widgets.clear_state()\n",
    "Widget.widgets.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "BATCH_SIZE = 48\n",
    "LEARNING_RATE = 3e-4\n",
    "NUM_EPOCHS = 2\n",
    "DATA_DIR = \"data/\"  # Directory containing text files\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model configuration\n",
    "config = Config(\n",
    "    vocab_size=50257,\n",
    "    max_seq_len=256,\n",
    "    dim=768,\n",
    "    num_layers=8,\n",
    "    num_heads=8,\n",
    "    dropout=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data_dir, seq_length):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.seq_length = seq_length\n",
    "        self.files = list(self.data_dir.glob('*.txt'))\n",
    "        \n",
    "        # Simple tokenization (character-level for this example)\n",
    "        self.chars = sorted(list(set(''.join(open(f).read() for f in self.files))))\n",
    "        self.vocab_size = len(self.chars)\n",
    "        self.char_to_idx = {ch: i for i, ch in enumerate(self.chars)}\n",
    "        self.idx_to_char = {i: ch for i, ch in enumerate(self.chars)}\n",
    "        \n",
    "        # Load all text\n",
    "        self.text = ''\n",
    "        for file in self.files:\n",
    "            with open(file, 'r') as f:\n",
    "                self.text += f.read()\n",
    "        \n",
    "        # Convert text to indices\n",
    "        self.data = torch.tensor([self.char_to_idx[ch] for ch in self.text], dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get sequence and target\n",
    "        x = self.data[idx:idx + self.seq_length]\n",
    "        y = self.data[idx + 1:idx + self.seq_length + 1]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 134,095,872\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = DecoderOnlyTransformer(config).to(DEVICE)\n",
    "\n",
    "# Calculate and print model size\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "num_params = count_parameters(model)\n",
    "print(f'Number of parameters: {num_params:,}')\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc='Training')\n",
    "    for batch_idx, (x, y) in enumerate(progress_bar):\n",
    "        # Move data to device\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(x)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update progress bar\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': total_loss / (batch_idx + 1)})\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67b1ca98e88442db158b0e316afd871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/23233 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.0455\n",
      "\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7a7b9ad73945c5a9edeb8d218312cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/23233 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.0072\n"
     ]
    }
   ],
   "source": [
    "# Create dataset and dataloader\n",
    "dataset = TextDataset(DATA_DIR, config.max_seq_len)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f'\\nEpoch {epoch+1}/{NUM_EPOCHS}')\n",
    "    avg_loss = train_epoch(model, dataloader, optimizer, DEVICE)\n",
    "    print(f'Average loss: {avg_loss:.4f}')\n",
    "    \n",
    "    # Save checkpoint\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': avg_loss,\n",
    "    }, f'checkpoint_epoch_{epoch+1}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Text (Inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time ceetiiit niittiietctttinute mtiieintttatnain ueautttat titiiettt tucetitinutanttuneitinintiitttinii\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, dataset, start_text, max_length=100, temperature=1.0):\n",
    "    model.eval()\n",
    "    \n",
    "    # Convert start text to indices\n",
    "    context = torch.tensor([dataset.char_to_idx[ch] for ch in start_text], dtype=torch.long)\n",
    "    context = context.unsqueeze(0).to(DEVICE)  # Add batch dimension\n",
    "    \n",
    "    generated = list(start_text)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            # Get predictions\n",
    "            logits = model(context)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            \n",
    "            # Sample from the distribution\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            \n",
    "            # Add the predicted token to the sequence\n",
    "            generated.append(dataset.idx_to_char[next_token.item()])\n",
    "            context = torch.cat([context, next_token], dim=1)\n",
    "    \n",
    "    return ''.join(generated)\n",
    "\n",
    "# Example text generation\n",
    "start_text = \"Once upon a time\"\n",
    "generated_text = generate_text(model, dataset, start_text)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
